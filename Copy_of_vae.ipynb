{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lxthames/variational_auto_encoder/blob/main/Copy_of_vae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MD_RGUwWmfV"
      },
      "source": [
        "# Variational AutoEncoder\n",
        "\n",
        "**Author:** [fchollet](https://twitter.com/fchollet)<br>\n",
        "**Date created:** 2020/05/03<br>\n",
        "**Last modified:** 2020/05/03<br>\n",
        "**Description:** Convolutional Variational AutoEncoder (VAE) trained on MNIST digits."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkkS-FOkWsPf",
        "outputId": "dd32ecfd-84d7-4b8c-a03f-4ce90646f834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCQMB6L8Wmfa"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCRF8tZ8Wmfb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyxdxLh1Wmfd"
      },
      "source": [
        "## Create a sampling layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlg9SbioWmfd"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Sampling(layers.Layer):\n",
        "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yF8Qn3HWmfe"
      },
      "source": [
        "## Build the encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1la1y-XyWmff",
        "outputId": "dffb72db-9336-4a47-b046-487fc53f1cd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 64, 64, 32)   896         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 32, 32, 64)   18496       ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 65536)        0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 16)           1048592     ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " z_mean (Dense)                 (None, 200)          3400        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " z_log_var (Dense)              (None, 200)          3400        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " sampling (Sampling)            (None, 200)          0           ['z_mean[0][0]',                 \n",
            "                                                                  'z_log_var[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,074,784\n",
            "Trainable params: 1,074,784\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "latent_dim = 200\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(128, 128, 3))\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
        "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(16, activation=\"relu\")(x)\n",
        "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
        "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgsVf-LEWmfg"
      },
      "source": [
        "## Build the decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lfaQ7WUWmfg",
        "outputId": "55c27ee8-0515-436a-cc82-60cc0c751075"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 200)]             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 65536)             13172736  \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 64, 64, 64)       36928     \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 128, 128, 32)     18464     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 128, 128, 3)      867       \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,228,995\n",
            "Trainable params: 13,228,995\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "latent_inputs = keras.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(32 * 32 * 64, activation=\"relu\")(latent_inputs)\n",
        "x = layers.Reshape((32, 32, 64))(x)\n",
        "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
        "decoder_outputs = layers.Conv2DTranspose(3, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
        "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
        "decoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELJSXmosWmfi"
      },
      "source": [
        "## Define the VAE as a `Model` with a custom `train_step`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUsnB2ePWmfj"
      },
      "outputs": [],
      "source": [
        "\n",
        "class VAE(keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "            reconstruction_loss = tf.reduce_mean(\n",
        "                tf.reduce_sum(\n",
        "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
        "                )\n",
        "            )\n",
        "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
        "            total_loss = reconstruction_loss + kl_loss\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss)\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "directory = \"/content/drive/MyDrive/content/apple2orange\""
      ],
      "metadata": {
        "id": "MlGgatSGZacN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "nOmp87CHb3sS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "FaIqX7WtcDze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = (128,128)\n",
        "batch_size = 128\n",
        "\n",
        "\n",
        "train_batches = train_datagen.flow_from_directory(\n",
        "        directory ,\n",
        "         color_mode=\"rgb\",\n",
        "        target_size=image_size,\n",
        "    \n",
        "        batch_size=batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "957J6DvlcGtT",
        "outputId": "0258caec-861e-4a0d-f43c-20b9f1cc80a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 18524 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_batches"
      ],
      "metadata": {
        "id": "kg1FQDwZnVXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNCcl4M5Wmfk"
      },
      "source": [
        "## Train the VAE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds=tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory,\n",
        "    batch_size=128,\n",
        "    image_size=(128, 128)\n",
        "   \n",
        ")"
      ],
      "metadata": {
        "id": "bZ7o4hn7ZAow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4ztS9QSWmfl",
        "outputId": "b0ef74c9-bcf5-40b9-de3e-6c7753312194"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "145/145 [==============================] - 1910s 13s/step - loss: 7591.5934 - reconstruction_loss: 6891.1685 - kl_loss: 52.3752\n",
            "Epoch 2/30\n",
            "145/145 [==============================] - 38s 255ms/step - loss: 5987.9192 - reconstruction_loss: 6268.7100 - kl_loss: 39.3577\n",
            "Epoch 3/30\n",
            "145/145 [==============================] - 40s 269ms/step - loss: 5867.9247 - reconstruction_loss: 6149.7192 - kl_loss: 42.8772\n",
            "Epoch 4/30\n",
            "145/145 [==============================] - 39s 262ms/step - loss: 5794.4133 - reconstruction_loss: 6091.7578 - kl_loss: 44.7405\n",
            "Epoch 5/30\n",
            "145/145 [==============================] - 39s 259ms/step - loss: 5746.8402 - reconstruction_loss: 6057.7246 - kl_loss: 44.3645\n",
            "Epoch 6/30\n",
            "145/145 [==============================] - 39s 259ms/step - loss: 5703.8953 - reconstruction_loss: 6030.1318 - kl_loss: 43.7991\n",
            "Epoch 7/30\n",
            "145/145 [==============================] - 38s 258ms/step - loss: 5676.9532 - reconstruction_loss: 6006.0386 - kl_loss: 42.9575\n",
            "Epoch 8/30\n",
            "145/145 [==============================] - 40s 267ms/step - loss: 5648.3311 - reconstruction_loss: 5986.2095 - kl_loss: 40.9844\n",
            "Epoch 9/30\n",
            "145/145 [==============================] - 39s 265ms/step - loss: 5633.2498 - reconstruction_loss: 5970.1821 - kl_loss: 40.0985\n",
            "Epoch 10/30\n",
            "145/145 [==============================] - 39s 262ms/step - loss: 5615.6424 - reconstruction_loss: 5957.4878 - kl_loss: 39.1178\n",
            "Epoch 11/30\n",
            "145/145 [==============================] - 39s 260ms/step - loss: 5604.5165 - reconstruction_loss: 5944.9336 - kl_loss: 38.9006\n",
            "Epoch 12/30\n",
            "145/145 [==============================] - 39s 262ms/step - loss: 5589.6367 - reconstruction_loss: 5933.1338 - kl_loss: 38.4778\n",
            "Epoch 13/30\n",
            "145/145 [==============================] - 39s 262ms/step - loss: 5580.1521 - reconstruction_loss: 5923.4844 - kl_loss: 38.4339\n",
            "Epoch 14/30\n",
            "145/145 [==============================] - 39s 265ms/step - loss: 5558.9115 - reconstruction_loss: 5914.9678 - kl_loss: 37.9701\n",
            "Epoch 15/30\n",
            "145/145 [==============================] - 39s 262ms/step - loss: 5563.4380 - reconstruction_loss: 5904.8750 - kl_loss: 38.3996\n",
            "Epoch 16/30\n",
            "145/145 [==============================] - 39s 260ms/step - loss: 5553.7206 - reconstruction_loss: 5897.7334 - kl_loss: 38.4043\n",
            "Epoch 17/30\n",
            "145/145 [==============================] - 39s 263ms/step - loss: 5543.5176 - reconstruction_loss: 5889.7070 - kl_loss: 38.5044\n",
            "Epoch 18/30\n",
            "145/145 [==============================] - 39s 265ms/step - loss: 5535.6441 - reconstruction_loss: 5884.0210 - kl_loss: 38.1448\n",
            "Epoch 19/30\n",
            "145/145 [==============================] - 39s 264ms/step - loss: 5521.4988 - reconstruction_loss: 5875.5098 - kl_loss: 38.8328\n",
            "Epoch 20/30\n",
            "145/145 [==============================] - 39s 265ms/step - loss: 5519.6047 - reconstruction_loss: 5869.9102 - kl_loss: 38.7529\n",
            "Epoch 21/30\n",
            "145/145 [==============================] - 39s 265ms/step - loss: 5514.1390 - reconstruction_loss: 5863.6929 - kl_loss: 39.1163\n",
            "Epoch 22/30\n",
            "145/145 [==============================] - 40s 267ms/step - loss: 5511.5904 - reconstruction_loss: 5857.9453 - kl_loss: 39.4272\n",
            "Epoch 23/30\n",
            "145/145 [==============================] - 40s 269ms/step - loss: 5498.6288 - reconstruction_loss: 5852.1196 - kl_loss: 39.2343\n",
            "Epoch 24/30\n",
            "145/145 [==============================] - 40s 270ms/step - loss: 5497.1752 - reconstruction_loss: 5847.4175 - kl_loss: 39.4374\n",
            "Epoch 25/30\n",
            "145/145 [==============================] - 40s 271ms/step - loss: 5494.6532 - reconstruction_loss: 5844.7046 - kl_loss: 39.8160\n",
            "Epoch 26/30\n",
            "145/145 [==============================] - 40s 267ms/step - loss: 5495.7853 - reconstruction_loss: 5839.5645 - kl_loss: 39.9827\n",
            "Epoch 27/30\n",
            "145/145 [==============================] - 41s 273ms/step - loss: 5484.0964 - reconstruction_loss: 5834.3608 - kl_loss: 40.2706\n",
            "Epoch 28/30\n",
            "145/145 [==============================] - 40s 269ms/step - loss: 5476.2774 - reconstruction_loss: 5829.3330 - kl_loss: 40.7730\n",
            "Epoch 29/30\n",
            "145/145 [==============================] - 40s 270ms/step - loss: 5476.4751 - reconstruction_loss: 5824.2280 - kl_loss: 40.7466\n",
            "Epoch 30/30\n",
            "145/145 [==============================] - 40s 270ms/step - loss: 5476.9300 - reconstruction_loss: 5822.8701 - kl_loss: 41.2118\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f58b5fe6190>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
        "#mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
        "#mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255\n",
        "\n",
        "vae = VAE(encoder, decoder)\n",
        "vae.compile(optimizer=keras.optimizers.Adam())\n",
        "vae.fit_generator(training_dataset , epochs=30)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vae.save_weights(\"/content/drive/MyDrive/output/my_vae_model.h5\")"
      ],
      "metadata": {
        "id": "PCsg_yOvZzVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4L7hDeLWmfm"
      },
      "source": [
        "## Display a grid of sampled digits"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n_to_show = 1\n",
        "znew = np.random.normal(size = (n_to_show,200))\n",
        "reconst = vae.decoder.predict(np.array(znew))\n",
        "fig = plt.figure(figsize=(18, 5))\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "for i in range(n_to_show):\n",
        "  ax = fig.add_subplot(3, 10, i+1)\n",
        "  ax.imshow(reconst[i, :,:,:])\n",
        "  ax.set_axis_off()\n",
        "  plt.imshow(reconst[i, :,:,:])\n",
        "  plt.savefig(\"squares.pdf\", dpi=250,bbox_inches =\"tight\")"
      ],
      "metadata": {
        "id": "sNjeImIheNZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "cUIbiClVWmfm",
        "outputId": "0798ccd8-bfc4-4f9c-aa8c-b25e3f52960c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-34ce2d8ded8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mplot_latent_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'vae' is not defined"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_latent_space(vae, n=30, figsize=15):\n",
        "    # display a n*n 2D manifold of digits\n",
        "    digit_size = 128\n",
        "    scale = 1.0\n",
        "    figure = np.zeros((digit_size * n, digit_size * n))\n",
        "    # linearly spaced coordinates corresponding to the 2D plot\n",
        "    # of digit classes in the latent space\n",
        "    grid_x = np.linspace(-scale, scale, n)\n",
        "    grid_y = np.linspace(-scale, scale, n)[::-1]\n",
        "\n",
        "    for i, yi in enumerate(grid_y):\n",
        "        for j, xi in enumerate(grid_x):\n",
        "            znew = np.random.normal(size = (n_to_show,200))\n",
        "            x_decoded = vae.decoder.predict(znew )\n",
        "            digit = x_decoded[0].reshape(digit_size, digit_size,3)\n",
        "            digit = x_decoded[0].reshape(digit_size, digit_size,3)\n",
        "    plt.figure(figsize=(figsize, figsize))\n",
        "    start_range = digit_size // 2\n",
        "    end_range = n * digit_size + start_range\n",
        "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
        "    sample_range_x = np.round(grid_x, 1)\n",
        "    sample_range_y = np.round(grid_y, 1)\n",
        "    plt.xticks(pixel_range, sample_range_x)\n",
        "    plt.yticks(pixel_range, sample_range_y)\n",
        "    plt.xlabel(\"z[0]\")\n",
        "    plt.ylabel(\"z[1]\")\n",
        "    plt.imshow(figure, cmap=\"Greys_r\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_latent_space(vae)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n_to_show = 60\n",
        "znew = np.random.normal(size = (n_to_show,200) )\n",
        "reconst = vae.decoder.predict(np.array(znew))\n",
        "fig = plt.figure(figsize=(500, 500)) \n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "for i in range(n_to_show):\n",
        "    ax = fig.add_subplot(6, 10, i+1)\n",
        "    ax.imshow(reconst[i, :,:,:])\n",
        "    ax.axis('off')\n",
        "\n",
        "#plt.savefig(\"squares.pdf\", dpi=250,bbox_inches =\"tight\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OOslVyNZfgGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPGJCepZWmfn"
      },
      "source": [
        "## Display how the latent space clusters different digit classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYF_qgsmWmfo"
      },
      "outputs": [],
      "source": [
        "\n",
        "def plot_label_clusters(vae, data, labels):\n",
        "    # display a 2D plot of the digit classes in the latent space\n",
        "    z_mean, _, _ = vae.encoder.predict(data)\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)\n",
        "    plt.colorbar()\n",
        "    plt.xlabel(\"z[0]\")\n",
        "    plt.ylabel(\"z[1]\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "(x_train, y_train), _ = keras.datasets.mnist.load_data()\n",
        "x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255\n",
        "\n",
        "plot_label_clusters(vae, x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "imgs, labels = train_batches[1]\n",
        "plotImages(imgs)\n",
        "print(labels[:5])"
      ],
      "metadata": {
        "id": "0-fYA69HgYfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1,5)\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip(images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "FOLyS7kugiBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "TYKlSa9uoaW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = \"/content/drive/MyDrive/s/appleandoranges/trainA\"\n",
        "images = [os.path.join(image_dir, image) for image in os.listdir(image_dir)]\n",
        "images[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cmwGp1Nobij",
        "outputId": "9cc84e57-f313-4a18-b6af-f0876b4c76d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/s/appleandoranges/trainA/Copy of 15.jpeg',\n",
              " '/content/drive/MyDrive/s/appleandoranges/trainA/Copy of 13.jpeg']"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "images= glob.glob('/content/drive/MyDrive/content/apple2orange/**/*.jpg', \n",
        "                   recursive = True)"
      ],
      "metadata": {
        "id": "uIl_qeGAsWyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwTvtjDks7eZ",
        "outputId": "3a5191f0-b629-41cc-f06f-2551e7e55172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/content/apple2orange/trainA/frame_3991.jpg',\n",
              " '/content/drive/MyDrive/content/apple2orange/trainA/frame_3992.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRFr8NyWtEb9",
        "outputId": "6179b1ab-d7cd-4c11-9a91-4a6d24544965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18524"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess\n",
        "image_size = 128\n",
        "\n",
        "def preprocess(image):\n",
        "    image = tf.io.read_file(image)\n",
        "    image = tf.io.decode_jpeg(image)\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = tf.image.resize(image, (image_size, image_size))\n",
        "    image = image / 255.0\n",
        "    image = tf.reshape(image, shape = (image_size, image_size, 3,))\n",
        "    return image"
      ],
      "metadata": {
        "id": "bm6Tp9WMomnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "\n",
        "training_dataset = tf.data.Dataset.from_tensor_slices((images))\n",
        "training_dataset = training_dataset.map(preprocess)\n",
        "training_dataset = training_dataset.shuffle(1000).batch(batch_size)"
      ],
      "metadata": {
        "id": "I6I1gUK1oqNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(training_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkEg3aonosdb",
        "outputId": "febba4fc-6077-4695-f18a-c9a75a4e0293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "145"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize some of them\n",
        "fig, axes = plt.subplots(5,5, figsize = (14,14))\n",
        "sample = training_dataset.unbatch().take(25)\n",
        "sample = [image for image in sample]\n",
        "\n",
        "idx = 0\n",
        "for row in range(5):\n",
        "    for column in range(5):\n",
        "        axes[row, column].imshow(sample[idx])\n",
        "        idx+=1"
      ],
      "metadata": {
        "id": "L8GR1V9zoumG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 512"
      ],
      "metadata": {
        "id": "6yNrW34IozCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential, Model\n",
        "\n",
        "from keras.layers import Dense, Conv2D, Conv2DTranspose, Input, Flatten, BatchNormalization, Lambda, Reshape, Activation\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.activations import selu\n",
        "from keras.layers import Multiply, Add\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "mpm916pAo3XH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K.clear_session()"
      ],
      "metadata": {
        "id": "YV102vlrpKWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = Input(shape = (64,64,3))\n",
        "\n",
        "x = Conv2D(32, kernel_size=5, activation = LeakyReLU(0.02), strides = 1, padding = 'same')(encoder_input)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "filter_size = [64,128,256,512]\n",
        "for i in filter_size:\n",
        "    x = Conv2D(i, kernel_size=5, activation = LeakyReLU(0.02), strides = 2, padding = 'same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024, activation = selu)(x)\n",
        "encoder_output = BatchNormalization()(x)\n",
        "\n",
        "# sampling layer\n",
        "mu = Dense(latent_dim)(encoder_output)\n",
        "log_var = Dense(latent_dim)(encoder_output)\n",
        "\n",
        "epsilon = K.random_normal(shape = (tf.shape(mu)[0], tf.shape(mu)[1]))\n",
        "sigma = tf.exp(0.5 * log_var)\n",
        "\n",
        "z_eps = Multiply()([sigma, epsilon])\n",
        "z = Add()([mu, z_eps])\n",
        "\n",
        "encoder = Model(encoder_input, outputs = [mu, log_var, z], name = 'encoder')\n",
        "encoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ubz994KppP01",
        "outputId": "8b130135-effb-44f2-eddc-6c8c35d31614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 64, 64, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 64, 64, 32)   2432        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 64, 64, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 32, 32, 64)   51264       ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 16, 16, 128)  204928      ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 8, 8, 256)    819456      ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 8, 8, 256)   1024        ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 4, 4, 512)    3277312     ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 4, 4, 512)   2048        ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 8192)         0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1024)         8389632     ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 1024)        4096        ['dense[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 512)          524800      ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 512)          524800      ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape (TFOpLambda  (2,)                0           ['dense_1[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape_1 (TFOpLamb  (2,)                0           ['dense_1[0][0]']                \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.math.multiply (TFOpLambda)  (None, 512)          0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  ()                  0           ['tf.compat.v1.shape[0][0]']     \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1 (Sl  ()                  0           ['tf.compat.v1.shape_1[0][0]']   \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.math.exp (TFOpLambda)       (None, 512)          0           ['tf.math.multiply[0][0]']       \n",
            "                                                                                                  \n",
            " tf.random.normal (TFOpLambda)  (None, 512)          0           ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 , 'tf.__operators__.getitem_1[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 512)          0           ['tf.math.exp[0][0]',            \n",
            "                                                                  'tf.random.normal[0][0]']       \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 512)          0           ['dense_1[0][0]',                \n",
            "                                                                  'multiply[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 13,802,688\n",
            "Trainable params: 13,798,656\n",
            "Non-trainable params: 4,032\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Sequential()\n",
        "decoder.add(Dense(1024, activation = selu, input_shape = (latent_dim, )))\n",
        "decoder.add(BatchNormalization())\n",
        "\n",
        "decoder.add(Dense(8192, activation = selu))\n",
        "decoder.add(Reshape((4,4,512)))\n",
        "\n",
        "decoder.add(Conv2DTranspose(256, (5,5), activation = LeakyReLU(0.02), strides = 2, padding = 'same'))\n",
        "decoder.add(BatchNormalization())\n",
        "\n",
        "decoder.add(Conv2DTranspose(128, (5,5), activation = LeakyReLU(0.02), strides = 2, padding = 'same'))\n",
        "decoder.add(BatchNormalization())\n",
        "\n",
        "decoder.add(Conv2DTranspose(64, (5,5), activation = LeakyReLU(0.02), strides = 2, padding = 'same'))\n",
        "decoder.add(BatchNormalization())\n",
        "\n",
        "decoder.add(Conv2DTranspose(32, (5,5), activation = LeakyReLU(0.02), strides = 2, padding = 'same'))\n",
        "decoder.add(BatchNormalization())\n",
        "\n",
        "decoder.add(Conv2DTranspose(3, (5,5), activation = \"sigmoid\", strides = 1, padding = 'same'))\n",
        "decoder.add(BatchNormalization())\n",
        "\n",
        "decoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4lbtxUzpTZn",
        "outputId": "8d4c2c19-9a7b-43e6-d700-8993ed5a6029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 1024)              525312    \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 1024)             4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 8192)              8396800   \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 8, 8, 256)        3277056   \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 8, 8, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 16, 16, 128)      819328    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 16, 16, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 32, 32, 64)       204864    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 32, 32, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 64, 64, 32)       51232     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 64, 64, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_transpose_4 (Conv2DT  (None, 64, 64, 3)        2403      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 64, 64, 3)        12        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,283,023\n",
            "Trainable params: 13,280,009\n",
            "Non-trainable params: 3,014\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make loss function \n",
        "# vae loss = reconstruction loss + KL div\n",
        "\n",
        "def reconstruction_loss(y, y_pred):\n",
        "    return tf.reduce_mean(tf.square(y - y_pred))\n",
        "\n",
        "def kl_loss(mu, log_var):\n",
        "    loss = -0.5 * tf.reduce_mean(1 + log_var - tf.square(mu) - tf.exp(log_var))\n",
        "    return loss\n",
        "\n",
        "def vae_loss(y_true, y_pred, mu, log_var):\n",
        "    return reconstruction_loss(y_true, y_pred) + (1 / (64*64)) * kl_loss(mu, log_var)"
      ],
      "metadata": {
        "id": "dTUCzJE-pWuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# conbine encoder and decoder\n",
        "mu, log_var, z = encoder(encoder_input)\n",
        "reconstructed = decoder(z)\n",
        "model = Model(encoder_input, reconstructed, name =\"vae\")\n",
        "loss = kl_loss(mu, log_var)\n",
        "model.add_loss(loss)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdHF9y8RpZes",
        "outputId": "b6411ea6-7052-4529-9963-d3420a37f0d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vae\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 64, 64, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " encoder (Functional)           [(None, 512),        13802688    ['input_1[0][0]']                \n",
            "                                 (None, 512),                                                     \n",
            "                                 (None, 512)]                                                     \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, 64, 64, 3)    13283023    ['encoder[0][2]']                \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  (None, 512)         0           ['encoder[0][1]']                \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.math.square (TFOpLambda)    (None, 512)          0           ['encoder[0][0]']                \n",
            "                                                                                                  \n",
            " tf.math.subtract (TFOpLambda)  (None, 512)          0           ['tf.__operators__.add[0][0]',   \n",
            "                                                                  'tf.math.square[0][0]']         \n",
            "                                                                                                  \n",
            " tf.math.exp_1 (TFOpLambda)     (None, 512)          0           ['encoder[0][1]']                \n",
            "                                                                                                  \n",
            " tf.math.subtract_1 (TFOpLambda  (None, 512)         0           ['tf.math.subtract[0][0]',       \n",
            " )                                                                'tf.math.exp_1[0][0]']          \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean (TFOpLambd  ()                  0           ['tf.math.subtract_1[0][0]']     \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply_1 (TFOpLambda  ()                  0           ['tf.math.reduce_mean[0][0]']    \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " add_loss (AddLoss)             ()                   0           ['tf.math.multiply_1[0][0]']     \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 27,085,711\n",
            "Trainable params: 27,078,665\n",
            "Non-trainable params: 7,046\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make a function to save images while learning\n",
        "def save_images(model, epoch, step, input_):\n",
        "    prediction = model.predict(input_)\n",
        "    fig, axes = plt.subplots(5,5, figsize = (14,14))\n",
        "    idx = 0\n",
        "    for row in range(5):\n",
        "        for column in range(5):\n",
        "            image = prediction[idx] * 255\n",
        "            image = image.astype(\"int32\")\n",
        "            axes[row, column].imshow(image)\n",
        "            axes[row, column].axis(\"off\")\n",
        "            idx+=1\n",
        "    output_path = \"output/\"\n",
        "    if not os.path.exists(output_path):\n",
        "        os.mkdir(output_path)\n",
        "    plt.savefig(output_path + \"Epoch_{:04d}_step_{:04d}.jpg\".format(epoch, step))\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "SglzuKTdpc_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from keras.optimizers import Adam\n",
        "\n",
        "random_vector = tf.random.normal(shape = (25, latent_dim,))\n",
        "save_images(decoder, 0, 0, random_vector)\n",
        "\n",
        "mse_losses = []\n",
        "kl_losses = []\n",
        "\n",
        "optimizer = Adam(0.0001, 0.5)\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    print(\"Epoch: \", epoch)\n",
        "    for step, training_batch in enumerate(training_dataset):\n",
        "        with tf.GradientTape() as tape:\n",
        "            reconstructed = model(training_batch)\n",
        "            y_true = tf.reshape(training_batch, shape = [-1])\n",
        "            y_pred = tf.reshape(reconstructed, shape = [-1])\n",
        "            \n",
        "            mse_loss = reconstruction_loss(y_true, y_pred)\n",
        "            mse_losses.append(mse_loss.numpy())\n",
        "            \n",
        "            kl = sum(model.losses)\n",
        "            kl_losses.append(kl.numpy())\n",
        "            \n",
        "            train_loss = 0.01 * kl + mse_loss\n",
        "            \n",
        "            grads = tape.gradient(train_loss, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "            \n",
        "            if step % 10 == 0:\n",
        "                save_images(decoder, epoch, step, random_vector)\n",
        "            print(\"Epoch: %s - Step: %s - MSE loss: %s - KL loss: %s\" % (epoch, step, mse_loss.numpy(), kl.numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jxPCZpfpfwW",
        "outputId": "8ca8d5db-8d4c-46ad-9928-dd92aff37116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch: 9 - Step: 121 - MSE loss: 0.018373188 - KL loss: 0.24742466\n",
            "Epoch: 9 - Step: 122 - MSE loss: 0.018337645 - KL loss: 0.2275961\n",
            "Epoch: 9 - Step: 123 - MSE loss: 0.019046778 - KL loss: 0.25735226\n",
            "Epoch: 9 - Step: 124 - MSE loss: 0.021418536 - KL loss: 0.20209533\n",
            "Epoch: 9 - Step: 125 - MSE loss: 0.023154484 - KL loss: 0.21189159\n",
            "Epoch: 9 - Step: 126 - MSE loss: 0.02134799 - KL loss: 0.18341574\n",
            "Epoch: 9 - Step: 127 - MSE loss: 0.01895535 - KL loss: 0.21181619\n",
            "Epoch: 9 - Step: 128 - MSE loss: 0.018269809 - KL loss: 0.20699723\n",
            "Epoch: 9 - Step: 129 - MSE loss: 0.019224154 - KL loss: 0.2237811\n",
            "Epoch: 9 - Step: 130 - MSE loss: 0.018750802 - KL loss: 0.23089588\n",
            "Epoch: 9 - Step: 131 - MSE loss: 0.017713958 - KL loss: 0.24109392\n",
            "Epoch: 9 - Step: 132 - MSE loss: 0.020461543 - KL loss: 0.23212618\n",
            "Epoch: 9 - Step: 133 - MSE loss: 0.021182397 - KL loss: 0.2385257\n",
            "Epoch: 9 - Step: 134 - MSE loss: 0.021170536 - KL loss: 0.21709138\n",
            "Epoch: 9 - Step: 135 - MSE loss: 0.020299789 - KL loss: 0.23365155\n",
            "Epoch: 9 - Step: 136 - MSE loss: 0.021392995 - KL loss: 0.20137359\n",
            "Epoch: 9 - Step: 137 - MSE loss: 0.022225998 - KL loss: 0.21514109\n",
            "Epoch: 9 - Step: 138 - MSE loss: 0.022878326 - KL loss: 0.1717498\n",
            "Epoch: 9 - Step: 139 - MSE loss: 0.020430481 - KL loss: 0.18489432\n",
            "Epoch: 9 - Step: 140 - MSE loss: 0.019665482 - KL loss: 0.18870986\n",
            "Epoch: 9 - Step: 141 - MSE loss: 0.020853646 - KL loss: 0.20298469\n",
            "Epoch: 9 - Step: 142 - MSE loss: 0.019827206 - KL loss: 0.21039551\n",
            "Epoch: 9 - Step: 143 - MSE loss: 0.019496812 - KL loss: 0.20522568\n",
            "Epoch: 9 - Step: 144 - MSE loss: 0.01881568 - KL loss: 0.21311393\n",
            "Epoch:  10\n",
            "Epoch: 10 - Step: 0 - MSE loss: 0.009360537 - KL loss: 0.18914051\n",
            "Epoch: 10 - Step: 1 - MSE loss: 0.009617409 - KL loss: 0.18651478\n",
            "Epoch: 10 - Step: 2 - MSE loss: 0.009585544 - KL loss: 0.18628514\n",
            "Epoch: 10 - Step: 3 - MSE loss: 0.010240157 - KL loss: 0.19493027\n",
            "Epoch: 10 - Step: 4 - MSE loss: 0.009557134 - KL loss: 0.17785385\n",
            "Epoch: 10 - Step: 5 - MSE loss: 0.009692775 - KL loss: 0.17102897\n",
            "Epoch: 10 - Step: 6 - MSE loss: 0.010569979 - KL loss: 0.16772112\n",
            "Epoch: 10 - Step: 7 - MSE loss: 0.009853908 - KL loss: 0.15891966\n",
            "Epoch: 10 - Step: 8 - MSE loss: 0.010942337 - KL loss: 0.15546197\n",
            "Epoch: 10 - Step: 9 - MSE loss: 0.010936624 - KL loss: 0.15938877\n",
            "Epoch: 10 - Step: 10 - MSE loss: 0.00988726 - KL loss: 0.16186151\n",
            "Epoch: 10 - Step: 11 - MSE loss: 0.010870618 - KL loss: 0.1520168\n",
            "Epoch: 10 - Step: 12 - MSE loss: 0.009511176 - KL loss: 0.15976205\n",
            "Epoch: 10 - Step: 13 - MSE loss: 0.010223216 - KL loss: 0.16079734\n",
            "Epoch: 10 - Step: 14 - MSE loss: 0.01025582 - KL loss: 0.14580733\n",
            "Epoch: 10 - Step: 15 - MSE loss: 0.010348319 - KL loss: 0.15744428\n",
            "Epoch: 10 - Step: 16 - MSE loss: 0.010373115 - KL loss: 0.1581024\n",
            "Epoch: 10 - Step: 17 - MSE loss: 0.010233951 - KL loss: 0.15648484\n",
            "Epoch: 10 - Step: 18 - MSE loss: 0.0092714345 - KL loss: 0.1459972\n",
            "Epoch: 10 - Step: 19 - MSE loss: 0.009201137 - KL loss: 0.14747964\n",
            "Epoch: 10 - Step: 20 - MSE loss: 0.008796346 - KL loss: 0.1358876\n",
            "Epoch: 10 - Step: 21 - MSE loss: 0.008564248 - KL loss: 0.13535807\n",
            "Epoch: 10 - Step: 22 - MSE loss: 0.009356118 - KL loss: 0.14362472\n",
            "Epoch: 10 - Step: 23 - MSE loss: 0.008836848 - KL loss: 0.13724363\n",
            "Epoch: 10 - Step: 24 - MSE loss: 0.008818892 - KL loss: 0.13958633\n",
            "Epoch: 10 - Step: 25 - MSE loss: 0.008608836 - KL loss: 0.13956523\n",
            "Epoch: 10 - Step: 26 - MSE loss: 0.008025063 - KL loss: 0.13815367\n",
            "Epoch: 10 - Step: 27 - MSE loss: 0.009043877 - KL loss: 0.13833204\n",
            "Epoch: 10 - Step: 28 - MSE loss: 0.008634985 - KL loss: 0.13591567\n",
            "Epoch: 10 - Step: 29 - MSE loss: 0.008691799 - KL loss: 0.13731962\n",
            "Epoch: 10 - Step: 30 - MSE loss: 0.0076503134 - KL loss: 0.13920903\n",
            "Epoch: 10 - Step: 31 - MSE loss: 0.009014114 - KL loss: 0.1438004\n",
            "Epoch: 10 - Step: 32 - MSE loss: 0.009625895 - KL loss: 0.15615308\n",
            "Epoch: 10 - Step: 33 - MSE loss: 0.010867012 - KL loss: 0.16354498\n",
            "Epoch: 10 - Step: 34 - MSE loss: 0.011003685 - KL loss: 0.16193616\n",
            "Epoch: 10 - Step: 35 - MSE loss: 0.011125732 - KL loss: 0.1811248\n",
            "Epoch: 10 - Step: 36 - MSE loss: 0.012746724 - KL loss: 0.17601383\n",
            "Epoch: 10 - Step: 37 - MSE loss: 0.013873383 - KL loss: 0.21248703\n",
            "Epoch: 10 - Step: 38 - MSE loss: 0.0141744325 - KL loss: 0.17826664\n",
            "Epoch: 10 - Step: 39 - MSE loss: 0.01571705 - KL loss: 0.20057154\n",
            "Epoch: 10 - Step: 40 - MSE loss: 0.017017381 - KL loss: 0.20321308\n",
            "Epoch: 10 - Step: 41 - MSE loss: 0.016791731 - KL loss: 0.21424168\n",
            "Epoch: 10 - Step: 42 - MSE loss: 0.016627802 - KL loss: 0.20682207\n",
            "Epoch: 10 - Step: 43 - MSE loss: 0.016830867 - KL loss: 0.22906028\n",
            "Epoch: 10 - Step: 44 - MSE loss: 0.017433012 - KL loss: 0.2192497\n",
            "Epoch: 10 - Step: 45 - MSE loss: 0.016726607 - KL loss: 0.21622829\n",
            "Epoch: 10 - Step: 46 - MSE loss: 0.018076716 - KL loss: 0.1904984\n",
            "Epoch: 10 - Step: 47 - MSE loss: 0.01849523 - KL loss: 0.2192035\n",
            "Epoch: 10 - Step: 48 - MSE loss: 0.017909458 - KL loss: 0.19498383\n",
            "Epoch: 10 - Step: 49 - MSE loss: 0.017696155 - KL loss: 0.20573032\n",
            "Epoch: 10 - Step: 50 - MSE loss: 0.01903434 - KL loss: 0.22311741\n",
            "Epoch: 10 - Step: 51 - MSE loss: 0.019435083 - KL loss: 0.22318996\n",
            "Epoch: 10 - Step: 52 - MSE loss: 0.018172042 - KL loss: 0.21438858\n",
            "Epoch: 10 - Step: 53 - MSE loss: 0.019942878 - KL loss: 0.22895378\n",
            "Epoch: 10 - Step: 54 - MSE loss: 0.01874342 - KL loss: 0.21854602\n",
            "Epoch: 10 - Step: 55 - MSE loss: 0.019448476 - KL loss: 0.22173196\n",
            "Epoch: 10 - Step: 56 - MSE loss: 0.018357743 - KL loss: 0.20916851\n",
            "Epoch: 10 - Step: 57 - MSE loss: 0.019471489 - KL loss: 0.1966073\n",
            "Epoch: 10 - Step: 58 - MSE loss: 0.019887159 - KL loss: 0.20829555\n",
            "Epoch: 10 - Step: 59 - MSE loss: 0.020314863 - KL loss: 0.21046633\n",
            "Epoch: 10 - Step: 60 - MSE loss: 0.021046972 - KL loss: 0.22388396\n",
            "Epoch: 10 - Step: 61 - MSE loss: 0.01993989 - KL loss: 0.21774533\n",
            "Epoch: 10 - Step: 62 - MSE loss: 0.021934295 - KL loss: 0.23292038\n",
            "Epoch: 10 - Step: 63 - MSE loss: 0.020626815 - KL loss: 0.20542851\n",
            "Epoch: 10 - Step: 64 - MSE loss: 0.022514401 - KL loss: 0.22576083\n",
            "Epoch: 10 - Step: 65 - MSE loss: 0.020289125 - KL loss: 0.20813008\n",
            "Epoch: 10 - Step: 66 - MSE loss: 0.01838985 - KL loss: 0.219299\n",
            "Epoch: 10 - Step: 67 - MSE loss: 0.016674915 - KL loss: 0.21442369\n",
            "Epoch: 10 - Step: 68 - MSE loss: 0.015587561 - KL loss: 0.18767735\n",
            "Epoch: 10 - Step: 69 - MSE loss: 0.016176244 - KL loss: 0.1901818\n",
            "Epoch: 10 - Step: 70 - MSE loss: 0.014407554 - KL loss: 0.17876542\n",
            "Epoch: 10 - Step: 71 - MSE loss: 0.01320447 - KL loss: 0.17704241\n",
            "Epoch: 10 - Step: 72 - MSE loss: 0.012130198 - KL loss: 0.17598218\n",
            "Epoch: 10 - Step: 73 - MSE loss: 0.010950242 - KL loss: 0.18193577\n",
            "Epoch: 10 - Step: 74 - MSE loss: 0.012322317 - KL loss: 0.17724976\n",
            "Epoch: 10 - Step: 75 - MSE loss: 0.010406208 - KL loss: 0.15798572\n",
            "Epoch: 10 - Step: 76 - MSE loss: 0.010135194 - KL loss: 0.15964288\n",
            "Epoch: 10 - Step: 77 - MSE loss: 0.010542125 - KL loss: 0.14451605\n",
            "Epoch: 10 - Step: 78 - MSE loss: 0.009570009 - KL loss: 0.14059475\n",
            "Epoch: 10 - Step: 79 - MSE loss: 0.010269433 - KL loss: 0.13833946\n",
            "Epoch: 10 - Step: 80 - MSE loss: 0.01036037 - KL loss: 0.14402235\n",
            "Epoch: 10 - Step: 81 - MSE loss: 0.010588589 - KL loss: 0.15164709\n",
            "Epoch: 10 - Step: 82 - MSE loss: 0.009722243 - KL loss: 0.1432825\n",
            "Epoch: 10 - Step: 83 - MSE loss: 0.009646053 - KL loss: 0.14978\n",
            "Epoch: 10 - Step: 84 - MSE loss: 0.009708636 - KL loss: 0.15579523\n",
            "Epoch: 10 - Step: 85 - MSE loss: 0.009124178 - KL loss: 0.14490938\n",
            "Epoch: 10 - Step: 86 - MSE loss: 0.009673422 - KL loss: 0.1427867\n",
            "Epoch: 10 - Step: 87 - MSE loss: 0.010404305 - KL loss: 0.14282978\n",
            "Epoch: 10 - Step: 88 - MSE loss: 0.010454289 - KL loss: 0.15727264\n",
            "Epoch: 10 - Step: 89 - MSE loss: 0.0099532725 - KL loss: 0.15772948\n",
            "Epoch: 10 - Step: 90 - MSE loss: 0.009724203 - KL loss: 0.15802434\n",
            "Epoch: 10 - Step: 91 - MSE loss: 0.0101991175 - KL loss: 0.15722108\n",
            "Epoch: 10 - Step: 92 - MSE loss: 0.009411506 - KL loss: 0.16088346\n",
            "Epoch: 10 - Step: 93 - MSE loss: 0.009861442 - KL loss: 0.16208485\n",
            "Epoch: 10 - Step: 94 - MSE loss: 0.010216277 - KL loss: 0.15475392\n",
            "Epoch: 10 - Step: 95 - MSE loss: 0.010165614 - KL loss: 0.15760382\n",
            "Epoch: 10 - Step: 96 - MSE loss: 0.010068734 - KL loss: 0.1690991\n",
            "Epoch: 10 - Step: 97 - MSE loss: 0.009875443 - KL loss: 0.16053852\n",
            "Epoch: 10 - Step: 98 - MSE loss: 0.01057925 - KL loss: 0.15032253\n",
            "Epoch: 10 - Step: 99 - MSE loss: 0.011218703 - KL loss: 0.1512465\n",
            "Epoch: 10 - Step: 100 - MSE loss: 0.01054885 - KL loss: 0.16346426\n",
            "Epoch: 10 - Step: 101 - MSE loss: 0.0118660405 - KL loss: 0.15296611\n",
            "Epoch: 10 - Step: 102 - MSE loss: 0.011780568 - KL loss: 0.14881709\n",
            "Epoch: 10 - Step: 103 - MSE loss: 0.010759904 - KL loss: 0.16093452\n",
            "Epoch: 10 - Step: 104 - MSE loss: 0.010726158 - KL loss: 0.17529455\n",
            "Epoch: 10 - Step: 105 - MSE loss: 0.011770698 - KL loss: 0.18869534\n",
            "Epoch: 10 - Step: 106 - MSE loss: 0.015419667 - KL loss: 0.20520847\n",
            "Epoch: 10 - Step: 107 - MSE loss: 0.0130218575 - KL loss: 0.19062793\n",
            "Epoch: 10 - Step: 108 - MSE loss: 0.015064447 - KL loss: 0.22669753\n",
            "Epoch: 10 - Step: 109 - MSE loss: 0.015877225 - KL loss: 0.20301\n",
            "Epoch: 10 - Step: 110 - MSE loss: 0.01449313 - KL loss: 0.20851895\n",
            "Epoch: 10 - Step: 111 - MSE loss: 0.018355945 - KL loss: 0.2011923\n",
            "Epoch: 10 - Step: 112 - MSE loss: 0.017872734 - KL loss: 0.20725659\n",
            "Epoch: 10 - Step: 113 - MSE loss: 0.01903809 - KL loss: 0.21800357\n",
            "Epoch: 10 - Step: 114 - MSE loss: 0.017569078 - KL loss: 0.21743146\n",
            "Epoch: 10 - Step: 115 - MSE loss: 0.018416235 - KL loss: 0.22650939\n",
            "Epoch: 10 - Step: 116 - MSE loss: 0.020518513 - KL loss: 0.23760068\n",
            "Epoch: 10 - Step: 117 - MSE loss: 0.021822108 - KL loss: 0.20118214\n",
            "Epoch: 10 - Step: 118 - MSE loss: 0.02482079 - KL loss: 0.2208744\n",
            "Epoch: 10 - Step: 119 - MSE loss: 0.0241284 - KL loss: 0.19411129\n",
            "Epoch: 10 - Step: 120 - MSE loss: 0.02230973 - KL loss: 0.23647244\n",
            "Epoch: 10 - Step: 121 - MSE loss: 0.020368433 - KL loss: 0.19989923\n",
            "Epoch: 10 - Step: 122 - MSE loss: 0.018452069 - KL loss: 0.2298891\n",
            "Epoch: 10 - Step: 123 - MSE loss: 0.019351589 - KL loss: 0.21839395\n",
            "Epoch: 10 - Step: 124 - MSE loss: 0.017970523 - KL loss: 0.22972098\n",
            "Epoch: 10 - Step: 125 - MSE loss: 0.018923756 - KL loss: 0.21763618\n",
            "Epoch: 10 - Step: 126 - MSE loss: 0.01816499 - KL loss: 0.230814\n",
            "Epoch: 10 - Step: 127 - MSE loss: 0.017936649 - KL loss: 0.2284399\n",
            "Epoch: 10 - Step: 128 - MSE loss: 0.016979765 - KL loss: 0.22891691\n",
            "Epoch: 10 - Step: 129 - MSE loss: 0.01712391 - KL loss: 0.23877755\n",
            "Epoch: 10 - Step: 130 - MSE loss: 0.018412188 - KL loss: 0.23266986\n",
            "Epoch: 10 - Step: 131 - MSE loss: 0.018685492 - KL loss: 0.23991874\n",
            "Epoch: 10 - Step: 132 - MSE loss: 0.019949986 - KL loss: 0.22426772\n",
            "Epoch: 10 - Step: 133 - MSE loss: 0.01994186 - KL loss: 0.22835067\n",
            "Epoch: 10 - Step: 134 - MSE loss: 0.019978091 - KL loss: 0.21786588\n",
            "Epoch: 10 - Step: 135 - MSE loss: 0.022435231 - KL loss: 0.24022877\n",
            "Epoch: 10 - Step: 136 - MSE loss: 0.023911288 - KL loss: 0.19467372\n",
            "Epoch: 10 - Step: 137 - MSE loss: 0.02138856 - KL loss: 0.20726357\n",
            "Epoch: 10 - Step: 138 - MSE loss: 0.020081542 - KL loss: 0.20470062\n",
            "Epoch: 10 - Step: 139 - MSE loss: 0.018800208 - KL loss: 0.2024119\n",
            "Epoch: 10 - Step: 140 - MSE loss: 0.018977644 - KL loss: 0.2122065\n",
            "Epoch: 10 - Step: 141 - MSE loss: 0.018472832 - KL loss: 0.21027657\n",
            "Epoch: 10 - Step: 142 - MSE loss: 0.019122219 - KL loss: 0.21584508\n",
            "Epoch: 10 - Step: 143 - MSE loss: 0.017452417 - KL loss: 0.22582474\n",
            "Epoch: 10 - Step: 144 - MSE loss: 0.017581915 - KL loss: 0.21163206\n",
            "Epoch:  11\n",
            "Epoch: 11 - Step: 0 - MSE loss: 0.008654608 - KL loss: 0.18375683\n",
            "Epoch: 11 - Step: 1 - MSE loss: 0.009062805 - KL loss: 0.18503353\n",
            "Epoch: 11 - Step: 2 - MSE loss: 0.009674519 - KL loss: 0.19874075\n",
            "Epoch: 11 - Step: 3 - MSE loss: 0.008907737 - KL loss: 0.17743975\n",
            "Epoch: 11 - Step: 4 - MSE loss: 0.008848744 - KL loss: 0.1608662\n",
            "Epoch: 11 - Step: 5 - MSE loss: 0.009771919 - KL loss: 0.17263447\n",
            "Epoch: 11 - Step: 6 - MSE loss: 0.009248216 - KL loss: 0.18058226\n",
            "Epoch: 11 - Step: 7 - MSE loss: 0.009567661 - KL loss: 0.16274348\n",
            "Epoch: 11 - Step: 8 - MSE loss: 0.009608594 - KL loss: 0.15672624\n",
            "Epoch: 11 - Step: 9 - MSE loss: 0.010635729 - KL loss: 0.16343294\n",
            "Epoch: 11 - Step: 10 - MSE loss: 0.011213104 - KL loss: 0.15408128\n",
            "Epoch: 11 - Step: 11 - MSE loss: 0.00978959 - KL loss: 0.1556295\n",
            "Epoch: 11 - Step: 12 - MSE loss: 0.009349474 - KL loss: 0.15967168\n",
            "Epoch: 11 - Step: 13 - MSE loss: 0.009568959 - KL loss: 0.15883297\n",
            "Epoch: 11 - Step: 14 - MSE loss: 0.010527964 - KL loss: 0.1572466\n",
            "Epoch: 11 - Step: 15 - MSE loss: 0.010530538 - KL loss: 0.15775624\n",
            "Epoch: 11 - Step: 16 - MSE loss: 0.009556696 - KL loss: 0.15721808\n",
            "Epoch: 11 - Step: 17 - MSE loss: 0.009791971 - KL loss: 0.15629342\n",
            "Epoch: 11 - Step: 18 - MSE loss: 0.008630269 - KL loss: 0.14033595\n",
            "Epoch: 11 - Step: 19 - MSE loss: 0.009092348 - KL loss: 0.14769563\n",
            "Epoch: 11 - Step: 20 - MSE loss: 0.009067264 - KL loss: 0.13678616\n",
            "Epoch: 11 - Step: 21 - MSE loss: 0.008406945 - KL loss: 0.13987336\n",
            "Epoch: 11 - Step: 22 - MSE loss: 0.008713706 - KL loss: 0.13223933\n",
            "Epoch: 11 - Step: 23 - MSE loss: 0.008731224 - KL loss: 0.13881256\n",
            "Epoch: 11 - Step: 24 - MSE loss: 0.008512774 - KL loss: 0.12719922\n",
            "Epoch: 11 - Step: 25 - MSE loss: 0.008071988 - KL loss: 0.13616529\n",
            "Epoch: 11 - Step: 26 - MSE loss: 0.008101371 - KL loss: 0.14038056\n",
            "Epoch: 11 - Step: 27 - MSE loss: 0.00875144 - KL loss: 0.1387561\n",
            "Epoch: 11 - Step: 28 - MSE loss: 0.0088782245 - KL loss: 0.14055961\n",
            "Epoch: 11 - Step: 29 - MSE loss: 0.008107328 - KL loss: 0.13695386\n",
            "Epoch: 11 - Step: 30 - MSE loss: 0.007658201 - KL loss: 0.14011355\n",
            "Epoch: 11 - Step: 31 - MSE loss: 0.008070291 - KL loss: 0.13945688\n",
            "Epoch: 11 - Step: 32 - MSE loss: 0.008888774 - KL loss: 0.14736089\n",
            "Epoch: 11 - Step: 33 - MSE loss: 0.009943031 - KL loss: 0.14834747\n",
            "Epoch: 11 - Step: 34 - MSE loss: 0.0115300445 - KL loss: 0.17152101\n",
            "Epoch: 11 - Step: 35 - MSE loss: 0.01123141 - KL loss: 0.17441133\n",
            "Epoch: 11 - Step: 36 - MSE loss: 0.013247781 - KL loss: 0.18360817\n",
            "Epoch: 11 - Step: 37 - MSE loss: 0.01291113 - KL loss: 0.19178757\n",
            "Epoch: 11 - Step: 38 - MSE loss: 0.014026337 - KL loss: 0.19085076\n",
            "Epoch: 11 - Step: 39 - MSE loss: 0.01582472 - KL loss: 0.21051428\n",
            "Epoch: 11 - Step: 40 - MSE loss: 0.015650973 - KL loss: 0.1929796\n",
            "Epoch: 11 - Step: 41 - MSE loss: 0.015101655 - KL loss: 0.19755977\n",
            "Epoch: 11 - Step: 42 - MSE loss: 0.015968332 - KL loss: 0.20988697\n",
            "Epoch: 11 - Step: 43 - MSE loss: 0.014528494 - KL loss: 0.21726638\n",
            "Epoch: 11 - Step: 44 - MSE loss: 0.015001673 - KL loss: 0.23328447\n",
            "Epoch: 11 - Step: 45 - MSE loss: 0.015710535 - KL loss: 0.21258476\n",
            "Epoch: 11 - Step: 46 - MSE loss: 0.01566505 - KL loss: 0.2148587\n",
            "Epoch: 11 - Step: 47 - MSE loss: 0.0152277835 - KL loss: 0.21475795\n",
            "Epoch: 11 - Step: 48 - MSE loss: 0.01637356 - KL loss: 0.22866797\n",
            "Epoch: 11 - Step: 49 - MSE loss: 0.016336909 - KL loss: 0.21138018\n",
            "Epoch: 11 - Step: 50 - MSE loss: 0.018833939 - KL loss: 0.21415226\n",
            "Epoch: 11 - Step: 51 - MSE loss: 0.017123427 - KL loss: 0.21388365\n",
            "Epoch: 11 - Step: 52 - MSE loss: 0.01838606 - KL loss: 0.23118149\n",
            "Epoch: 11 - Step: 53 - MSE loss: 0.018231543 - KL loss: 0.1988869\n",
            "Epoch: 11 - Step: 54 - MSE loss: 0.018495716 - KL loss: 0.2210584\n",
            "Epoch: 11 - Step: 55 - MSE loss: 0.01953235 - KL loss: 0.21445774\n",
            "Epoch: 11 - Step: 56 - MSE loss: 0.018640121 - KL loss: 0.23195839\n",
            "Epoch: 11 - Step: 57 - MSE loss: 0.021323567 - KL loss: 0.20808208\n",
            "Epoch: 11 - Step: 58 - MSE loss: 0.019978957 - KL loss: 0.2123348\n",
            "Epoch: 11 - Step: 59 - MSE loss: 0.020998048 - KL loss: 0.2065005\n",
            "Epoch: 11 - Step: 60 - MSE loss: 0.02070564 - KL loss: 0.23314613\n",
            "Epoch: 11 - Step: 61 - MSE loss: 0.020444205 - KL loss: 0.22083347\n",
            "Epoch: 11 - Step: 62 - MSE loss: 0.020809839 - KL loss: 0.23400605\n",
            "Epoch: 11 - Step: 63 - MSE loss: 0.020610629 - KL loss: 0.21748954\n",
            "Epoch: 11 - Step: 64 - MSE loss: 0.022740932 - KL loss: 0.22075282\n",
            "Epoch: 11 - Step: 65 - MSE loss: 0.020173723 - KL loss: 0.21005666\n",
            "Epoch: 11 - Step: 66 - MSE loss: 0.018210141 - KL loss: 0.21961218\n",
            "Epoch: 11 - Step: 67 - MSE loss: 0.016756536 - KL loss: 0.18105488\n",
            "Epoch: 11 - Step: 68 - MSE loss: 0.015105359 - KL loss: 0.18100192\n",
            "Epoch: 11 - Step: 69 - MSE loss: 0.014957432 - KL loss: 0.19311874\n",
            "Epoch: 11 - Step: 70 - MSE loss: 0.013940059 - KL loss: 0.18725002\n",
            "Epoch: 11 - Step: 71 - MSE loss: 0.012589977 - KL loss: 0.17629522\n",
            "Epoch: 11 - Step: 72 - MSE loss: 0.0126818335 - KL loss: 0.18378928\n",
            "Epoch: 11 - Step: 73 - MSE loss: 0.011221928 - KL loss: 0.16575766\n",
            "Epoch: 11 - Step: 74 - MSE loss: 0.010714785 - KL loss: 0.16460097\n",
            "Epoch: 11 - Step: 75 - MSE loss: 0.009189445 - KL loss: 0.15029061\n",
            "Epoch: 11 - Step: 76 - MSE loss: 0.009019605 - KL loss: 0.16153507\n",
            "Epoch: 11 - Step: 77 - MSE loss: 0.010114889 - KL loss: 0.15540348\n",
            "Epoch: 11 - Step: 78 - MSE loss: 0.010024947 - KL loss: 0.157038\n",
            "Epoch: 11 - Step: 79 - MSE loss: 0.008299588 - KL loss: 0.14415097\n",
            "Epoch: 11 - Step: 80 - MSE loss: 0.009541452 - KL loss: 0.14979848\n",
            "Epoch: 11 - Step: 81 - MSE loss: 0.009213536 - KL loss: 0.14145918\n",
            "Epoch: 11 - Step: 82 - MSE loss: 0.010409514 - KL loss: 0.1421512\n",
            "Epoch: 11 - Step: 83 - MSE loss: 0.009553533 - KL loss: 0.14562026\n",
            "Epoch: 11 - Step: 84 - MSE loss: 0.009701944 - KL loss: 0.14789777\n",
            "Epoch: 11 - Step: 85 - MSE loss: 0.010153331 - KL loss: 0.14637873\n",
            "Epoch: 11 - Step: 86 - MSE loss: 0.009670717 - KL loss: 0.1450629\n",
            "Epoch: 11 - Step: 87 - MSE loss: 0.01107929 - KL loss: 0.14864232\n",
            "Epoch: 11 - Step: 88 - MSE loss: 0.009999891 - KL loss: 0.14679775\n",
            "Epoch: 11 - Step: 89 - MSE loss: 0.009657921 - KL loss: 0.16653538\n",
            "Epoch: 11 - Step: 90 - MSE loss: 0.010306969 - KL loss: 0.15740582\n",
            "Epoch: 11 - Step: 91 - MSE loss: 0.009675893 - KL loss: 0.16798413\n",
            "Epoch: 11 - Step: 92 - MSE loss: 0.0102518555 - KL loss: 0.15549129\n",
            "Epoch: 11 - Step: 93 - MSE loss: 0.009131902 - KL loss: 0.16687533\n",
            "Epoch: 11 - Step: 94 - MSE loss: 0.009419104 - KL loss: 0.1623049\n",
            "Epoch: 11 - Step: 95 - MSE loss: 0.008949489 - KL loss: 0.16200006\n",
            "Epoch: 11 - Step: 96 - MSE loss: 0.009095125 - KL loss: 0.1611273\n",
            "Epoch: 11 - Step: 97 - MSE loss: 0.009306763 - KL loss: 0.14856532\n",
            "Epoch: 11 - Step: 98 - MSE loss: 0.010352667 - KL loss: 0.15598735\n",
            "Epoch: 11 - Step: 99 - MSE loss: 0.0103080375 - KL loss: 0.16779885\n",
            "Epoch: 11 - Step: 100 - MSE loss: 0.010264748 - KL loss: 0.15404934\n",
            "Epoch: 11 - Step: 101 - MSE loss: 0.0096663 - KL loss: 0.14661801\n",
            "Epoch: 11 - Step: 102 - MSE loss: 0.0103340335 - KL loss: 0.14405537\n",
            "Epoch: 11 - Step: 103 - MSE loss: 0.00931543 - KL loss: 0.157002\n",
            "Epoch: 11 - Step: 104 - MSE loss: 0.010866509 - KL loss: 0.16058551\n",
            "Epoch: 11 - Step: 105 - MSE loss: 0.011781223 - KL loss: 0.17557484\n",
            "Epoch: 11 - Step: 106 - MSE loss: 0.012503576 - KL loss: 0.17359847\n",
            "Epoch: 11 - Step: 107 - MSE loss: 0.01506428 - KL loss: 0.19830951\n",
            "Epoch: 11 - Step: 108 - MSE loss: 0.013443419 - KL loss: 0.18984134\n",
            "Epoch: 11 - Step: 109 - MSE loss: 0.01529259 - KL loss: 0.21166444\n",
            "Epoch: 11 - Step: 110 - MSE loss: 0.01635857 - KL loss: 0.21473481\n",
            "Epoch: 11 - Step: 111 - MSE loss: 0.015896082 - KL loss: 0.20470329\n",
            "Epoch: 11 - Step: 112 - MSE loss: 0.016184676 - KL loss: 0.21199287\n",
            "Epoch: 11 - Step: 113 - MSE loss: 0.017673558 - KL loss: 0.21458934\n",
            "Epoch: 11 - Step: 114 - MSE loss: 0.017480696 - KL loss: 0.22154254\n",
            "Epoch: 11 - Step: 115 - MSE loss: 0.017669274 - KL loss: 0.2210477\n",
            "Epoch: 11 - Step: 116 - MSE loss: 0.01794341 - KL loss: 0.22716078\n",
            "Epoch: 11 - Step: 117 - MSE loss: 0.018527133 - KL loss: 0.20961225\n",
            "Epoch: 11 - Step: 118 - MSE loss: 0.018691009 - KL loss: 0.2111285\n",
            "Epoch: 11 - Step: 119 - MSE loss: 0.017549714 - KL loss: 0.2196742\n",
            "Epoch: 11 - Step: 120 - MSE loss: 0.016132247 - KL loss: 0.22491056\n",
            "Epoch: 11 - Step: 121 - MSE loss: 0.017613137 - KL loss: 0.22062162\n",
            "Epoch: 11 - Step: 122 - MSE loss: 0.016758425 - KL loss: 0.2602051\n",
            "Epoch: 11 - Step: 123 - MSE loss: 0.021184033 - KL loss: 0.21064298\n",
            "Epoch: 11 - Step: 124 - MSE loss: 0.02341702 - KL loss: 0.23970494\n",
            "Epoch: 11 - Step: 125 - MSE loss: 0.02190462 - KL loss: 0.17895395\n",
            "Epoch: 11 - Step: 126 - MSE loss: 0.018439986 - KL loss: 0.18713793\n",
            "Epoch: 11 - Step: 127 - MSE loss: 0.01814997 - KL loss: 0.21433762\n",
            "Epoch: 11 - Step: 128 - MSE loss: 0.018431796 - KL loss: 0.21868291\n",
            "Epoch: 11 - Step: 129 - MSE loss: 0.018526768 - KL loss: 0.23968168\n",
            "Epoch: 11 - Step: 130 - MSE loss: 0.017353604 - KL loss: 0.21567121\n",
            "Epoch: 11 - Step: 131 - MSE loss: 0.019258244 - KL loss: 0.25294742\n",
            "Epoch: 11 - Step: 132 - MSE loss: 0.019737909 - KL loss: 0.23284054\n",
            "Epoch: 11 - Step: 133 - MSE loss: 0.020591589 - KL loss: 0.22944239\n",
            "Epoch: 11 - Step: 134 - MSE loss: 0.018745918 - KL loss: 0.22410332\n",
            "Epoch: 11 - Step: 135 - MSE loss: 0.018754633 - KL loss: 0.21605048\n",
            "Epoch: 11 - Step: 136 - MSE loss: 0.01789342 - KL loss: 0.2216141\n",
            "Epoch: 11 - Step: 137 - MSE loss: 0.017165188 - KL loss: 0.21590081\n",
            "Epoch: 11 - Step: 138 - MSE loss: 0.018574012 - KL loss: 0.22128063\n",
            "Epoch: 11 - Step: 139 - MSE loss: 0.018101202 - KL loss: 0.20564243\n",
            "Epoch: 11 - Step: 140 - MSE loss: 0.018546978 - KL loss: 0.2178276\n",
            "Epoch: 11 - Step: 141 - MSE loss: 0.01853902 - KL loss: 0.21421854\n",
            "Epoch: 11 - Step: 142 - MSE loss: 0.018195953 - KL loss: 0.22190142\n",
            "Epoch: 11 - Step: 143 - MSE loss: 0.018335814 - KL loss: 0.21607539\n",
            "Epoch: 11 - Step: 144 - MSE loss: 0.018106828 - KL loss: 0.22119823\n",
            "Epoch:  12\n",
            "Epoch: 12 - Step: 0 - MSE loss: 0.008726356 - KL loss: 0.18749905\n",
            "Epoch: 12 - Step: 1 - MSE loss: 0.009281048 - KL loss: 0.17655313\n",
            "Epoch: 12 - Step: 2 - MSE loss: 0.009711411 - KL loss: 0.17407334\n",
            "Epoch: 12 - Step: 3 - MSE loss: 0.010079184 - KL loss: 0.17737743\n",
            "Epoch: 12 - Step: 4 - MSE loss: 0.00916367 - KL loss: 0.17592835\n",
            "Epoch: 12 - Step: 5 - MSE loss: 0.009086221 - KL loss: 0.16811755\n",
            "Epoch: 12 - Step: 6 - MSE loss: 0.008456779 - KL loss: 0.16363093\n",
            "Epoch: 12 - Step: 7 - MSE loss: 0.009643861 - KL loss: 0.16620263\n",
            "Epoch: 12 - Step: 8 - MSE loss: 0.009525734 - KL loss: 0.16765109\n",
            "Epoch: 12 - Step: 9 - MSE loss: 0.010716085 - KL loss: 0.15769637\n",
            "Epoch: 12 - Step: 10 - MSE loss: 0.009649838 - KL loss: 0.15616661\n",
            "Epoch: 12 - Step: 11 - MSE loss: 0.009697686 - KL loss: 0.16457933\n",
            "Epoch: 12 - Step: 12 - MSE loss: 0.009395751 - KL loss: 0.15696914\n",
            "Epoch: 12 - Step: 13 - MSE loss: 0.010155083 - KL loss: 0.14264685\n",
            "Epoch: 12 - Step: 14 - MSE loss: 0.009820518 - KL loss: 0.15108404\n",
            "Epoch: 12 - Step: 15 - MSE loss: 0.009675485 - KL loss: 0.15810172\n",
            "Epoch: 12 - Step: 16 - MSE loss: 0.009186673 - KL loss: 0.15531915\n",
            "Epoch: 12 - Step: 17 - MSE loss: 0.0090904245 - KL loss: 0.15332726\n",
            "Epoch: 12 - Step: 18 - MSE loss: 0.008191954 - KL loss: 0.14739266\n",
            "Epoch: 12 - Step: 19 - MSE loss: 0.007859673 - KL loss: 0.14440215\n",
            "Epoch: 12 - Step: 20 - MSE loss: 0.008547463 - KL loss: 0.1455858\n",
            "Epoch: 12 - Step: 21 - MSE loss: 0.0081255 - KL loss: 0.13644065\n",
            "Epoch: 12 - Step: 22 - MSE loss: 0.008606424 - KL loss: 0.1339432\n",
            "Epoch: 12 - Step: 23 - MSE loss: 0.008563324 - KL loss: 0.14065073\n",
            "Epoch: 12 - Step: 24 - MSE loss: 0.008695162 - KL loss: 0.14133024\n",
            "Epoch: 12 - Step: 25 - MSE loss: 0.007828684 - KL loss: 0.13883114\n",
            "Epoch: 12 - Step: 26 - MSE loss: 0.007779691 - KL loss: 0.1331031\n",
            "Epoch: 12 - Step: 27 - MSE loss: 0.008027864 - KL loss: 0.12898147\n",
            "Epoch: 12 - Step: 28 - MSE loss: 0.00923342 - KL loss: 0.1279794\n",
            "Epoch: 12 - Step: 29 - MSE loss: 0.008581499 - KL loss: 0.13408852\n",
            "Epoch: 12 - Step: 30 - MSE loss: 0.0076700444 - KL loss: 0.13084042\n",
            "Epoch: 12 - Step: 31 - MSE loss: 0.007798938 - KL loss: 0.13226703\n",
            "Epoch: 12 - Step: 32 - MSE loss: 0.009909066 - KL loss: 0.15147771\n",
            "Epoch: 12 - Step: 33 - MSE loss: 0.009645387 - KL loss: 0.15170886\n",
            "Epoch: 12 - Step: 34 - MSE loss: 0.01016738 - KL loss: 0.16650055\n",
            "Epoch: 12 - Step: 35 - MSE loss: 0.010354065 - KL loss: 0.17342798\n",
            "Epoch: 12 - Step: 36 - MSE loss: 0.012340389 - KL loss: 0.17642105\n",
            "Epoch: 12 - Step: 37 - MSE loss: 0.014244783 - KL loss: 0.20679697\n",
            "Epoch: 12 - Step: 38 - MSE loss: 0.012733313 - KL loss: 0.19096267\n",
            "Epoch: 12 - Step: 39 - MSE loss: 0.014476153 - KL loss: 0.19497465\n",
            "Epoch: 12 - Step: 40 - MSE loss: 0.014516432 - KL loss: 0.19449554\n",
            "Epoch: 12 - Step: 41 - MSE loss: 0.014230258 - KL loss: 0.20819826\n",
            "Epoch: 12 - Step: 42 - MSE loss: 0.013637956 - KL loss: 0.20553528\n",
            "Epoch: 12 - Step: 43 - MSE loss: 0.013048727 - KL loss: 0.21667752\n",
            "Epoch: 12 - Step: 44 - MSE loss: 0.013916464 - KL loss: 0.22020774\n",
            "Epoch: 12 - Step: 45 - MSE loss: 0.014834874 - KL loss: 0.19884107\n",
            "Epoch: 12 - Step: 46 - MSE loss: 0.014492378 - KL loss: 0.21856087\n",
            "Epoch: 12 - Step: 47 - MSE loss: 0.015388139 - KL loss: 0.21346691\n",
            "Epoch: 12 - Step: 48 - MSE loss: 0.017071942 - KL loss: 0.21001738\n",
            "Epoch: 12 - Step: 49 - MSE loss: 0.016689261 - KL loss: 0.21848878\n",
            "Epoch: 12 - Step: 50 - MSE loss: 0.017785167 - KL loss: 0.24068591\n",
            "Epoch: 12 - Step: 51 - MSE loss: 0.019397736 - KL loss: 0.2096495\n",
            "Epoch: 12 - Step: 52 - MSE loss: 0.018624624 - KL loss: 0.22696832\n",
            "Epoch: 12 - Step: 53 - MSE loss: 0.01699604 - KL loss: 0.20052184\n",
            "Epoch: 12 - Step: 54 - MSE loss: 0.018447112 - KL loss: 0.21323341\n",
            "Epoch: 12 - Step: 55 - MSE loss: 0.017876843 - KL loss: 0.20822354\n",
            "Epoch: 12 - Step: 56 - MSE loss: 0.01777909 - KL loss: 0.2127364\n",
            "Epoch: 12 - Step: 57 - MSE loss: 0.018175675 - KL loss: 0.21374348\n",
            "Epoch: 12 - Step: 58 - MSE loss: 0.018133385 - KL loss: 0.22399393\n",
            "Epoch: 12 - Step: 59 - MSE loss: 0.020323368 - KL loss: 0.2198406\n",
            "Epoch: 12 - Step: 60 - MSE loss: 0.017452504 - KL loss: 0.22968476\n",
            "Epoch: 12 - Step: 61 - MSE loss: 0.018519638 - KL loss: 0.21941502\n",
            "Epoch: 12 - Step: 62 - MSE loss: 0.018922137 - KL loss: 0.23091519\n",
            "Epoch: 12 - Step: 63 - MSE loss: 0.018859008 - KL loss: 0.215023\n",
            "Epoch: 12 - Step: 64 - MSE loss: 0.019442486 - KL loss: 0.22119623\n",
            "Epoch: 12 - Step: 65 - MSE loss: 0.02032171 - KL loss: 0.21653253\n",
            "Epoch: 12 - Step: 66 - MSE loss: 0.018964082 - KL loss: 0.22384179\n",
            "Epoch: 12 - Step: 67 - MSE loss: 0.017270092 - KL loss: 0.18540153\n",
            "Epoch: 12 - Step: 68 - MSE loss: 0.016781887 - KL loss: 0.19913757\n",
            "Epoch: 12 - Step: 69 - MSE loss: 0.014675737 - KL loss: 0.18000337\n",
            "Epoch: 12 - Step: 70 - MSE loss: 0.012858034 - KL loss: 0.17026913\n",
            "Epoch: 12 - Step: 71 - MSE loss: 0.012816533 - KL loss: 0.17830676\n",
            "Epoch: 12 - Step: 72 - MSE loss: 0.01260106 - KL loss: 0.16938192\n",
            "Epoch: 12 - Step: 73 - MSE loss: 0.009844062 - KL loss: 0.1572819\n",
            "Epoch: 12 - Step: 74 - MSE loss: 0.0103992345 - KL loss: 0.16365871\n",
            "Epoch: 12 - Step: 75 - MSE loss: 0.009779775 - KL loss: 0.15603977\n",
            "Epoch: 12 - Step: 76 - MSE loss: 0.00872738 - KL loss: 0.14061643\n",
            "Epoch: 12 - Step: 77 - MSE loss: 0.008832748 - KL loss: 0.13716471\n",
            "Epoch: 12 - Step: 78 - MSE loss: 0.008826104 - KL loss: 0.14137727\n",
            "Epoch: 12 - Step: 79 - MSE loss: 0.0091129495 - KL loss: 0.14835447\n",
            "Epoch: 12 - Step: 80 - MSE loss: 0.008742359 - KL loss: 0.14819208\n",
            "Epoch: 12 - Step: 81 - MSE loss: 0.009195149 - KL loss: 0.14983262\n",
            "Epoch: 12 - Step: 82 - MSE loss: 0.009057847 - KL loss: 0.14482298\n",
            "Epoch: 12 - Step: 83 - MSE loss: 0.008910193 - KL loss: 0.14035231\n",
            "Epoch: 12 - Step: 84 - MSE loss: 0.008742672 - KL loss: 0.14492899\n",
            "Epoch: 12 - Step: 85 - MSE loss: 0.00928588 - KL loss: 0.15888831\n",
            "Epoch: 12 - Step: 86 - MSE loss: 0.009470486 - KL loss: 0.15425868\n",
            "Epoch: 12 - Step: 87 - MSE loss: 0.009617112 - KL loss: 0.16298974\n",
            "Epoch: 12 - Step: 88 - MSE loss: 0.009688153 - KL loss: 0.16187014\n",
            "Epoch: 12 - Step: 89 - MSE loss: 0.009451985 - KL loss: 0.15643847\n",
            "Epoch: 12 - Step: 90 - MSE loss: 0.010447648 - KL loss: 0.16103612\n",
            "Epoch: 12 - Step: 91 - MSE loss: 0.009013329 - KL loss: 0.1623029\n",
            "Epoch: 12 - Step: 92 - MSE loss: 0.008963172 - KL loss: 0.14859302\n",
            "Epoch: 12 - Step: 93 - MSE loss: 0.008600812 - KL loss: 0.14679036\n",
            "Epoch: 12 - Step: 94 - MSE loss: 0.009130237 - KL loss: 0.15573186\n",
            "Epoch: 12 - Step: 95 - MSE loss: 0.009722388 - KL loss: 0.15271384\n",
            "Epoch: 12 - Step: 96 - MSE loss: 0.009508808 - KL loss: 0.16632608\n",
            "Epoch: 12 - Step: 97 - MSE loss: 0.008198858 - KL loss: 0.15898958\n",
            "Epoch: 12 - Step: 98 - MSE loss: 0.009255267 - KL loss: 0.15915534\n",
            "Epoch: 12 - Step: 99 - MSE loss: 0.009148004 - KL loss: 0.1659182\n",
            "Epoch: 12 - Step: 100 - MSE loss: 0.009431484 - KL loss: 0.1506964\n",
            "Epoch: 12 - Step: 101 - MSE loss: 0.00870266 - KL loss: 0.1609091\n",
            "Epoch: 12 - Step: 102 - MSE loss: 0.009423893 - KL loss: 0.16236877\n",
            "Epoch: 12 - Step: 103 - MSE loss: 0.008923712 - KL loss: 0.16777113\n",
            "Epoch: 12 - Step: 104 - MSE loss: 0.010670733 - KL loss: 0.16894937\n",
            "Epoch: 12 - Step: 105 - MSE loss: 0.01135976 - KL loss: 0.185301\n",
            "Epoch: 12 - Step: 106 - MSE loss: 0.012204724 - KL loss: 0.18462726\n",
            "Epoch: 12 - Step: 107 - MSE loss: 0.012620305 - KL loss: 0.17497085\n",
            "Epoch: 12 - Step: 108 - MSE loss: 0.012607646 - KL loss: 0.18732393\n",
            "Epoch: 12 - Step: 109 - MSE loss: 0.0146976 - KL loss: 0.20295107\n",
            "Epoch: 12 - Step: 110 - MSE loss: 0.014087796 - KL loss: 0.19731823\n",
            "Epoch: 12 - Step: 111 - MSE loss: 0.01614195 - KL loss: 0.19758756\n",
            "Epoch: 12 - Step: 112 - MSE loss: 0.016057925 - KL loss: 0.21449432\n",
            "Epoch: 12 - Step: 113 - MSE loss: 0.016482772 - KL loss: 0.21290831\n",
            "Epoch: 12 - Step: 114 - MSE loss: 0.016961465 - KL loss: 0.21687362\n",
            "Epoch: 12 - Step: 115 - MSE loss: 0.016120937 - KL loss: 0.23398742\n",
            "Epoch: 12 - Step: 116 - MSE loss: 0.019283647 - KL loss: 0.20653343\n",
            "Epoch: 12 - Step: 117 - MSE loss: 0.020422094 - KL loss: 0.2247255\n",
            "Epoch: 12 - Step: 118 - MSE loss: 0.02120114 - KL loss: 0.18287641\n",
            "Epoch: 12 - Step: 119 - MSE loss: 0.01905475 - KL loss: 0.2078056\n",
            "Epoch: 12 - Step: 120 - MSE loss: 0.01683862 - KL loss: 0.22341761\n",
            "Epoch: 12 - Step: 121 - MSE loss: 0.017023899 - KL loss: 0.23525557\n",
            "Epoch: 12 - Step: 122 - MSE loss: 0.015427168 - KL loss: 0.21588103\n",
            "Epoch: 12 - Step: 123 - MSE loss: 0.0146737285 - KL loss: 0.23088643\n",
            "Epoch: 12 - Step: 124 - MSE loss: 0.017057827 - KL loss: 0.22499244\n",
            "Epoch: 12 - Step: 125 - MSE loss: 0.016046235 - KL loss: 0.23675436\n",
            "Epoch: 12 - Step: 126 - MSE loss: 0.015824495 - KL loss: 0.2316527\n",
            "Epoch: 12 - Step: 127 - MSE loss: 0.015897984 - KL loss: 0.23307085\n",
            "Epoch: 12 - Step: 128 - MSE loss: 0.015254591 - KL loss: 0.2192322\n",
            "Epoch: 12 - Step: 129 - MSE loss: 0.015862444 - KL loss: 0.22524062\n",
            "Epoch: 12 - Step: 130 - MSE loss: 0.017203059 - KL loss: 0.22783053\n",
            "Epoch: 12 - Step: 131 - MSE loss: 0.017489443 - KL loss: 0.23796722\n",
            "Epoch: 12 - Step: 132 - MSE loss: 0.02025254 - KL loss: 0.21430138\n",
            "Epoch: 12 - Step: 133 - MSE loss: 0.021778526 - KL loss: 0.23506626\n",
            "Epoch: 12 - Step: 134 - MSE loss: 0.02656961 - KL loss: 0.18996896\n",
            "Epoch: 12 - Step: 135 - MSE loss: 0.024109637 - KL loss: 0.22344398\n",
            "Epoch: 12 - Step: 136 - MSE loss: 0.021110212 - KL loss: 0.20309699\n",
            "Epoch: 12 - Step: 137 - MSE loss: 0.019079639 - KL loss: 0.21712944\n",
            "Epoch: 12 - Step: 138 - MSE loss: 0.01973489 - KL loss: 0.22478232\n",
            "Epoch: 12 - Step: 139 - MSE loss: 0.019816654 - KL loss: 0.19737908\n",
            "Epoch: 12 - Step: 140 - MSE loss: 0.018287199 - KL loss: 0.20343104\n",
            "Epoch: 12 - Step: 141 - MSE loss: 0.016854921 - KL loss: 0.2041311\n",
            "Epoch: 12 - Step: 142 - MSE loss: 0.017614212 - KL loss: 0.21472923\n",
            "Epoch: 12 - Step: 143 - MSE loss: 0.017450875 - KL loss: 0.22031085\n",
            "Epoch: 12 - Step: 144 - MSE loss: 0.016804364 - KL loss: 0.22468327\n",
            "Epoch:  13\n",
            "Epoch: 13 - Step: 0 - MSE loss: 0.0083119 - KL loss: 0.17174788\n",
            "Epoch: 13 - Step: 1 - MSE loss: 0.008240917 - KL loss: 0.18184994\n",
            "Epoch: 13 - Step: 2 - MSE loss: 0.009803206 - KL loss: 0.1773951\n",
            "Epoch: 13 - Step: 3 - MSE loss: 0.008908749 - KL loss: 0.17988887\n",
            "Epoch: 13 - Step: 4 - MSE loss: 0.008492171 - KL loss: 0.16940483\n",
            "Epoch: 13 - Step: 5 - MSE loss: 0.008879831 - KL loss: 0.15925434\n",
            "Epoch: 13 - Step: 6 - MSE loss: 0.0086899595 - KL loss: 0.16140473\n",
            "Epoch: 13 - Step: 7 - MSE loss: 0.009219777 - KL loss: 0.16557868\n",
            "Epoch: 13 - Step: 8 - MSE loss: 0.009641886 - KL loss: 0.15669361\n",
            "Epoch: 13 - Step: 9 - MSE loss: 0.009276425 - KL loss: 0.15614843\n",
            "Epoch: 13 - Step: 10 - MSE loss: 0.00947765 - KL loss: 0.15339978\n",
            "Epoch: 13 - Step: 11 - MSE loss: 0.009004199 - KL loss: 0.15156326\n",
            "Epoch: 13 - Step: 12 - MSE loss: 0.0088366605 - KL loss: 0.15486452\n",
            "Epoch: 13 - Step: 13 - MSE loss: 0.008734187 - KL loss: 0.15552211\n",
            "Epoch: 13 - Step: 14 - MSE loss: 0.009894663 - KL loss: 0.1521683\n",
            "Epoch: 13 - Step: 15 - MSE loss: 0.009525011 - KL loss: 0.16205427\n",
            "Epoch: 13 - Step: 16 - MSE loss: 0.009709084 - KL loss: 0.15159826\n",
            "Epoch: 13 - Step: 17 - MSE loss: 0.009312879 - KL loss: 0.14784902\n",
            "Epoch: 13 - Step: 18 - MSE loss: 0.009286287 - KL loss: 0.14778991\n",
            "Epoch: 13 - Step: 19 - MSE loss: 0.008335724 - KL loss: 0.13717885\n",
            "Epoch: 13 - Step: 20 - MSE loss: 0.008136251 - KL loss: 0.13783732\n",
            "Epoch: 13 - Step: 21 - MSE loss: 0.007817551 - KL loss: 0.13305318\n",
            "Epoch: 13 - Step: 22 - MSE loss: 0.008100705 - KL loss: 0.1263662\n",
            "Epoch: 13 - Step: 23 - MSE loss: 0.00808623 - KL loss: 0.13062435\n",
            "Epoch: 13 - Step: 24 - MSE loss: 0.008740086 - KL loss: 0.14157966\n",
            "Epoch: 13 - Step: 25 - MSE loss: 0.0075687617 - KL loss: 0.1393767\n",
            "Epoch: 13 - Step: 26 - MSE loss: 0.00793858 - KL loss: 0.14366704\n",
            "Epoch: 13 - Step: 27 - MSE loss: 0.007944388 - KL loss: 0.13681544\n",
            "Epoch: 13 - Step: 28 - MSE loss: 0.008149828 - KL loss: 0.13520674\n",
            "Epoch: 13 - Step: 29 - MSE loss: 0.0077506225 - KL loss: 0.13385464\n",
            "Epoch: 13 - Step: 30 - MSE loss: 0.007794976 - KL loss: 0.1310157\n",
            "Epoch: 13 - Step: 31 - MSE loss: 0.0075546107 - KL loss: 0.13560468\n",
            "Epoch: 13 - Step: 32 - MSE loss: 0.009486335 - KL loss: 0.14729768\n",
            "Epoch: 13 - Step: 33 - MSE loss: 0.009273722 - KL loss: 0.15592882\n",
            "Epoch: 13 - Step: 34 - MSE loss: 0.00945245 - KL loss: 0.16763599\n",
            "Epoch: 13 - Step: 35 - MSE loss: 0.010342714 - KL loss: 0.16285007\n",
            "Epoch: 13 - Step: 36 - MSE loss: 0.011929938 - KL loss: 0.17373341\n",
            "Epoch: 13 - Step: 37 - MSE loss: 0.01313956 - KL loss: 0.1948027\n",
            "Epoch: 13 - Step: 38 - MSE loss: 0.0134221725 - KL loss: 0.20494309\n",
            "Epoch: 13 - Step: 39 - MSE loss: 0.013338921 - KL loss: 0.21188265\n",
            "Epoch: 13 - Step: 40 - MSE loss: 0.013751657 - KL loss: 0.1938023\n",
            "Epoch: 13 - Step: 41 - MSE loss: 0.013298179 - KL loss: 0.2117083\n",
            "Epoch: 13 - Step: 42 - MSE loss: 0.012533091 - KL loss: 0.20904726\n",
            "Epoch: 13 - Step: 43 - MSE loss: 0.014378983 - KL loss: 0.21268624\n",
            "Epoch: 13 - Step: 44 - MSE loss: 0.013902019 - KL loss: 0.21369377\n",
            "Epoch: 13 - Step: 45 - MSE loss: 0.013856347 - KL loss: 0.2246641\n",
            "Epoch: 13 - Step: 46 - MSE loss: 0.014630177 - KL loss: 0.2217398\n",
            "Epoch: 13 - Step: 47 - MSE loss: 0.01631608 - KL loss: 0.22104494\n",
            "Epoch: 13 - Step: 48 - MSE loss: 0.015175746 - KL loss: 0.2166832\n",
            "Epoch: 13 - Step: 49 - MSE loss: 0.0147307785 - KL loss: 0.21427263\n",
            "Epoch: 13 - Step: 50 - MSE loss: 0.014575716 - KL loss: 0.20526621\n",
            "Epoch: 13 - Step: 51 - MSE loss: 0.01666493 - KL loss: 0.22511162\n",
            "Epoch: 13 - Step: 52 - MSE loss: 0.015277402 - KL loss: 0.22471341\n",
            "Epoch: 13 - Step: 53 - MSE loss: 0.016386548 - KL loss: 0.22453679\n",
            "Epoch: 13 - Step: 54 - MSE loss: 0.01619356 - KL loss: 0.2232507\n",
            "Epoch: 13 - Step: 55 - MSE loss: 0.018208615 - KL loss: 0.2169177\n",
            "Epoch: 13 - Step: 56 - MSE loss: 0.01695155 - KL loss: 0.21288808\n",
            "Epoch: 13 - Step: 57 - MSE loss: 0.017506542 - KL loss: 0.21576202\n",
            "Epoch: 13 - Step: 58 - MSE loss: 0.016425503 - KL loss: 0.21474662\n",
            "Epoch: 13 - Step: 59 - MSE loss: 0.018149944 - KL loss: 0.22060227\n",
            "Epoch: 13 - Step: 60 - MSE loss: 0.017787268 - KL loss: 0.23640421\n",
            "Epoch: 13 - Step: 61 - MSE loss: 0.018668644 - KL loss: 0.2262306\n",
            "Epoch: 13 - Step: 62 - MSE loss: 0.016930997 - KL loss: 0.21754399\n",
            "Epoch: 13 - Step: 63 - MSE loss: 0.0177149 - KL loss: 0.22470799\n",
            "Epoch: 13 - Step: 64 - MSE loss: 0.018689651 - KL loss: 0.24709675\n",
            "Epoch: 13 - Step: 65 - MSE loss: 0.018563047 - KL loss: 0.21181192\n",
            "Epoch: 13 - Step: 66 - MSE loss: 0.01835893 - KL loss: 0.2108595\n",
            "Epoch: 13 - Step: 67 - MSE loss: 0.017654043 - KL loss: 0.17923895\n",
            "Epoch: 13 - Step: 68 - MSE loss: 0.015382096 - KL loss: 0.18361822\n",
            "Epoch: 13 - Step: 69 - MSE loss: 0.013651005 - KL loss: 0.16786772\n",
            "Epoch: 13 - Step: 70 - MSE loss: 0.014043399 - KL loss: 0.17915767\n",
            "Epoch: 13 - Step: 71 - MSE loss: 0.010912542 - KL loss: 0.15308172\n",
            "Epoch: 13 - Step: 72 - MSE loss: 0.01084065 - KL loss: 0.16702202\n",
            "Epoch: 13 - Step: 73 - MSE loss: 0.010710674 - KL loss: 0.17630875\n",
            "Epoch: 13 - Step: 74 - MSE loss: 0.008602847 - KL loss: 0.15255508\n",
            "Epoch: 13 - Step: 75 - MSE loss: 0.009510158 - KL loss: 0.1519309\n",
            "Epoch: 13 - Step: 76 - MSE loss: 0.007988401 - KL loss: 0.15027589\n",
            "Epoch: 13 - Step: 77 - MSE loss: 0.01037128 - KL loss: 0.1542328\n",
            "Epoch: 13 - Step: 78 - MSE loss: 0.0097972825 - KL loss: 0.14796226\n",
            "Epoch: 13 - Step: 79 - MSE loss: 0.008738303 - KL loss: 0.14710435\n",
            "Epoch: 13 - Step: 80 - MSE loss: 0.008522791 - KL loss: 0.13817185\n",
            "Epoch: 13 - Step: 81 - MSE loss: 0.0090191 - KL loss: 0.14910053\n",
            "Epoch: 13 - Step: 82 - MSE loss: 0.008650936 - KL loss: 0.13616237\n",
            "Epoch: 13 - Step: 83 - MSE loss: 0.008893136 - KL loss: 0.15480536\n",
            "Epoch: 13 - Step: 84 - MSE loss: 0.008480582 - KL loss: 0.15531433\n",
            "Epoch: 13 - Step: 85 - MSE loss: 0.008489897 - KL loss: 0.1492959\n",
            "Epoch: 13 - Step: 86 - MSE loss: 0.008572356 - KL loss: 0.14581978\n",
            "Epoch: 13 - Step: 87 - MSE loss: 0.008678466 - KL loss: 0.14511561\n",
            "Epoch: 13 - Step: 88 - MSE loss: 0.008890765 - KL loss: 0.14747939\n",
            "Epoch: 13 - Step: 89 - MSE loss: 0.009893893 - KL loss: 0.1596264\n",
            "Epoch: 13 - Step: 90 - MSE loss: 0.0093643395 - KL loss: 0.16643816\n",
            "Epoch: 13 - Step: 91 - MSE loss: 0.009148136 - KL loss: 0.16064265\n",
            "Epoch: 13 - Step: 92 - MSE loss: 0.00881328 - KL loss: 0.15351644\n",
            "Epoch: 13 - Step: 93 - MSE loss: 0.008979029 - KL loss: 0.16036639\n",
            "Epoch: 13 - Step: 94 - MSE loss: 0.008979466 - KL loss: 0.15829787\n",
            "Epoch: 13 - Step: 95 - MSE loss: 0.008616828 - KL loss: 0.15329719\n",
            "Epoch: 13 - Step: 96 - MSE loss: 0.008997642 - KL loss: 0.15333533\n",
            "Epoch: 13 - Step: 97 - MSE loss: 0.008818512 - KL loss: 0.15650204\n",
            "Epoch: 13 - Step: 98 - MSE loss: 0.009534952 - KL loss: 0.15049969\n",
            "Epoch: 13 - Step: 99 - MSE loss: 0.009360629 - KL loss: 0.1568866\n",
            "Epoch: 13 - Step: 100 - MSE loss: 0.010967396 - KL loss: 0.16511087\n",
            "Epoch: 13 - Step: 101 - MSE loss: 0.011028215 - KL loss: 0.14002515\n",
            "Epoch: 13 - Step: 102 - MSE loss: 0.0112563195 - KL loss: 0.14173311\n",
            "Epoch: 13 - Step: 103 - MSE loss: 0.01101495 - KL loss: 0.15099004\n",
            "Epoch: 13 - Step: 104 - MSE loss: 0.009735285 - KL loss: 0.1615659\n",
            "Epoch: 13 - Step: 105 - MSE loss: 0.01009192 - KL loss: 0.17485952\n",
            "Epoch: 13 - Step: 106 - MSE loss: 0.011963169 - KL loss: 0.18037981\n",
            "Epoch: 13 - Step: 107 - MSE loss: 0.012288009 - KL loss: 0.18047878\n",
            "Epoch: 13 - Step: 108 - MSE loss: 0.012936813 - KL loss: 0.18671086\n",
            "Epoch: 13 - Step: 109 - MSE loss: 0.014989334 - KL loss: 0.20652795\n",
            "Epoch: 13 - Step: 110 - MSE loss: 0.013244495 - KL loss: 0.19350725\n",
            "Epoch: 13 - Step: 111 - MSE loss: 0.01586946 - KL loss: 0.21841744\n",
            "Epoch: 13 - Step: 112 - MSE loss: 0.01653127 - KL loss: 0.21032248\n",
            "Epoch: 13 - Step: 113 - MSE loss: 0.015924692 - KL loss: 0.22661065\n",
            "Epoch: 13 - Step: 114 - MSE loss: 0.01512682 - KL loss: 0.22894526\n",
            "Epoch: 13 - Step: 115 - MSE loss: 0.015023411 - KL loss: 0.20808783\n",
            "Epoch: 13 - Step: 116 - MSE loss: 0.016768953 - KL loss: 0.22915268\n",
            "Epoch: 13 - Step: 117 - MSE loss: 0.01738537 - KL loss: 0.20887177\n",
            "Epoch: 13 - Step: 118 - MSE loss: 0.018132327 - KL loss: 0.21162951\n",
            "Epoch: 13 - Step: 119 - MSE loss: 0.01610873 - KL loss: 0.20636413\n",
            "Epoch: 13 - Step: 120 - MSE loss: 0.016069802 - KL loss: 0.23967063\n",
            "Epoch: 13 - Step: 121 - MSE loss: 0.016533611 - KL loss: 0.21584332\n",
            "Epoch: 13 - Step: 122 - MSE loss: 0.016823445 - KL loss: 0.22697076\n",
            "Epoch: 13 - Step: 123 - MSE loss: 0.01618409 - KL loss: 0.21021593\n",
            "Epoch: 13 - Step: 124 - MSE loss: 0.015673824 - KL loss: 0.22156617\n",
            "Epoch: 13 - Step: 125 - MSE loss: 0.014749861 - KL loss: 0.211824\n",
            "Epoch: 13 - Step: 126 - MSE loss: 0.016057156 - KL loss: 0.23509969\n",
            "Epoch: 13 - Step: 127 - MSE loss: 0.016549457 - KL loss: 0.22515416\n",
            "Epoch: 13 - Step: 128 - MSE loss: 0.0144760795 - KL loss: 0.21658139\n",
            "Epoch: 13 - Step: 129 - MSE loss: 0.0151650235 - KL loss: 0.22165856\n",
            "Epoch: 13 - Step: 130 - MSE loss: 0.015724326 - KL loss: 0.2318457\n",
            "Epoch: 13 - Step: 131 - MSE loss: 0.015546168 - KL loss: 0.24145128\n",
            "Epoch: 13 - Step: 132 - MSE loss: 0.016682932 - KL loss: 0.2311029\n",
            "Epoch: 13 - Step: 133 - MSE loss: 0.016687676 - KL loss: 0.23571211\n",
            "Epoch: 13 - Step: 134 - MSE loss: 0.016408611 - KL loss: 0.22344945\n",
            "Epoch: 13 - Step: 135 - MSE loss: 0.016581232 - KL loss: 0.22038135\n",
            "Epoch: 13 - Step: 136 - MSE loss: 0.016101252 - KL loss: 0.217147\n",
            "Epoch: 13 - Step: 137 - MSE loss: 0.0157406 - KL loss: 0.20767044\n",
            "Epoch: 13 - Step: 138 - MSE loss: 0.016366268 - KL loss: 0.21649693\n",
            "Epoch: 13 - Step: 139 - MSE loss: 0.017111076 - KL loss: 0.21295202\n",
            "Epoch: 13 - Step: 140 - MSE loss: 0.016765606 - KL loss: 0.21331516\n",
            "Epoch: 13 - Step: 141 - MSE loss: 0.02037875 - KL loss: 0.20241311\n",
            "Epoch: 13 - Step: 142 - MSE loss: 0.021369897 - KL loss: 0.2113426\n",
            "Epoch: 13 - Step: 143 - MSE loss: 0.022277853 - KL loss: 0.18878996\n",
            "Epoch: 13 - Step: 144 - MSE loss: 0.020917965 - KL loss: 0.20375907\n",
            "Epoch:  14\n",
            "Epoch: 14 - Step: 0 - MSE loss: 0.008921024 - KL loss: 0.14594285\n",
            "Epoch: 14 - Step: 1 - MSE loss: 0.008550628 - KL loss: 0.17238182\n",
            "Epoch: 14 - Step: 2 - MSE loss: 0.008727039 - KL loss: 0.17954776\n",
            "Epoch: 14 - Step: 3 - MSE loss: 0.008462029 - KL loss: 0.17488676\n",
            "Epoch: 14 - Step: 4 - MSE loss: 0.008663339 - KL loss: 0.1666287\n",
            "Epoch: 14 - Step: 5 - MSE loss: 0.009263652 - KL loss: 0.1692571\n",
            "Epoch: 14 - Step: 6 - MSE loss: 0.008468774 - KL loss: 0.15508638\n",
            "Epoch: 14 - Step: 7 - MSE loss: 0.009603159 - KL loss: 0.15185882\n",
            "Epoch: 14 - Step: 8 - MSE loss: 0.00919891 - KL loss: 0.16052395\n",
            "Epoch: 14 - Step: 9 - MSE loss: 0.009621958 - KL loss: 0.15005717\n",
            "Epoch: 14 - Step: 10 - MSE loss: 0.009232093 - KL loss: 0.15061334\n",
            "Epoch: 14 - Step: 11 - MSE loss: 0.008549813 - KL loss: 0.15154985\n",
            "Epoch: 14 - Step: 12 - MSE loss: 0.008907651 - KL loss: 0.15149531\n",
            "Epoch: 14 - Step: 13 - MSE loss: 0.009167594 - KL loss: 0.15233561\n",
            "Epoch: 14 - Step: 14 - MSE loss: 0.009264792 - KL loss: 0.15010968\n",
            "Epoch: 14 - Step: 15 - MSE loss: 0.00920323 - KL loss: 0.15058486\n",
            "Epoch: 14 - Step: 16 - MSE loss: 0.008938554 - KL loss: 0.1459653\n",
            "Epoch: 14 - Step: 17 - MSE loss: 0.008504712 - KL loss: 0.1421369\n",
            "Epoch: 14 - Step: 18 - MSE loss: 0.007938773 - KL loss: 0.13844003\n",
            "Epoch: 14 - Step: 19 - MSE loss: 0.0074718143 - KL loss: 0.1406782\n",
            "Epoch: 14 - Step: 20 - MSE loss: 0.0075669754 - KL loss: 0.13439174\n",
            "Epoch: 14 - Step: 21 - MSE loss: 0.0074518234 - KL loss: 0.13351426\n",
            "Epoch: 14 - Step: 22 - MSE loss: 0.00810534 - KL loss: 0.14215869\n",
            "Epoch: 14 - Step: 23 - MSE loss: 0.0076745027 - KL loss: 0.13882816\n",
            "Epoch: 14 - Step: 24 - MSE loss: 0.0078063584 - KL loss: 0.13757779\n",
            "Epoch: 14 - Step: 25 - MSE loss: 0.0074900095 - KL loss: 0.13695654\n",
            "Epoch: 14 - Step: 26 - MSE loss: 0.007243469 - KL loss: 0.13362208\n",
            "Epoch: 14 - Step: 27 - MSE loss: 0.007933843 - KL loss: 0.13117754\n",
            "Epoch: 14 - Step: 28 - MSE loss: 0.008518738 - KL loss: 0.13313761\n",
            "Epoch: 14 - Step: 29 - MSE loss: 0.0071549136 - KL loss: 0.13278246\n",
            "Epoch: 14 - Step: 30 - MSE loss: 0.0070310533 - KL loss: 0.13692692\n",
            "Epoch: 14 - Step: 31 - MSE loss: 0.007293634 - KL loss: 0.13544667\n",
            "Epoch: 14 - Step: 32 - MSE loss: 0.008870139 - KL loss: 0.14891395\n",
            "Epoch: 14 - Step: 33 - MSE loss: 0.008890014 - KL loss: 0.14432126\n",
            "Epoch: 14 - Step: 34 - MSE loss: 0.0095125 - KL loss: 0.15953253\n",
            "Epoch: 14 - Step: 35 - MSE loss: 0.0106350975 - KL loss: 0.17312115\n",
            "Epoch: 14 - Step: 36 - MSE loss: 0.011181156 - KL loss: 0.18017344\n",
            "Epoch: 14 - Step: 37 - MSE loss: 0.012509268 - KL loss: 0.18838353\n",
            "Epoch: 14 - Step: 38 - MSE loss: 0.012730836 - KL loss: 0.19247472\n",
            "Epoch: 14 - Step: 39 - MSE loss: 0.013968021 - KL loss: 0.1940058\n",
            "Epoch: 14 - Step: 40 - MSE loss: 0.014643363 - KL loss: 0.20434898\n",
            "Epoch: 14 - Step: 41 - MSE loss: 0.013420875 - KL loss: 0.19110295\n",
            "Epoch: 14 - Step: 42 - MSE loss: 0.013338312 - KL loss: 0.21615502\n",
            "Epoch: 14 - Step: 43 - MSE loss: 0.013198215 - KL loss: 0.22354223\n",
            "Epoch: 14 - Step: 44 - MSE loss: 0.012582594 - KL loss: 0.21092403\n",
            "Epoch: 14 - Step: 45 - MSE loss: 0.013086729 - KL loss: 0.20933223\n",
            "Epoch: 14 - Step: 46 - MSE loss: 0.013875671 - KL loss: 0.20101812\n",
            "Epoch: 14 - Step: 47 - MSE loss: 0.01489473 - KL loss: 0.20829827\n",
            "Epoch: 14 - Step: 48 - MSE loss: 0.014741509 - KL loss: 0.20468867\n",
            "Epoch: 14 - Step: 49 - MSE loss: 0.014386821 - KL loss: 0.22713378\n",
            "Epoch: 14 - Step: 50 - MSE loss: 0.016699819 - KL loss: 0.21993989\n",
            "Epoch: 14 - Step: 51 - MSE loss: 0.01650443 - KL loss: 0.21667035\n",
            "Epoch: 14 - Step: 52 - MSE loss: 0.016191062 - KL loss: 0.22336389\n",
            "Epoch: 14 - Step: 53 - MSE loss: 0.015703678 - KL loss: 0.2154801\n",
            "Epoch: 14 - Step: 54 - MSE loss: 0.015517756 - KL loss: 0.2116261\n",
            "Epoch: 14 - Step: 55 - MSE loss: 0.015791394 - KL loss: 0.21153727\n",
            "Epoch: 14 - Step: 56 - MSE loss: 0.015795896 - KL loss: 0.22091374\n",
            "Epoch: 14 - Step: 57 - MSE loss: 0.01555454 - KL loss: 0.21356425\n",
            "Epoch: 14 - Step: 58 - MSE loss: 0.016673347 - KL loss: 0.2199725\n",
            "Epoch: 14 - Step: 59 - MSE loss: 0.017526211 - KL loss: 0.22299731\n",
            "Epoch: 14 - Step: 60 - MSE loss: 0.018026156 - KL loss: 0.22959816\n",
            "Epoch: 14 - Step: 61 - MSE loss: 0.016993282 - KL loss: 0.21476978\n",
            "Epoch: 14 - Step: 62 - MSE loss: 0.016242692 - KL loss: 0.23006418\n",
            "Epoch: 14 - Step: 63 - MSE loss: 0.018069917 - KL loss: 0.21885413\n",
            "Epoch: 14 - Step: 64 - MSE loss: 0.018938275 - KL loss: 0.23493066\n",
            "Epoch: 14 - Step: 65 - MSE loss: 0.01911656 - KL loss: 0.20752487\n",
            "Epoch: 14 - Step: 66 - MSE loss: 0.017583525 - KL loss: 0.21925598\n",
            "Epoch: 14 - Step: 67 - MSE loss: 0.017934838 - KL loss: 0.18465683\n",
            "Epoch: 14 - Step: 68 - MSE loss: 0.014244817 - KL loss: 0.17974836\n",
            "Epoch: 14 - Step: 69 - MSE loss: 0.014122647 - KL loss: 0.18527721\n",
            "Epoch: 14 - Step: 70 - MSE loss: 0.012461115 - KL loss: 0.18151376\n",
            "Epoch: 14 - Step: 71 - MSE loss: 0.010324493 - KL loss: 0.16739823\n",
            "Epoch: 14 - Step: 72 - MSE loss: 0.011399917 - KL loss: 0.16722181\n",
            "Epoch: 14 - Step: 73 - MSE loss: 0.009669482 - KL loss: 0.16360769\n",
            "Epoch: 14 - Step: 74 - MSE loss: 0.010959294 - KL loss: 0.16014361\n",
            "Epoch: 14 - Step: 75 - MSE loss: 0.009288775 - KL loss: 0.15019378\n",
            "Epoch: 14 - Step: 76 - MSE loss: 0.008362003 - KL loss: 0.14409113\n",
            "Epoch: 14 - Step: 77 - MSE loss: 0.008021066 - KL loss: 0.13310905\n",
            "Epoch: 14 - Step: 78 - MSE loss: 0.008393947 - KL loss: 0.13844348\n",
            "Epoch: 14 - Step: 79 - MSE loss: 0.008856914 - KL loss: 0.14507516\n",
            "Epoch: 14 - Step: 80 - MSE loss: 0.008395825 - KL loss: 0.1431313\n",
            "Epoch: 14 - Step: 81 - MSE loss: 0.008248162 - KL loss: 0.14737561\n",
            "Epoch: 14 - Step: 82 - MSE loss: 0.009098612 - KL loss: 0.14651442\n",
            "Epoch: 14 - Step: 83 - MSE loss: 0.008378668 - KL loss: 0.13726193\n",
            "Epoch: 14 - Step: 84 - MSE loss: 0.008157573 - KL loss: 0.14344877\n",
            "Epoch: 14 - Step: 85 - MSE loss: 0.007972875 - KL loss: 0.14071457\n",
            "Epoch: 14 - Step: 86 - MSE loss: 0.009036233 - KL loss: 0.15116522\n",
            "Epoch: 14 - Step: 87 - MSE loss: 0.008600936 - KL loss: 0.15271267\n",
            "Epoch: 14 - Step: 88 - MSE loss: 0.008862492 - KL loss: 0.14045121\n",
            "Epoch: 14 - Step: 89 - MSE loss: 0.008339356 - KL loss: 0.15168926\n",
            "Epoch: 14 - Step: 90 - MSE loss: 0.008735041 - KL loss: 0.15983346\n",
            "Epoch: 14 - Step: 91 - MSE loss: 0.008736127 - KL loss: 0.15640768\n",
            "Epoch: 14 - Step: 92 - MSE loss: 0.008610866 - KL loss: 0.1542507\n",
            "Epoch: 14 - Step: 93 - MSE loss: 0.008609162 - KL loss: 0.14906827\n",
            "Epoch: 14 - Step: 94 - MSE loss: 0.009055681 - KL loss: 0.15100354\n",
            "Epoch: 14 - Step: 95 - MSE loss: 0.00846148 - KL loss: 0.14357638\n",
            "Epoch: 14 - Step: 96 - MSE loss: 0.008834363 - KL loss: 0.14337528\n",
            "Epoch: 14 - Step: 97 - MSE loss: 0.008518775 - KL loss: 0.14327472\n",
            "Epoch: 14 - Step: 98 - MSE loss: 0.009397686 - KL loss: 0.16096297\n",
            "Epoch: 14 - Step: 99 - MSE loss: 0.010041434 - KL loss: 0.15358454\n",
            "Epoch: 14 - Step: 100 - MSE loss: 0.009453539 - KL loss: 0.14818\n",
            "Epoch: 14 - Step: 101 - MSE loss: 0.008982021 - KL loss: 0.13976923\n",
            "Epoch: 14 - Step: 102 - MSE loss: 0.009688459 - KL loss: 0.1486704\n",
            "Epoch: 14 - Step: 103 - MSE loss: 0.008428705 - KL loss: 0.15415071\n",
            "Epoch: 14 - Step: 104 - MSE loss: 0.009415288 - KL loss: 0.15641391\n",
            "Epoch: 14 - Step: 105 - MSE loss: 0.010306749 - KL loss: 0.18651399\n",
            "Epoch: 14 - Step: 106 - MSE loss: 0.010749515 - KL loss: 0.17256907\n",
            "Epoch: 14 - Step: 107 - MSE loss: 0.012290475 - KL loss: 0.17998126\n",
            "Epoch: 14 - Step: 108 - MSE loss: 0.011578151 - KL loss: 0.20085052\n",
            "Epoch: 14 - Step: 109 - MSE loss: 0.013291556 - KL loss: 0.19765952\n",
            "Epoch: 14 - Step: 110 - MSE loss: 0.013337205 - KL loss: 0.19109556\n",
            "Epoch: 14 - Step: 111 - MSE loss: 0.012891818 - KL loss: 0.20660827\n",
            "Epoch: 14 - Step: 112 - MSE loss: 0.015699578 - KL loss: 0.21562812\n",
            "Epoch: 14 - Step: 113 - MSE loss: 0.015411469 - KL loss: 0.21491164\n",
            "Epoch: 14 - Step: 114 - MSE loss: 0.016444476 - KL loss: 0.20545226\n",
            "Epoch: 14 - Step: 115 - MSE loss: 0.015757173 - KL loss: 0.21675953\n",
            "Epoch: 14 - Step: 116 - MSE loss: 0.014389973 - KL loss: 0.2198034\n",
            "Epoch: 14 - Step: 117 - MSE loss: 0.016262678 - KL loss: 0.21789184\n",
            "Epoch: 14 - Step: 118 - MSE loss: 0.015408221 - KL loss: 0.22017543\n",
            "Epoch: 14 - Step: 119 - MSE loss: 0.015969282 - KL loss: 0.21170816\n",
            "Epoch: 14 - Step: 120 - MSE loss: 0.014402357 - KL loss: 0.22838403\n",
            "Epoch: 14 - Step: 121 - MSE loss: 0.015039136 - KL loss: 0.22741553\n",
            "Epoch: 14 - Step: 122 - MSE loss: 0.01488138 - KL loss: 0.22008929\n",
            "Epoch: 14 - Step: 123 - MSE loss: 0.0150667215 - KL loss: 0.21532722\n",
            "Epoch: 14 - Step: 124 - MSE loss: 0.015863575 - KL loss: 0.21913321\n",
            "Epoch: 14 - Step: 125 - MSE loss: 0.016136369 - KL loss: 0.22202608\n",
            "Epoch: 14 - Step: 126 - MSE loss: 0.017636443 - KL loss: 0.22742963\n",
            "Epoch: 14 - Step: 127 - MSE loss: 0.017238662 - KL loss: 0.19888172\n",
            "Epoch: 14 - Step: 128 - MSE loss: 0.017953308 - KL loss: 0.2256487\n",
            "Epoch: 14 - Step: 129 - MSE loss: 0.018426904 - KL loss: 0.20497352\n",
            "Epoch: 14 - Step: 130 - MSE loss: 0.018431148 - KL loss: 0.2321026\n",
            "Epoch: 14 - Step: 131 - MSE loss: 0.017706394 - KL loss: 0.20781878\n",
            "Epoch: 14 - Step: 132 - MSE loss: 0.0171184 - KL loss: 0.22944734\n",
            "Epoch: 14 - Step: 133 - MSE loss: 0.016794166 - KL loss: 0.22543421\n",
            "Epoch: 14 - Step: 134 - MSE loss: 0.015543 - KL loss: 0.22307998\n",
            "Epoch: 14 - Step: 135 - MSE loss: 0.018434366 - KL loss: 0.23503765\n",
            "Epoch: 14 - Step: 136 - MSE loss: 0.017062286 - KL loss: 0.22790487\n",
            "Epoch: 14 - Step: 137 - MSE loss: 0.01630044 - KL loss: 0.22174671\n",
            "Epoch: 14 - Step: 138 - MSE loss: 0.015283194 - KL loss: 0.21372193\n",
            "Epoch: 14 - Step: 139 - MSE loss: 0.015400684 - KL loss: 0.20578341\n",
            "Epoch: 14 - Step: 140 - MSE loss: 0.01581284 - KL loss: 0.20790863\n",
            "Epoch: 14 - Step: 141 - MSE loss: 0.01585945 - KL loss: 0.21692637\n",
            "Epoch: 14 - Step: 142 - MSE loss: 0.015055084 - KL loss: 0.222204\n",
            "Epoch: 14 - Step: 143 - MSE loss: 0.015668469 - KL loss: 0.21314663\n",
            "Epoch: 14 - Step: 144 - MSE loss: 0.015210368 - KL loss: 0.21316238\n",
            "Epoch:  15\n",
            "Epoch: 15 - Step: 0 - MSE loss: 0.00783342 - KL loss: 0.1621297\n",
            "Epoch: 15 - Step: 1 - MSE loss: 0.008755992 - KL loss: 0.15713818\n",
            "Epoch: 15 - Step: 2 - MSE loss: 0.008361768 - KL loss: 0.15595256\n",
            "Epoch: 15 - Step: 3 - MSE loss: 0.008140817 - KL loss: 0.15549067\n",
            "Epoch: 15 - Step: 4 - MSE loss: 0.009185114 - KL loss: 0.1606907\n",
            "Epoch: 15 - Step: 5 - MSE loss: 0.008165886 - KL loss: 0.16234991\n",
            "Epoch: 15 - Step: 6 - MSE loss: 0.008433901 - KL loss: 0.14744163\n",
            "Epoch: 15 - Step: 7 - MSE loss: 0.009288072 - KL loss: 0.14904925\n",
            "Epoch: 15 - Step: 8 - MSE loss: 0.008587462 - KL loss: 0.15423012\n",
            "Epoch: 15 - Step: 9 - MSE loss: 0.008911747 - KL loss: 0.15719059\n",
            "Epoch: 15 - Step: 10 - MSE loss: 0.0094248345 - KL loss: 0.14378364\n",
            "Epoch: 15 - Step: 11 - MSE loss: 0.008733663 - KL loss: 0.15618405\n",
            "Epoch: 15 - Step: 12 - MSE loss: 0.009906222 - KL loss: 0.1476029\n",
            "Epoch: 15 - Step: 13 - MSE loss: 0.008490289 - KL loss: 0.14053571\n",
            "Epoch: 15 - Step: 14 - MSE loss: 0.009654531 - KL loss: 0.14211664\n",
            "Epoch: 15 - Step: 15 - MSE loss: 0.00889271 - KL loss: 0.1469833\n",
            "Epoch: 15 - Step: 16 - MSE loss: 0.0088418955 - KL loss: 0.1568169\n",
            "Epoch: 15 - Step: 17 - MSE loss: 0.007882963 - KL loss: 0.14297207\n",
            "Epoch: 15 - Step: 18 - MSE loss: 0.007928436 - KL loss: 0.14228126\n",
            "Epoch: 15 - Step: 19 - MSE loss: 0.0074166157 - KL loss: 0.13565888\n",
            "Epoch: 15 - Step: 20 - MSE loss: 0.0073256916 - KL loss: 0.12891287\n",
            "Epoch: 15 - Step: 21 - MSE loss: 0.007249048 - KL loss: 0.12980726\n",
            "Epoch: 15 - Step: 22 - MSE loss: 0.007856813 - KL loss: 0.1413494\n",
            "Epoch: 15 - Step: 23 - MSE loss: 0.007483158 - KL loss: 0.13396844\n",
            "Epoch: 15 - Step: 24 - MSE loss: 0.0073626195 - KL loss: 0.13198273\n",
            "Epoch: 15 - Step: 25 - MSE loss: 0.007956285 - KL loss: 0.13579738\n",
            "Epoch: 15 - Step: 26 - MSE loss: 0.0071099824 - KL loss: 0.13548285\n",
            "Epoch: 15 - Step: 27 - MSE loss: 0.0073248125 - KL loss: 0.13162702\n",
            "Epoch: 15 - Step: 28 - MSE loss: 0.0076718032 - KL loss: 0.13894634\n",
            "Epoch: 15 - Step: 29 - MSE loss: 0.007477528 - KL loss: 0.13467571\n",
            "Epoch: 15 - Step: 30 - MSE loss: 0.0070548807 - KL loss: 0.13315906\n",
            "Epoch: 15 - Step: 31 - MSE loss: 0.007470369 - KL loss: 0.13447031\n",
            "Epoch: 15 - Step: 32 - MSE loss: 0.008750697 - KL loss: 0.14197928\n",
            "Epoch: 15 - Step: 33 - MSE loss: 0.008717244 - KL loss: 0.15144205\n",
            "Epoch: 15 - Step: 34 - MSE loss: 0.0107529415 - KL loss: 0.1602754\n",
            "Epoch: 15 - Step: 35 - MSE loss: 0.009884342 - KL loss: 0.16774623\n",
            "Epoch: 15 - Step: 36 - MSE loss: 0.010619533 - KL loss: 0.17050152\n",
            "Epoch: 15 - Step: 37 - MSE loss: 0.010915118 - KL loss: 0.18588349\n",
            "Epoch: 15 - Step: 38 - MSE loss: 0.011910494 - KL loss: 0.18823907\n",
            "Epoch: 15 - Step: 39 - MSE loss: 0.013506995 - KL loss: 0.19614938\n",
            "Epoch: 15 - Step: 40 - MSE loss: 0.01326478 - KL loss: 0.19506145\n",
            "Epoch: 15 - Step: 41 - MSE loss: 0.01285961 - KL loss: 0.201867\n",
            "Epoch: 15 - Step: 42 - MSE loss: 0.012718507 - KL loss: 0.20868379\n",
            "Epoch: 15 - Step: 43 - MSE loss: 0.012532455 - KL loss: 0.2071948\n",
            "Epoch: 15 - Step: 44 - MSE loss: 0.013019409 - KL loss: 0.2055856\n",
            "Epoch: 15 - Step: 45 - MSE loss: 0.012632448 - KL loss: 0.20524053\n",
            "Epoch: 15 - Step: 46 - MSE loss: 0.013573762 - KL loss: 0.2117272\n",
            "Epoch: 15 - Step: 47 - MSE loss: 0.013531263 - KL loss: 0.20281535\n",
            "Epoch: 15 - Step: 48 - MSE loss: 0.0141321225 - KL loss: 0.21200064\n",
            "Epoch: 15 - Step: 49 - MSE loss: 0.014017635 - KL loss: 0.2130051\n",
            "Epoch: 15 - Step: 50 - MSE loss: 0.014831322 - KL loss: 0.2108584\n",
            "Epoch: 15 - Step: 51 - MSE loss: 0.014510308 - KL loss: 0.20816453\n",
            "Epoch: 15 - Step: 52 - MSE loss: 0.014654167 - KL loss: 0.22009727\n",
            "Epoch: 15 - Step: 53 - MSE loss: 0.014821474 - KL loss: 0.20929375\n",
            "Epoch: 15 - Step: 54 - MSE loss: 0.01581604 - KL loss: 0.23441783\n",
            "Epoch: 15 - Step: 55 - MSE loss: 0.015408364 - KL loss: 0.21490452\n",
            "Epoch: 15 - Step: 56 - MSE loss: 0.015723217 - KL loss: 0.22178368\n",
            "Epoch: 15 - Step: 57 - MSE loss: 0.016386468 - KL loss: 0.20920175\n",
            "Epoch: 15 - Step: 58 - MSE loss: 0.01588206 - KL loss: 0.2205739\n",
            "Epoch: 15 - Step: 59 - MSE loss: 0.017042393 - KL loss: 0.21223697\n",
            "Epoch: 15 - Step: 60 - MSE loss: 0.017761707 - KL loss: 0.22509372\n",
            "Epoch: 15 - Step: 61 - MSE loss: 0.021589914 - KL loss: 0.1986981\n",
            "Epoch: 15 - Step: 62 - MSE loss: 0.021902068 - KL loss: 0.21741846\n",
            "Epoch: 15 - Step: 63 - MSE loss: 0.019752825 - KL loss: 0.1793053\n",
            "Epoch: 15 - Step: 64 - MSE loss: 0.01728543 - KL loss: 0.20372644\n",
            "Epoch: 15 - Step: 65 - MSE loss: 0.01724871 - KL loss: 0.1990493\n",
            "Epoch: 15 - Step: 66 - MSE loss: 0.016105013 - KL loss: 0.20954111\n",
            "Epoch: 15 - Step: 67 - MSE loss: 0.015699882 - KL loss: 0.22286199\n",
            "Epoch: 15 - Step: 68 - MSE loss: 0.013783947 - KL loss: 0.19711784\n",
            "Epoch: 15 - Step: 69 - MSE loss: 0.012795215 - KL loss: 0.1906836\n",
            "Epoch: 15 - Step: 70 - MSE loss: 0.012740851 - KL loss: 0.16857909\n",
            "Epoch: 15 - Step: 71 - MSE loss: 0.011148192 - KL loss: 0.17597899\n",
            "Epoch: 15 - Step: 72 - MSE loss: 0.010465073 - KL loss: 0.17051743\n",
            "Epoch: 15 - Step: 73 - MSE loss: 0.010017482 - KL loss: 0.16024101\n",
            "Epoch: 15 - Step: 74 - MSE loss: 0.009492108 - KL loss: 0.15045567\n",
            "Epoch: 15 - Step: 75 - MSE loss: 0.00798265 - KL loss: 0.14650732\n",
            "Epoch: 15 - Step: 76 - MSE loss: 0.008957133 - KL loss: 0.15530345\n",
            "Epoch: 15 - Step: 77 - MSE loss: 0.00785965 - KL loss: 0.13640054\n",
            "Epoch: 15 - Step: 78 - MSE loss: 0.008010591 - KL loss: 0.13291946\n",
            "Epoch: 15 - Step: 79 - MSE loss: 0.0073834206 - KL loss: 0.13553488\n",
            "Epoch: 15 - Step: 80 - MSE loss: 0.0081801005 - KL loss: 0.13741086\n",
            "Epoch: 15 - Step: 81 - MSE loss: 0.007673236 - KL loss: 0.12960967\n",
            "Epoch: 15 - Step: 82 - MSE loss: 0.008896186 - KL loss: 0.14479867\n",
            "Epoch: 15 - Step: 83 - MSE loss: 0.008212208 - KL loss: 0.14047854\n",
            "Epoch: 15 - Step: 84 - MSE loss: 0.008300687 - KL loss: 0.14546117\n",
            "Epoch: 15 - Step: 85 - MSE loss: 0.008298913 - KL loss: 0.14322838\n",
            "Epoch: 15 - Step: 86 - MSE loss: 0.008113543 - KL loss: 0.14627391\n",
            "Epoch: 15 - Step: 87 - MSE loss: 0.008270437 - KL loss: 0.14529835\n",
            "Epoch: 15 - Step: 88 - MSE loss: 0.0090906015 - KL loss: 0.1526861\n",
            "Epoch: 15 - Step: 89 - MSE loss: 0.008165331 - KL loss: 0.14024422\n",
            "Epoch: 15 - Step: 90 - MSE loss: 0.008723981 - KL loss: 0.1515559\n",
            "Epoch: 15 - Step: 91 - MSE loss: 0.008884556 - KL loss: 0.14823452\n",
            "Epoch: 15 - Step: 92 - MSE loss: 0.008026905 - KL loss: 0.1451774\n",
            "Epoch: 15 - Step: 93 - MSE loss: 0.008291195 - KL loss: 0.15773176\n",
            "Epoch: 15 - Step: 94 - MSE loss: 0.008746335 - KL loss: 0.15494075\n",
            "Epoch: 15 - Step: 95 - MSE loss: 0.008306687 - KL loss: 0.15127581\n",
            "Epoch: 15 - Step: 96 - MSE loss: 0.008166515 - KL loss: 0.15864271\n",
            "Epoch: 15 - Step: 97 - MSE loss: 0.008481287 - KL loss: 0.14983526\n",
            "Epoch: 15 - Step: 98 - MSE loss: 0.009061378 - KL loss: 0.1488336\n",
            "Epoch: 15 - Step: 99 - MSE loss: 0.007898442 - KL loss: 0.1487296\n",
            "Epoch: 15 - Step: 100 - MSE loss: 0.009061641 - KL loss: 0.15085608\n",
            "Epoch: 15 - Step: 101 - MSE loss: 0.007643581 - KL loss: 0.14579226\n",
            "Epoch: 15 - Step: 102 - MSE loss: 0.007959396 - KL loss: 0.1500833\n",
            "Epoch: 15 - Step: 103 - MSE loss: 0.008758299 - KL loss: 0.15223438\n",
            "Epoch: 15 - Step: 104 - MSE loss: 0.008903249 - KL loss: 0.15900621\n",
            "Epoch: 15 - Step: 105 - MSE loss: 0.009874064 - KL loss: 0.16488124\n",
            "Epoch: 15 - Step: 106 - MSE loss: 0.011711173 - KL loss: 0.17449674\n",
            "Epoch: 15 - Step: 107 - MSE loss: 0.011308511 - KL loss: 0.17658295\n",
            "Epoch: 15 - Step: 108 - MSE loss: 0.0115697235 - KL loss: 0.18343866\n",
            "Epoch: 15 - Step: 109 - MSE loss: 0.012150619 - KL loss: 0.18658751\n",
            "Epoch: 15 - Step: 110 - MSE loss: 0.013426747 - KL loss: 0.20917404\n",
            "Epoch: 15 - Step: 111 - MSE loss: 0.013964103 - KL loss: 0.21234688\n",
            "Epoch: 15 - Step: 112 - MSE loss: 0.014968246 - KL loss: 0.21367227\n",
            "Epoch: 15 - Step: 113 - MSE loss: 0.014789403 - KL loss: 0.20691013\n",
            "Epoch: 15 - Step: 114 - MSE loss: 0.015004686 - KL loss: 0.21704695\n",
            "Epoch: 15 - Step: 115 - MSE loss: 0.014818549 - KL loss: 0.20163937\n",
            "Epoch: 15 - Step: 116 - MSE loss: 0.016227398 - KL loss: 0.22615147\n",
            "Epoch: 15 - Step: 117 - MSE loss: 0.015575398 - KL loss: 0.20771712\n",
            "Epoch: 15 - Step: 118 - MSE loss: 0.015112958 - KL loss: 0.208614\n",
            "Epoch: 15 - Step: 119 - MSE loss: 0.014611118 - KL loss: 0.20307353\n",
            "Epoch: 15 - Step: 120 - MSE loss: 0.014504924 - KL loss: 0.21499148\n",
            "Epoch: 15 - Step: 121 - MSE loss: 0.013308027 - KL loss: 0.22257888\n",
            "Epoch: 15 - Step: 122 - MSE loss: 0.013904293 - KL loss: 0.20888792\n",
            "Epoch: 15 - Step: 123 - MSE loss: 0.014153157 - KL loss: 0.22711818\n",
            "Epoch: 15 - Step: 124 - MSE loss: 0.01400829 - KL loss: 0.21519595\n",
            "Epoch: 15 - Step: 125 - MSE loss: 0.014823943 - KL loss: 0.22758137\n",
            "Epoch: 15 - Step: 126 - MSE loss: 0.01414682 - KL loss: 0.23065002\n",
            "Epoch: 15 - Step: 127 - MSE loss: 0.013718121 - KL loss: 0.22069001\n",
            "Epoch: 15 - Step: 128 - MSE loss: 0.013895725 - KL loss: 0.22100912\n",
            "Epoch: 15 - Step: 129 - MSE loss: 0.014958292 - KL loss: 0.21915318\n",
            "Epoch: 15 - Step: 130 - MSE loss: 0.01522586 - KL loss: 0.233271\n",
            "Epoch: 15 - Step: 131 - MSE loss: 0.017483782 - KL loss: 0.22340757\n",
            "Epoch: 15 - Step: 132 - MSE loss: 0.02129502 - KL loss: 0.24673833\n",
            "Epoch: 15 - Step: 133 - MSE loss: 0.029218838 - KL loss: 0.18098685\n",
            "Epoch: 15 - Step: 134 - MSE loss: 0.025794486 - KL loss: 0.19483277\n",
            "Epoch: 15 - Step: 135 - MSE loss: 0.02176782 - KL loss: 0.17192739\n",
            "Epoch: 15 - Step: 136 - MSE loss: 0.01885146 - KL loss: 0.1856986\n",
            "Epoch: 15 - Step: 137 - MSE loss: 0.018362155 - KL loss: 0.20713115\n",
            "Epoch: 15 - Step: 138 - MSE loss: 0.018578945 - KL loss: 0.22835553\n",
            "Epoch: 15 - Step: 139 - MSE loss: 0.016346466 - KL loss: 0.23354718\n",
            "Epoch: 15 - Step: 140 - MSE loss: 0.016291944 - KL loss: 0.20973206\n",
            "Epoch: 15 - Step: 141 - MSE loss: 0.016058668 - KL loss: 0.23131189\n",
            "Epoch: 15 - Step: 142 - MSE loss: 0.014918249 - KL loss: 0.23201728\n",
            "Epoch: 15 - Step: 143 - MSE loss: 0.01551259 - KL loss: 0.223586\n",
            "Epoch: 15 - Step: 144 - MSE loss: 0.014341193 - KL loss: 0.21601652\n",
            "Epoch:  16\n",
            "Epoch: 16 - Step: 0 - MSE loss: 0.008111574 - KL loss: 0.16705395\n",
            "Epoch: 16 - Step: 1 - MSE loss: 0.008129056 - KL loss: 0.17294554\n",
            "Epoch: 16 - Step: 2 - MSE loss: 0.007871251 - KL loss: 0.17677559\n",
            "Epoch: 16 - Step: 3 - MSE loss: 0.007357226 - KL loss: 0.16487917\n",
            "Epoch: 16 - Step: 4 - MSE loss: 0.0074398383 - KL loss: 0.16006745\n",
            "Epoch: 16 - Step: 5 - MSE loss: 0.0075328783 - KL loss: 0.1555098\n",
            "Epoch: 16 - Step: 6 - MSE loss: 0.008125127 - KL loss: 0.15242429\n",
            "Epoch: 16 - Step: 7 - MSE loss: 0.00805299 - KL loss: 0.15113899\n",
            "Epoch: 16 - Step: 8 - MSE loss: 0.00816843 - KL loss: 0.14873326\n",
            "Epoch: 16 - Step: 9 - MSE loss: 0.008687885 - KL loss: 0.15449184\n",
            "Epoch: 16 - Step: 10 - MSE loss: 0.00947407 - KL loss: 0.15198638\n",
            "Epoch: 16 - Step: 11 - MSE loss: 0.009537171 - KL loss: 0.14287212\n",
            "Epoch: 16 - Step: 12 - MSE loss: 0.008894835 - KL loss: 0.15218192\n",
            "Epoch: 16 - Step: 13 - MSE loss: 0.008921559 - KL loss: 0.14133218\n",
            "Epoch: 16 - Step: 14 - MSE loss: 0.008937199 - KL loss: 0.14083953\n",
            "Epoch: 16 - Step: 15 - MSE loss: 0.008496351 - KL loss: 0.14856765\n",
            "Epoch: 16 - Step: 16 - MSE loss: 0.007651843 - KL loss: 0.14698133\n",
            "Epoch: 16 - Step: 17 - MSE loss: 0.008453618 - KL loss: 0.13929139\n",
            "Epoch: 16 - Step: 18 - MSE loss: 0.0073958114 - KL loss: 0.13877234\n",
            "Epoch: 16 - Step: 19 - MSE loss: 0.0074702674 - KL loss: 0.12950005\n",
            "Epoch: 16 - Step: 20 - MSE loss: 0.007451612 - KL loss: 0.13750497\n",
            "Epoch: 16 - Step: 21 - MSE loss: 0.0076759383 - KL loss: 0.12969694\n",
            "Epoch: 16 - Step: 22 - MSE loss: 0.007137686 - KL loss: 0.125631\n",
            "Epoch: 16 - Step: 23 - MSE loss: 0.0073805633 - KL loss: 0.13775623\n",
            "Epoch: 16 - Step: 24 - MSE loss: 0.007221155 - KL loss: 0.13242021\n",
            "Epoch: 16 - Step: 25 - MSE loss: 0.007322576 - KL loss: 0.13223454\n",
            "Epoch: 16 - Step: 26 - MSE loss: 0.0066050813 - KL loss: 0.12552989\n",
            "Epoch: 16 - Step: 27 - MSE loss: 0.007424761 - KL loss: 0.12566236\n",
            "Epoch: 16 - Step: 28 - MSE loss: 0.007641142 - KL loss: 0.13171282\n",
            "Epoch: 16 - Step: 29 - MSE loss: 0.0069173393 - KL loss: 0.12718923\n",
            "Epoch: 16 - Step: 30 - MSE loss: 0.0069797137 - KL loss: 0.12905744\n",
            "Epoch: 16 - Step: 31 - MSE loss: 0.0068570464 - KL loss: 0.13493198\n",
            "Epoch: 16 - Step: 32 - MSE loss: 0.0081467405 - KL loss: 0.14106688\n",
            "Epoch: 16 - Step: 33 - MSE loss: 0.008598752 - KL loss: 0.14589596\n",
            "Epoch: 16 - Step: 34 - MSE loss: 0.009427164 - KL loss: 0.15313193\n",
            "Epoch: 16 - Step: 35 - MSE loss: 0.010172394 - KL loss: 0.15806594\n",
            "Epoch: 16 - Step: 36 - MSE loss: 0.010649872 - KL loss: 0.1737334\n",
            "Epoch: 16 - Step: 37 - MSE loss: 0.010425106 - KL loss: 0.16865297\n",
            "Epoch: 16 - Step: 38 - MSE loss: 0.011639847 - KL loss: 0.18683353\n",
            "Epoch: 16 - Step: 39 - MSE loss: 0.012848645 - KL loss: 0.19662079\n",
            "Epoch: 16 - Step: 40 - MSE loss: 0.012015368 - KL loss: 0.20154819\n",
            "Epoch: 16 - Step: 41 - MSE loss: 0.012646109 - KL loss: 0.21077673\n",
            "Epoch: 16 - Step: 42 - MSE loss: 0.012667085 - KL loss: 0.21291527\n",
            "Epoch: 16 - Step: 43 - MSE loss: 0.011472846 - KL loss: 0.20384793\n",
            "Epoch: 16 - Step: 44 - MSE loss: 0.012167637 - KL loss: 0.20470567\n",
            "Epoch: 16 - Step: 45 - MSE loss: 0.012901839 - KL loss: 0.20971859\n",
            "Epoch: 16 - Step: 46 - MSE loss: 0.012965369 - KL loss: 0.20326227\n",
            "Epoch: 16 - Step: 47 - MSE loss: 0.012729473 - KL loss: 0.20803267\n",
            "Epoch: 16 - Step: 48 - MSE loss: 0.013457716 - KL loss: 0.20565294\n",
            "Epoch: 16 - Step: 49 - MSE loss: 0.014059613 - KL loss: 0.2081762\n",
            "Epoch: 16 - Step: 50 - MSE loss: 0.014001698 - KL loss: 0.20290111\n",
            "Epoch: 16 - Step: 51 - MSE loss: 0.014673021 - KL loss: 0.21237136\n",
            "Epoch: 16 - Step: 52 - MSE loss: 0.0139471525 - KL loss: 0.21484983\n",
            "Epoch: 16 - Step: 53 - MSE loss: 0.015994247 - KL loss: 0.20634261\n",
            "Epoch: 16 - Step: 54 - MSE loss: 0.01574766 - KL loss: 0.2132223\n",
            "Epoch: 16 - Step: 55 - MSE loss: 0.015416422 - KL loss: 0.19818309\n",
            "Epoch: 16 - Step: 56 - MSE loss: 0.0154267615 - KL loss: 0.21552467\n",
            "Epoch: 16 - Step: 57 - MSE loss: 0.015246347 - KL loss: 0.20833623\n",
            "Epoch: 16 - Step: 58 - MSE loss: 0.014952137 - KL loss: 0.21731222\n",
            "Epoch: 16 - Step: 59 - MSE loss: 0.015320151 - KL loss: 0.22151792\n",
            "Epoch: 16 - Step: 60 - MSE loss: 0.015725568 - KL loss: 0.21687308\n",
            "Epoch: 16 - Step: 61 - MSE loss: 0.014944821 - KL loss: 0.22022524\n",
            "Epoch: 16 - Step: 62 - MSE loss: 0.016275866 - KL loss: 0.22583815\n",
            "Epoch: 16 - Step: 63 - MSE loss: 0.015308261 - KL loss: 0.225032\n",
            "Epoch: 16 - Step: 64 - MSE loss: 0.017052526 - KL loss: 0.21791294\n",
            "Epoch: 16 - Step: 65 - MSE loss: 0.014295922 - KL loss: 0.2164237\n",
            "Epoch: 16 - Step: 66 - MSE loss: 0.015274267 - KL loss: 0.22363609\n",
            "Epoch: 16 - Step: 67 - MSE loss: 0.013473301 - KL loss: 0.19971675\n",
            "Epoch: 16 - Step: 68 - MSE loss: 0.011549182 - KL loss: 0.19098061\n",
            "Epoch: 16 - Step: 69 - MSE loss: 0.011848458 - KL loss: 0.17480096\n",
            "Epoch: 16 - Step: 70 - MSE loss: 0.01104156 - KL loss: 0.17002319\n",
            "Epoch: 16 - Step: 71 - MSE loss: 0.010604632 - KL loss: 0.16851094\n",
            "Epoch: 16 - Step: 72 - MSE loss: 0.009096442 - KL loss: 0.155224\n",
            "Epoch: 16 - Step: 73 - MSE loss: 0.009883847 - KL loss: 0.16529283\n",
            "Epoch: 16 - Step: 74 - MSE loss: 0.009949303 - KL loss: 0.16334249\n",
            "Epoch: 16 - Step: 75 - MSE loss: 0.0080006 - KL loss: 0.13855511\n",
            "Epoch: 16 - Step: 76 - MSE loss: 0.008188996 - KL loss: 0.13138664\n",
            "Epoch: 16 - Step: 77 - MSE loss: 0.008261186 - KL loss: 0.13175511\n",
            "Epoch: 16 - Step: 78 - MSE loss: 0.008324846 - KL loss: 0.13775733\n",
            "Epoch: 16 - Step: 79 - MSE loss: 0.0076950565 - KL loss: 0.13012874\n",
            "Epoch: 16 - Step: 80 - MSE loss: 0.008185202 - KL loss: 0.13291973\n",
            "Epoch: 16 - Step: 81 - MSE loss: 0.008104914 - KL loss: 0.13350984\n",
            "Epoch: 16 - Step: 82 - MSE loss: 0.008032951 - KL loss: 0.13479264\n",
            "Epoch: 16 - Step: 83 - MSE loss: 0.008890708 - KL loss: 0.14496878\n",
            "Epoch: 16 - Step: 84 - MSE loss: 0.007781549 - KL loss: 0.14694804\n",
            "Epoch: 16 - Step: 85 - MSE loss: 0.007789397 - KL loss: 0.1477154\n",
            "Epoch: 16 - Step: 86 - MSE loss: 0.008206995 - KL loss: 0.14575115\n",
            "Epoch: 16 - Step: 87 - MSE loss: 0.007979979 - KL loss: 0.14261295\n",
            "Epoch: 16 - Step: 88 - MSE loss: 0.00876736 - KL loss: 0.14826196\n",
            "Epoch: 16 - Step: 89 - MSE loss: 0.0086927 - KL loss: 0.15065053\n",
            "Epoch: 16 - Step: 90 - MSE loss: 0.008761055 - KL loss: 0.14703658\n",
            "Epoch: 16 - Step: 91 - MSE loss: 0.008622818 - KL loss: 0.14886042\n",
            "Epoch: 16 - Step: 92 - MSE loss: 0.008313142 - KL loss: 0.14497754\n",
            "Epoch: 16 - Step: 93 - MSE loss: 0.00842629 - KL loss: 0.14541297\n",
            "Epoch: 16 - Step: 94 - MSE loss: 0.008890146 - KL loss: 0.15020075\n",
            "Epoch: 16 - Step: 95 - MSE loss: 0.008492836 - KL loss: 0.14677203\n",
            "Epoch: 16 - Step: 96 - MSE loss: 0.0077620554 - KL loss: 0.14076722\n",
            "Epoch: 16 - Step: 97 - MSE loss: 0.008123908 - KL loss: 0.14738327\n",
            "Epoch: 16 - Step: 98 - MSE loss: 0.008386562 - KL loss: 0.14893092\n",
            "Epoch: 16 - Step: 99 - MSE loss: 0.008874184 - KL loss: 0.15037155\n",
            "Epoch: 16 - Step: 100 - MSE loss: 0.008312709 - KL loss: 0.15024506\n",
            "Epoch: 16 - Step: 101 - MSE loss: 0.008468486 - KL loss: 0.14017609\n",
            "Epoch: 16 - Step: 102 - MSE loss: 0.009094019 - KL loss: 0.14438295\n",
            "Epoch: 16 - Step: 103 - MSE loss: 0.008896788 - KL loss: 0.14346816\n",
            "Epoch: 16 - Step: 104 - MSE loss: 0.009349697 - KL loss: 0.15526833\n",
            "Epoch: 16 - Step: 105 - MSE loss: 0.010138472 - KL loss: 0.1658856\n",
            "Epoch: 16 - Step: 106 - MSE loss: 0.010871399 - KL loss: 0.16393512\n",
            "Epoch: 16 - Step: 107 - MSE loss: 0.011656988 - KL loss: 0.1796979\n",
            "Epoch: 16 - Step: 108 - MSE loss: 0.010908621 - KL loss: 0.195485\n",
            "Epoch: 16 - Step: 109 - MSE loss: 0.011635605 - KL loss: 0.18134487\n",
            "Epoch: 16 - Step: 110 - MSE loss: 0.012953573 - KL loss: 0.19686979\n",
            "Epoch: 16 - Step: 111 - MSE loss: 0.013168686 - KL loss: 0.20210665\n",
            "Epoch: 16 - Step: 112 - MSE loss: 0.015529024 - KL loss: 0.2013106\n",
            "Epoch: 16 - Step: 113 - MSE loss: 0.013673021 - KL loss: 0.20015535\n",
            "Epoch: 16 - Step: 114 - MSE loss: 0.01422212 - KL loss: 0.21904936\n",
            "Epoch: 16 - Step: 115 - MSE loss: 0.0135788545 - KL loss: 0.21614482\n",
            "Epoch: 16 - Step: 116 - MSE loss: 0.014158792 - KL loss: 0.20564839\n",
            "Epoch: 16 - Step: 117 - MSE loss: 0.015393215 - KL loss: 0.21434222\n",
            "Epoch: 16 - Step: 118 - MSE loss: 0.015717017 - KL loss: 0.20619918\n",
            "Epoch: 16 - Step: 119 - MSE loss: 0.014617267 - KL loss: 0.22461507\n",
            "Epoch: 16 - Step: 120 - MSE loss: 0.014400578 - KL loss: 0.21433204\n",
            "Epoch: 16 - Step: 121 - MSE loss: 0.013383314 - KL loss: 0.22175871\n",
            "Epoch: 16 - Step: 122 - MSE loss: 0.01367183 - KL loss: 0.20849898\n",
            "Epoch: 16 - Step: 123 - MSE loss: 0.014560919 - KL loss: 0.22400846\n",
            "Epoch: 16 - Step: 124 - MSE loss: 0.015804086 - KL loss: 0.2087453\n",
            "Epoch: 16 - Step: 125 - MSE loss: 0.015658619 - KL loss: 0.21066281\n",
            "Epoch: 16 - Step: 126 - MSE loss: 0.01568951 - KL loss: 0.21132156\n",
            "Epoch: 16 - Step: 127 - MSE loss: 0.014483824 - KL loss: 0.2093733\n",
            "Epoch: 16 - Step: 128 - MSE loss: 0.01393802 - KL loss: 0.20710805\n",
            "Epoch: 16 - Step: 129 - MSE loss: 0.013124608 - KL loss: 0.2098912\n",
            "Epoch: 16 - Step: 130 - MSE loss: 0.014854152 - KL loss: 0.2130864\n",
            "Epoch: 16 - Step: 131 - MSE loss: 0.013571029 - KL loss: 0.22351354\n",
            "Epoch: 16 - Step: 132 - MSE loss: 0.01394868 - KL loss: 0.22395632\n",
            "Epoch: 16 - Step: 133 - MSE loss: 0.013795499 - KL loss: 0.22293535\n",
            "Epoch: 16 - Step: 134 - MSE loss: 0.0147426715 - KL loss: 0.20397502\n",
            "Epoch: 16 - Step: 135 - MSE loss: 0.015161986 - KL loss: 0.22048381\n",
            "Epoch: 16 - Step: 136 - MSE loss: 0.016007612 - KL loss: 0.21644574\n",
            "Epoch: 16 - Step: 137 - MSE loss: 0.015968092 - KL loss: 0.21485019\n",
            "Epoch: 16 - Step: 138 - MSE loss: 0.01588609 - KL loss: 0.209032\n",
            "Epoch: 16 - Step: 139 - MSE loss: 0.017359013 - KL loss: 0.2239869\n",
            "Epoch: 16 - Step: 140 - MSE loss: 0.019834975 - KL loss: 0.20020857\n",
            "Epoch: 16 - Step: 141 - MSE loss: 0.0186401 - KL loss: 0.20716041\n",
            "Epoch: 16 - Step: 142 - MSE loss: 0.017153753 - KL loss: 0.18904893\n",
            "Epoch: 16 - Step: 143 - MSE loss: 0.0161693 - KL loss: 0.19401257\n",
            "Epoch: 16 - Step: 144 - MSE loss: 0.016362295 - KL loss: 0.20872344\n",
            "Epoch:  17\n",
            "Epoch: 17 - Step: 0 - MSE loss: 0.008290678 - KL loss: 0.1559113\n",
            "Epoch: 17 - Step: 1 - MSE loss: 0.0074685924 - KL loss: 0.16539994\n",
            "Epoch: 17 - Step: 2 - MSE loss: 0.0076593463 - KL loss: 0.17163694\n",
            "Epoch: 17 - Step: 3 - MSE loss: 0.00757259 - KL loss: 0.15629715\n",
            "Epoch: 17 - Step: 4 - MSE loss: 0.0072421967 - KL loss: 0.15561369\n",
            "Epoch: 17 - Step: 5 - MSE loss: 0.007422089 - KL loss: 0.1436469\n",
            "Epoch: 17 - Step: 6 - MSE loss: 0.007553768 - KL loss: 0.15345751\n",
            "Epoch: 17 - Step: 7 - MSE loss: 0.0074275397 - KL loss: 0.14747664\n",
            "Epoch: 17 - Step: 8 - MSE loss: 0.008638081 - KL loss: 0.15272251\n",
            "Epoch: 17 - Step: 9 - MSE loss: 0.008059884 - KL loss: 0.14603904\n",
            "Epoch: 17 - Step: 10 - MSE loss: 0.007970908 - KL loss: 0.14156303\n",
            "Epoch: 17 - Step: 11 - MSE loss: 0.007709392 - KL loss: 0.136641\n",
            "Epoch: 17 - Step: 12 - MSE loss: 0.0076446347 - KL loss: 0.14193676\n",
            "Epoch: 17 - Step: 13 - MSE loss: 0.008399301 - KL loss: 0.14639717\n",
            "Epoch: 17 - Step: 14 - MSE loss: 0.008594536 - KL loss: 0.15196879\n",
            "Epoch: 17 - Step: 15 - MSE loss: 0.00805935 - KL loss: 0.14246513\n",
            "Epoch: 17 - Step: 16 - MSE loss: 0.00820865 - KL loss: 0.15224539\n",
            "Epoch: 17 - Step: 17 - MSE loss: 0.007861178 - KL loss: 0.14151171\n",
            "Epoch: 17 - Step: 18 - MSE loss: 0.007359496 - KL loss: 0.13660708\n",
            "Epoch: 17 - Step: 19 - MSE loss: 0.006952521 - KL loss: 0.13745227\n",
            "Epoch: 17 - Step: 20 - MSE loss: 0.007129871 - KL loss: 0.12763497\n",
            "Epoch: 17 - Step: 21 - MSE loss: 0.007254087 - KL loss: 0.1276158\n",
            "Epoch: 17 - Step: 22 - MSE loss: 0.006886923 - KL loss: 0.12529306\n",
            "Epoch: 17 - Step: 23 - MSE loss: 0.007701082 - KL loss: 0.12495621\n",
            "Epoch: 17 - Step: 24 - MSE loss: 0.006835044 - KL loss: 0.12894613\n",
            "Epoch: 17 - Step: 25 - MSE loss: 0.007098759 - KL loss: 0.1278573\n",
            "Epoch: 17 - Step: 26 - MSE loss: 0.0072753616 - KL loss: 0.13572638\n",
            "Epoch: 17 - Step: 27 - MSE loss: 0.00672408 - KL loss: 0.13299897\n",
            "Epoch: 17 - Step: 28 - MSE loss: 0.0073325336 - KL loss: 0.13265228\n",
            "Epoch: 17 - Step: 29 - MSE loss: 0.007414279 - KL loss: 0.12840438\n",
            "Epoch: 17 - Step: 30 - MSE loss: 0.0064744907 - KL loss: 0.12871505\n",
            "Epoch: 17 - Step: 31 - MSE loss: 0.0069161044 - KL loss: 0.12996434\n",
            "Epoch: 17 - Step: 32 - MSE loss: 0.007937543 - KL loss: 0.13804877\n",
            "Epoch: 17 - Step: 33 - MSE loss: 0.008733824 - KL loss: 0.14610267\n",
            "Epoch: 17 - Step: 34 - MSE loss: 0.009274271 - KL loss: 0.16061649\n",
            "Epoch: 17 - Step: 35 - MSE loss: 0.008745202 - KL loss: 0.15105966\n",
            "Epoch: 17 - Step: 36 - MSE loss: 0.009788357 - KL loss: 0.16010126\n",
            "Epoch: 17 - Step: 37 - MSE loss: 0.010638167 - KL loss: 0.18309948\n",
            "Epoch: 17 - Step: 38 - MSE loss: 0.0112135885 - KL loss: 0.19674404\n",
            "Epoch: 17 - Step: 39 - MSE loss: 0.011874587 - KL loss: 0.19204603\n",
            "Epoch: 17 - Step: 40 - MSE loss: 0.012551744 - KL loss: 0.18901148\n",
            "Epoch: 17 - Step: 41 - MSE loss: 0.012539726 - KL loss: 0.19542852\n",
            "Epoch: 17 - Step: 42 - MSE loss: 0.0114828795 - KL loss: 0.20268807\n",
            "Epoch: 17 - Step: 43 - MSE loss: 0.011588424 - KL loss: 0.20305178\n",
            "Epoch: 17 - Step: 44 - MSE loss: 0.011117016 - KL loss: 0.19539055\n",
            "Epoch: 17 - Step: 45 - MSE loss: 0.01213101 - KL loss: 0.2032841\n",
            "Epoch: 17 - Step: 46 - MSE loss: 0.0127063515 - KL loss: 0.20464826\n",
            "Epoch: 17 - Step: 47 - MSE loss: 0.013058931 - KL loss: 0.22241014\n",
            "Epoch: 17 - Step: 48 - MSE loss: 0.013795459 - KL loss: 0.21305624\n",
            "Epoch: 17 - Step: 49 - MSE loss: 0.012748851 - KL loss: 0.19882095\n",
            "Epoch: 17 - Step: 50 - MSE loss: 0.013118953 - KL loss: 0.18800245\n",
            "Epoch: 17 - Step: 51 - MSE loss: 0.014188345 - KL loss: 0.20736767\n",
            "Epoch: 17 - Step: 52 - MSE loss: 0.015206338 - KL loss: 0.21451971\n",
            "Epoch: 17 - Step: 53 - MSE loss: 0.013739668 - KL loss: 0.21911606\n",
            "Epoch: 17 - Step: 54 - MSE loss: 0.014182508 - KL loss: 0.2123154\n",
            "Epoch: 17 - Step: 55 - MSE loss: 0.014564841 - KL loss: 0.21079946\n",
            "Epoch: 17 - Step: 56 - MSE loss: 0.013209883 - KL loss: 0.21324736\n",
            "Epoch: 17 - Step: 57 - MSE loss: 0.014553298 - KL loss: 0.2110739\n",
            "Epoch: 17 - Step: 58 - MSE loss: 0.014737469 - KL loss: 0.21634357\n",
            "Epoch: 17 - Step: 59 - MSE loss: 0.015917405 - KL loss: 0.224345\n",
            "Epoch: 17 - Step: 60 - MSE loss: 0.014642681 - KL loss: 0.21520945\n",
            "Epoch: 17 - Step: 61 - MSE loss: 0.014391822 - KL loss: 0.22587001\n",
            "Epoch: 17 - Step: 62 - MSE loss: 0.015458375 - KL loss: 0.21404342\n",
            "Epoch: 17 - Step: 63 - MSE loss: 0.014279287 - KL loss: 0.21893853\n",
            "Epoch: 17 - Step: 64 - MSE loss: 0.015940946 - KL loss: 0.21937147\n",
            "Epoch: 17 - Step: 65 - MSE loss: 0.015234798 - KL loss: 0.22201386\n",
            "Epoch: 17 - Step: 66 - MSE loss: 0.014638557 - KL loss: 0.20160511\n",
            "Epoch: 17 - Step: 67 - MSE loss: 0.012716845 - KL loss: 0.19417776\n",
            "Epoch: 17 - Step: 68 - MSE loss: 0.01386068 - KL loss: 0.17505753\n",
            "Epoch: 17 - Step: 69 - MSE loss: 0.011993409 - KL loss: 0.18457802\n",
            "Epoch: 17 - Step: 70 - MSE loss: 0.012189344 - KL loss: 0.18218425\n",
            "Epoch: 17 - Step: 71 - MSE loss: 0.010364751 - KL loss: 0.16727957\n",
            "Epoch: 17 - Step: 72 - MSE loss: 0.009736973 - KL loss: 0.15170005\n",
            "Epoch: 17 - Step: 73 - MSE loss: 0.008605105 - KL loss: 0.15033269\n",
            "Epoch: 17 - Step: 74 - MSE loss: 0.008009761 - KL loss: 0.14263713\n",
            "Epoch: 17 - Step: 75 - MSE loss: 0.007493623 - KL loss: 0.14023164\n",
            "Epoch: 17 - Step: 76 - MSE loss: 0.008070601 - KL loss: 0.1412709\n",
            "Epoch: 17 - Step: 77 - MSE loss: 0.0075159264 - KL loss: 0.13493377\n",
            "Epoch: 17 - Step: 78 - MSE loss: 0.007955368 - KL loss: 0.13410401\n",
            "Epoch: 17 - Step: 79 - MSE loss: 0.0074128504 - KL loss: 0.12975551\n",
            "Epoch: 17 - Step: 80 - MSE loss: 0.007925597 - KL loss: 0.1422799\n",
            "Epoch: 17 - Step: 81 - MSE loss: 0.008347371 - KL loss: 0.13759574\n",
            "Epoch: 17 - Step: 82 - MSE loss: 0.008483399 - KL loss: 0.14261515\n",
            "Epoch: 17 - Step: 83 - MSE loss: 0.007675877 - KL loss: 0.12999204\n",
            "Epoch: 17 - Step: 84 - MSE loss: 0.0073640347 - KL loss: 0.13899782\n",
            "Epoch: 17 - Step: 85 - MSE loss: 0.0076759644 - KL loss: 0.14016996\n",
            "Epoch: 17 - Step: 86 - MSE loss: 0.0077085425 - KL loss: 0.13895655\n",
            "Epoch: 17 - Step: 87 - MSE loss: 0.008418971 - KL loss: 0.14309277\n",
            "Epoch: 17 - Step: 88 - MSE loss: 0.0072377883 - KL loss: 0.13863876\n",
            "Epoch: 17 - Step: 89 - MSE loss: 0.00855217 - KL loss: 0.15219077\n",
            "Epoch: 17 - Step: 90 - MSE loss: 0.007821707 - KL loss: 0.13956222\n",
            "Epoch: 17 - Step: 91 - MSE loss: 0.0073216506 - KL loss: 0.14187144\n",
            "Epoch: 17 - Step: 92 - MSE loss: 0.007959896 - KL loss: 0.14614025\n",
            "Epoch: 17 - Step: 93 - MSE loss: 0.007618135 - KL loss: 0.14309987\n",
            "Epoch: 17 - Step: 94 - MSE loss: 0.008390871 - KL loss: 0.1544986\n",
            "Epoch: 17 - Step: 95 - MSE loss: 0.008357227 - KL loss: 0.1420655\n",
            "Epoch: 17 - Step: 96 - MSE loss: 0.0073542953 - KL loss: 0.13968131\n",
            "Epoch: 17 - Step: 97 - MSE loss: 0.0078729 - KL loss: 0.14514188\n",
            "Epoch: 17 - Step: 98 - MSE loss: 0.008226858 - KL loss: 0.14152223\n",
            "Epoch: 17 - Step: 99 - MSE loss: 0.008466787 - KL loss: 0.14245044\n",
            "Epoch: 17 - Step: 100 - MSE loss: 0.008940185 - KL loss: 0.15933809\n",
            "Epoch: 17 - Step: 101 - MSE loss: 0.008137339 - KL loss: 0.14140114\n",
            "Epoch: 17 - Step: 102 - MSE loss: 0.009006728 - KL loss: 0.13996129\n",
            "Epoch: 17 - Step: 103 - MSE loss: 0.008725691 - KL loss: 0.14499462\n",
            "Epoch: 17 - Step: 104 - MSE loss: 0.008617383 - KL loss: 0.16005601\n",
            "Epoch: 17 - Step: 105 - MSE loss: 0.009410895 - KL loss: 0.16727084\n",
            "Epoch: 17 - Step: 106 - MSE loss: 0.009864135 - KL loss: 0.16074634\n",
            "Epoch: 17 - Step: 107 - MSE loss: 0.010115458 - KL loss: 0.1743432\n",
            "Epoch: 17 - Step: 108 - MSE loss: 0.011212443 - KL loss: 0.18035518\n",
            "Epoch: 17 - Step: 109 - MSE loss: 0.011110085 - KL loss: 0.18756102\n",
            "Epoch: 17 - Step: 110 - MSE loss: 0.01252547 - KL loss: 0.19969243\n",
            "Epoch: 17 - Step: 111 - MSE loss: 0.013024385 - KL loss: 0.19762796\n",
            "Epoch: 17 - Step: 112 - MSE loss: 0.013169291 - KL loss: 0.1983396\n",
            "Epoch: 17 - Step: 113 - MSE loss: 0.012995499 - KL loss: 0.20044886\n",
            "Epoch: 17 - Step: 114 - MSE loss: 0.013653268 - KL loss: 0.19659516\n",
            "Epoch: 17 - Step: 115 - MSE loss: 0.013323014 - KL loss: 0.20984182\n",
            "Epoch: 17 - Step: 116 - MSE loss: 0.015008246 - KL loss: 0.22257467\n",
            "Epoch: 17 - Step: 117 - MSE loss: 0.014316049 - KL loss: 0.21279317\n",
            "Epoch: 17 - Step: 118 - MSE loss: 0.0149105685 - KL loss: 0.20020421\n",
            "Epoch: 17 - Step: 119 - MSE loss: 0.015613534 - KL loss: 0.2128055\n",
            "Epoch: 17 - Step: 120 - MSE loss: 0.014104879 - KL loss: 0.2022067\n",
            "Epoch: 17 - Step: 121 - MSE loss: 0.015079201 - KL loss: 0.22487126\n",
            "Epoch: 17 - Step: 122 - MSE loss: 0.016958006 - KL loss: 0.19607489\n",
            "Epoch: 17 - Step: 123 - MSE loss: 0.018179124 - KL loss: 0.21678725\n",
            "Epoch: 17 - Step: 124 - MSE loss: 0.014708761 - KL loss: 0.19435196\n",
            "Epoch: 17 - Step: 125 - MSE loss: 0.015373339 - KL loss: 0.20918712\n",
            "Epoch: 17 - Step: 126 - MSE loss: 0.014096323 - KL loss: 0.20135233\n",
            "Epoch: 17 - Step: 127 - MSE loss: 0.015066002 - KL loss: 0.2144711\n",
            "Epoch: 17 - Step: 128 - MSE loss: 0.013649352 - KL loss: 0.22023875\n",
            "Epoch: 17 - Step: 129 - MSE loss: 0.013234499 - KL loss: 0.22283056\n",
            "Epoch: 17 - Step: 130 - MSE loss: 0.013522829 - KL loss: 0.22597222\n",
            "Epoch: 17 - Step: 131 - MSE loss: 0.014209256 - KL loss: 0.23369774\n",
            "Epoch: 17 - Step: 132 - MSE loss: 0.016112441 - KL loss: 0.21811622\n",
            "Epoch: 17 - Step: 133 - MSE loss: 0.018002292 - KL loss: 0.2209188\n",
            "Epoch: 17 - Step: 134 - MSE loss: 0.02068148 - KL loss: 0.19517612\n",
            "Epoch: 17 - Step: 135 - MSE loss: 0.019817417 - KL loss: 0.21439683\n",
            "Epoch: 17 - Step: 136 - MSE loss: 0.019080602 - KL loss: 0.17812312\n",
            "Epoch: 17 - Step: 137 - MSE loss: 0.016083037 - KL loss: 0.18478107\n",
            "Epoch: 17 - Step: 138 - MSE loss: 0.0171216 - KL loss: 0.21928121\n",
            "Epoch: 17 - Step: 139 - MSE loss: 0.016732866 - KL loss: 0.21671072\n",
            "Epoch: 17 - Step: 140 - MSE loss: 0.014984627 - KL loss: 0.2258118\n",
            "Epoch: 17 - Step: 141 - MSE loss: 0.015380208 - KL loss: 0.21061042\n",
            "Epoch: 17 - Step: 142 - MSE loss: 0.014345639 - KL loss: 0.20030649\n",
            "Epoch: 17 - Step: 143 - MSE loss: 0.014421326 - KL loss: 0.22009905\n",
            "Epoch: 17 - Step: 144 - MSE loss: 0.013615211 - KL loss: 0.21114117\n",
            "Epoch:  18\n",
            "Epoch: 18 - Step: 0 - MSE loss: 0.007594586 - KL loss: 0.15129161\n",
            "Epoch: 18 - Step: 1 - MSE loss: 0.0073581287 - KL loss: 0.15242232\n",
            "Epoch: 18 - Step: 2 - MSE loss: 0.0073601063 - KL loss: 0.15681794\n",
            "Epoch: 18 - Step: 3 - MSE loss: 0.0072085303 - KL loss: 0.15595207\n",
            "Epoch: 18 - Step: 4 - MSE loss: 0.006601185 - KL loss: 0.15780431\n",
            "Epoch: 18 - Step: 5 - MSE loss: 0.006972535 - KL loss: 0.15190043\n",
            "Epoch: 18 - Step: 6 - MSE loss: 0.0074415985 - KL loss: 0.14753084\n",
            "Epoch: 18 - Step: 7 - MSE loss: 0.007751416 - KL loss: 0.14537242\n",
            "Epoch: 18 - Step: 8 - MSE loss: 0.00780127 - KL loss: 0.15264459\n",
            "Epoch: 18 - Step: 9 - MSE loss: 0.0074117 - KL loss: 0.14982384\n",
            "Epoch: 18 - Step: 10 - MSE loss: 0.007989013 - KL loss: 0.13992739\n",
            "Epoch: 18 - Step: 11 - MSE loss: 0.0083165495 - KL loss: 0.144276\n",
            "Epoch: 18 - Step: 12 - MSE loss: 0.007778047 - KL loss: 0.14528002\n",
            "Epoch: 18 - Step: 13 - MSE loss: 0.007941121 - KL loss: 0.1444832\n",
            "Epoch: 18 - Step: 14 - MSE loss: 0.007866368 - KL loss: 0.13892518\n",
            "Epoch: 18 - Step: 15 - MSE loss: 0.0074345805 - KL loss: 0.14071244\n",
            "Epoch: 18 - Step: 16 - MSE loss: 0.007851179 - KL loss: 0.15039566\n",
            "Epoch: 18 - Step: 17 - MSE loss: 0.0075369906 - KL loss: 0.13626951\n",
            "Epoch: 18 - Step: 18 - MSE loss: 0.00705757 - KL loss: 0.13508268\n",
            "Epoch: 18 - Step: 19 - MSE loss: 0.006728266 - KL loss: 0.12742642\n",
            "Epoch: 18 - Step: 20 - MSE loss: 0.0071433294 - KL loss: 0.12839545\n",
            "Epoch: 18 - Step: 21 - MSE loss: 0.007792531 - KL loss: 0.1344173\n",
            "Epoch: 18 - Step: 22 - MSE loss: 0.00754451 - KL loss: 0.13347042\n",
            "Epoch: 18 - Step: 23 - MSE loss: 0.0077667716 - KL loss: 0.12930784\n",
            "Epoch: 18 - Step: 24 - MSE loss: 0.0070822057 - KL loss: 0.12321418\n",
            "Epoch: 18 - Step: 25 - MSE loss: 0.0066765943 - KL loss: 0.12516025\n",
            "Epoch: 18 - Step: 26 - MSE loss: 0.007289363 - KL loss: 0.12732814\n",
            "Epoch: 18 - Step: 27 - MSE loss: 0.0069424305 - KL loss: 0.123711795\n",
            "Epoch: 18 - Step: 28 - MSE loss: 0.007273825 - KL loss: 0.13002017\n",
            "Epoch: 18 - Step: 29 - MSE loss: 0.0066134264 - KL loss: 0.13312708\n",
            "Epoch: 18 - Step: 30 - MSE loss: 0.0066028405 - KL loss: 0.12975445\n",
            "Epoch: 18 - Step: 31 - MSE loss: 0.0070911027 - KL loss: 0.1337402\n",
            "Epoch: 18 - Step: 32 - MSE loss: 0.006878683 - KL loss: 0.1321665\n",
            "Epoch: 18 - Step: 33 - MSE loss: 0.007865497 - KL loss: 0.14043894\n",
            "Epoch: 18 - Step: 34 - MSE loss: 0.00868768 - KL loss: 0.15077324\n",
            "Epoch: 18 - Step: 35 - MSE loss: 0.008715976 - KL loss: 0.15327838\n",
            "Epoch: 18 - Step: 36 - MSE loss: 0.009934491 - KL loss: 0.17809208\n",
            "Epoch: 18 - Step: 37 - MSE loss: 0.009539274 - KL loss: 0.18127039\n",
            "Epoch: 18 - Step: 38 - MSE loss: 0.011782587 - KL loss: 0.19337395\n",
            "Epoch: 18 - Step: 39 - MSE loss: 0.011939931 - KL loss: 0.2009187\n",
            "Epoch: 18 - Step: 40 - MSE loss: 0.011976772 - KL loss: 0.18943873\n",
            "Epoch: 18 - Step: 41 - MSE loss: 0.011041034 - KL loss: 0.19507137\n",
            "Epoch: 18 - Step: 42 - MSE loss: 0.010655274 - KL loss: 0.20114419\n",
            "Epoch: 18 - Step: 43 - MSE loss: 0.010912366 - KL loss: 0.20764259\n",
            "Epoch: 18 - Step: 44 - MSE loss: 0.01091651 - KL loss: 0.19912106\n",
            "Epoch: 18 - Step: 45 - MSE loss: 0.011572838 - KL loss: 0.20948285\n",
            "Epoch: 18 - Step: 46 - MSE loss: 0.012051445 - KL loss: 0.20400026\n",
            "Epoch: 18 - Step: 47 - MSE loss: 0.01190243 - KL loss: 0.21192467\n",
            "Epoch: 18 - Step: 48 - MSE loss: 0.0130194435 - KL loss: 0.20390719\n",
            "Epoch: 18 - Step: 49 - MSE loss: 0.01315768 - KL loss: 0.20004041\n",
            "Epoch: 18 - Step: 50 - MSE loss: 0.01319931 - KL loss: 0.19535956\n",
            "Epoch: 18 - Step: 51 - MSE loss: 0.013113278 - KL loss: 0.1995281\n",
            "Epoch: 18 - Step: 52 - MSE loss: 0.012916996 - KL loss: 0.2042164\n",
            "Epoch: 18 - Step: 53 - MSE loss: 0.012781855 - KL loss: 0.20713827\n",
            "Epoch: 18 - Step: 54 - MSE loss: 0.013886052 - KL loss: 0.21595025\n",
            "Epoch: 18 - Step: 55 - MSE loss: 0.013967778 - KL loss: 0.20616956\n",
            "Epoch: 18 - Step: 56 - MSE loss: 0.014065812 - KL loss: 0.21567489\n",
            "Epoch: 18 - Step: 57 - MSE loss: 0.013626332 - KL loss: 0.21402687\n",
            "Epoch: 18 - Step: 58 - MSE loss: 0.013166088 - KL loss: 0.21185836\n",
            "Epoch: 18 - Step: 59 - MSE loss: 0.014447509 - KL loss: 0.20891243\n",
            "Epoch: 18 - Step: 60 - MSE loss: 0.014535245 - KL loss: 0.21574734\n",
            "Epoch: 18 - Step: 61 - MSE loss: 0.014534381 - KL loss: 0.22785217\n",
            "Epoch: 18 - Step: 62 - MSE loss: 0.014187104 - KL loss: 0.22012717\n",
            "Epoch: 18 - Step: 63 - MSE loss: 0.014506415 - KL loss: 0.21791781\n",
            "Epoch: 18 - Step: 64 - MSE loss: 0.015250083 - KL loss: 0.21719971\n",
            "Epoch: 18 - Step: 65 - MSE loss: 0.015022445 - KL loss: 0.2188068\n",
            "Epoch: 18 - Step: 66 - MSE loss: 0.013442009 - KL loss: 0.1905523\n",
            "Epoch: 18 - Step: 67 - MSE loss: 0.0128837 - KL loss: 0.19218588\n",
            "Epoch: 18 - Step: 68 - MSE loss: 0.01169634 - KL loss: 0.18257362\n",
            "Epoch: 18 - Step: 69 - MSE loss: 0.012291043 - KL loss: 0.18010834\n",
            "Epoch: 18 - Step: 70 - MSE loss: 0.010994476 - KL loss: 0.17219254\n",
            "Epoch: 18 - Step: 71 - MSE loss: 0.009459544 - KL loss: 0.1598199\n",
            "Epoch: 18 - Step: 72 - MSE loss: 0.008501377 - KL loss: 0.15316913\n",
            "Epoch: 18 - Step: 73 - MSE loss: 0.009459215 - KL loss: 0.15751699\n",
            "Epoch: 18 - Step: 74 - MSE loss: 0.008247239 - KL loss: 0.14578253\n",
            "Epoch: 18 - Step: 75 - MSE loss: 0.0068199094 - KL loss: 0.13521704\n",
            "Epoch: 18 - Step: 76 - MSE loss: 0.0076847994 - KL loss: 0.13681823\n",
            "Epoch: 18 - Step: 77 - MSE loss: 0.007856821 - KL loss: 0.13583067\n",
            "Epoch: 18 - Step: 78 - MSE loss: 0.0078524705 - KL loss: 0.1309801\n",
            "Epoch: 18 - Step: 79 - MSE loss: 0.0074716546 - KL loss: 0.12766185\n",
            "Epoch: 18 - Step: 80 - MSE loss: 0.008398086 - KL loss: 0.14568982\n",
            "Epoch: 18 - Step: 81 - MSE loss: 0.0070822816 - KL loss: 0.12855925\n",
            "Epoch: 18 - Step: 82 - MSE loss: 0.0077748694 - KL loss: 0.13234495\n",
            "Epoch: 18 - Step: 83 - MSE loss: 0.007529447 - KL loss: 0.13524416\n",
            "Epoch: 18 - Step: 84 - MSE loss: 0.0074929497 - KL loss: 0.13417053\n",
            "Epoch: 18 - Step: 85 - MSE loss: 0.007610779 - KL loss: 0.14043806\n",
            "Epoch: 18 - Step: 86 - MSE loss: 0.0076801223 - KL loss: 0.13351089\n",
            "Epoch: 18 - Step: 87 - MSE loss: 0.008367562 - KL loss: 0.13574056\n",
            "Epoch: 18 - Step: 88 - MSE loss: 0.008106637 - KL loss: 0.14053768\n",
            "Epoch: 18 - Step: 89 - MSE loss: 0.008274325 - KL loss: 0.14849114\n",
            "Epoch: 18 - Step: 90 - MSE loss: 0.008441033 - KL loss: 0.15380387\n",
            "Epoch: 18 - Step: 91 - MSE loss: 0.0077181626 - KL loss: 0.14982602\n",
            "Epoch: 18 - Step: 92 - MSE loss: 0.008106257 - KL loss: 0.14283153\n",
            "Epoch: 18 - Step: 93 - MSE loss: 0.008109566 - KL loss: 0.14703766\n",
            "Epoch: 18 - Step: 94 - MSE loss: 0.008280096 - KL loss: 0.13819776\n",
            "Epoch: 18 - Step: 95 - MSE loss: 0.0075457674 - KL loss: 0.14072889\n",
            "Epoch: 18 - Step: 96 - MSE loss: 0.009147971 - KL loss: 0.14913039\n",
            "Epoch: 18 - Step: 97 - MSE loss: 0.007754507 - KL loss: 0.13927975\n",
            "Epoch: 18 - Step: 98 - MSE loss: 0.0077200704 - KL loss: 0.14428014\n",
            "Epoch: 18 - Step: 99 - MSE loss: 0.00760157 - KL loss: 0.147645\n",
            "Epoch: 18 - Step: 100 - MSE loss: 0.007629247 - KL loss: 0.14334336\n",
            "Epoch: 18 - Step: 101 - MSE loss: 0.0071134367 - KL loss: 0.1430045\n",
            "Epoch: 18 - Step: 102 - MSE loss: 0.00719263 - KL loss: 0.14402904\n",
            "Epoch: 18 - Step: 103 - MSE loss: 0.007419435 - KL loss: 0.14925599\n",
            "Epoch: 18 - Step: 104 - MSE loss: 0.008046956 - KL loss: 0.15956041\n",
            "Epoch: 18 - Step: 105 - MSE loss: 0.00928184 - KL loss: 0.17285345\n",
            "Epoch: 18 - Step: 106 - MSE loss: 0.009502928 - KL loss: 0.17482962\n",
            "Epoch: 18 - Step: 107 - MSE loss: 0.009891291 - KL loss: 0.17559528\n",
            "Epoch: 18 - Step: 108 - MSE loss: 0.00996284 - KL loss: 0.1829599\n",
            "Epoch: 18 - Step: 109 - MSE loss: 0.010588139 - KL loss: 0.19084743\n",
            "Epoch: 18 - Step: 110 - MSE loss: 0.011885517 - KL loss: 0.2026411\n",
            "Epoch: 18 - Step: 111 - MSE loss: 0.011848792 - KL loss: 0.20241505\n",
            "Epoch: 18 - Step: 112 - MSE loss: 0.011578672 - KL loss: 0.20055015\n",
            "Epoch: 18 - Step: 113 - MSE loss: 0.012785827 - KL loss: 0.20422585\n",
            "Epoch: 18 - Step: 114 - MSE loss: 0.013939169 - KL loss: 0.19933067\n",
            "Epoch: 18 - Step: 115 - MSE loss: 0.01393563 - KL loss: 0.21131992\n",
            "Epoch: 18 - Step: 116 - MSE loss: 0.0134652415 - KL loss: 0.20214519\n",
            "Epoch: 18 - Step: 117 - MSE loss: 0.013204732 - KL loss: 0.20013061\n",
            "Epoch: 18 - Step: 118 - MSE loss: 0.012833137 - KL loss: 0.2072159\n",
            "Epoch: 18 - Step: 119 - MSE loss: 0.013939608 - KL loss: 0.20576137\n",
            "Epoch: 18 - Step: 120 - MSE loss: 0.011650925 - KL loss: 0.21200325\n",
            "Epoch: 18 - Step: 121 - MSE loss: 0.011649775 - KL loss: 0.21221219\n",
            "Epoch: 18 - Step: 122 - MSE loss: 0.012779989 - KL loss: 0.20691955\n",
            "Epoch: 18 - Step: 123 - MSE loss: 0.011500324 - KL loss: 0.20814335\n",
            "Epoch: 18 - Step: 124 - MSE loss: 0.012672324 - KL loss: 0.21030411\n",
            "Epoch: 18 - Step: 125 - MSE loss: 0.012918871 - KL loss: 0.2155464\n",
            "Epoch: 18 - Step: 126 - MSE loss: 0.013133057 - KL loss: 0.22306216\n",
            "Epoch: 18 - Step: 127 - MSE loss: 0.013630118 - KL loss: 0.20656887\n",
            "Epoch: 18 - Step: 128 - MSE loss: 0.013016756 - KL loss: 0.21818021\n",
            "Epoch: 18 - Step: 129 - MSE loss: 0.01361189 - KL loss: 0.2144444\n",
            "Epoch: 18 - Step: 130 - MSE loss: 0.016686939 - KL loss: 0.2160686\n",
            "Epoch: 18 - Step: 131 - MSE loss: 0.021106673 - KL loss: 0.18376867\n",
            "Epoch: 18 - Step: 132 - MSE loss: 0.022164637 - KL loss: 0.22087829\n",
            "Epoch: 18 - Step: 133 - MSE loss: 0.020017114 - KL loss: 0.18607378\n",
            "Epoch: 18 - Step: 134 - MSE loss: 0.0182225 - KL loss: 0.18244413\n",
            "Epoch: 18 - Step: 135 - MSE loss: 0.01728814 - KL loss: 0.22362238\n",
            "Epoch: 18 - Step: 136 - MSE loss: 0.017451057 - KL loss: 0.21402767\n",
            "Epoch: 18 - Step: 137 - MSE loss: 0.01634995 - KL loss: 0.24233279\n",
            "Epoch: 18 - Step: 138 - MSE loss: 0.016595183 - KL loss: 0.20192817\n",
            "Epoch: 18 - Step: 139 - MSE loss: 0.015325084 - KL loss: 0.20336446\n",
            "Epoch: 18 - Step: 140 - MSE loss: 0.01485899 - KL loss: 0.21675678\n",
            "Epoch: 18 - Step: 141 - MSE loss: 0.014366157 - KL loss: 0.20487136\n",
            "Epoch: 18 - Step: 142 - MSE loss: 0.014405075 - KL loss: 0.20271625\n",
            "Epoch: 18 - Step: 143 - MSE loss: 0.013662629 - KL loss: 0.20083502\n",
            "Epoch: 18 - Step: 144 - MSE loss: 0.014700753 - KL loss: 0.2103592\n",
            "Epoch:  19\n",
            "Epoch: 19 - Step: 0 - MSE loss: 0.0070505277 - KL loss: 0.15191278\n",
            "Epoch: 19 - Step: 1 - MSE loss: 0.0070071 - KL loss: 0.14684962\n",
            "Epoch: 19 - Step: 2 - MSE loss: 0.006976757 - KL loss: 0.15295023\n",
            "Epoch: 19 - Step: 3 - MSE loss: 0.006882982 - KL loss: 0.16315413\n",
            "Epoch: 19 - Step: 4 - MSE loss: 0.0066857752 - KL loss: 0.15556455\n",
            "Epoch: 19 - Step: 5 - MSE loss: 0.006951973 - KL loss: 0.14669316\n",
            "Epoch: 19 - Step: 6 - MSE loss: 0.0074168425 - KL loss: 0.14530145\n",
            "Epoch: 19 - Step: 7 - MSE loss: 0.008124386 - KL loss: 0.14974302\n",
            "Epoch: 19 - Step: 8 - MSE loss: 0.007978088 - KL loss: 0.1470845\n",
            "Epoch: 19 - Step: 9 - MSE loss: 0.008033852 - KL loss: 0.1425663\n",
            "Epoch: 19 - Step: 10 - MSE loss: 0.007887082 - KL loss: 0.13897002\n",
            "Epoch: 19 - Step: 11 - MSE loss: 0.0076331566 - KL loss: 0.14308646\n",
            "Epoch: 19 - Step: 12 - MSE loss: 0.007583482 - KL loss: 0.14332655\n",
            "Epoch: 19 - Step: 13 - MSE loss: 0.0070895157 - KL loss: 0.14365265\n",
            "Epoch: 19 - Step: 14 - MSE loss: 0.007695425 - KL loss: 0.14884368\n",
            "Epoch: 19 - Step: 15 - MSE loss: 0.0076579526 - KL loss: 0.14823887\n",
            "Epoch: 19 - Step: 16 - MSE loss: 0.0075484496 - KL loss: 0.14365546\n",
            "Epoch: 19 - Step: 17 - MSE loss: 0.007512828 - KL loss: 0.14591093\n",
            "Epoch: 19 - Step: 18 - MSE loss: 0.0069203624 - KL loss: 0.1398493\n",
            "Epoch: 19 - Step: 19 - MSE loss: 0.0062675276 - KL loss: 0.122822225\n",
            "Epoch: 19 - Step: 20 - MSE loss: 0.0067427126 - KL loss: 0.13107117\n",
            "Epoch: 19 - Step: 21 - MSE loss: 0.0070640035 - KL loss: 0.12756187\n",
            "Epoch: 19 - Step: 22 - MSE loss: 0.0068190624 - KL loss: 0.1248694\n",
            "Epoch: 19 - Step: 23 - MSE loss: 0.006326766 - KL loss: 0.12447412\n",
            "Epoch: 19 - Step: 24 - MSE loss: 0.0068302155 - KL loss: 0.12477788\n",
            "Epoch: 19 - Step: 25 - MSE loss: 0.006316386 - KL loss: 0.1319206\n",
            "Epoch: 19 - Step: 26 - MSE loss: 0.00692953 - KL loss: 0.13116404\n",
            "Epoch: 19 - Step: 27 - MSE loss: 0.006561974 - KL loss: 0.12676257\n",
            "Epoch: 19 - Step: 28 - MSE loss: 0.007439725 - KL loss: 0.13564768\n",
            "Epoch: 19 - Step: 29 - MSE loss: 0.006611334 - KL loss: 0.12070854\n",
            "Epoch: 19 - Step: 30 - MSE loss: 0.0066245706 - KL loss: 0.12054107\n",
            "Epoch: 19 - Step: 31 - MSE loss: 0.0066672186 - KL loss: 0.12772873\n",
            "Epoch: 19 - Step: 32 - MSE loss: 0.0076214783 - KL loss: 0.13909335\n",
            "Epoch: 19 - Step: 33 - MSE loss: 0.0088183535 - KL loss: 0.14584069\n",
            "Epoch: 19 - Step: 34 - MSE loss: 0.00845909 - KL loss: 0.16089247\n",
            "Epoch: 19 - Step: 35 - MSE loss: 0.00820366 - KL loss: 0.15411541\n",
            "Epoch: 19 - Step: 36 - MSE loss: 0.009920512 - KL loss: 0.17720231\n",
            "Epoch: 19 - Step: 37 - MSE loss: 0.009636422 - KL loss: 0.1686584\n",
            "Epoch: 19 - Step: 38 - MSE loss: 0.011041245 - KL loss: 0.18670197\n",
            "Epoch: 19 - Step: 39 - MSE loss: 0.010814422 - KL loss: 0.16898552\n",
            "Epoch: 19 - Step: 40 - MSE loss: 0.010797688 - KL loss: 0.17778474\n",
            "Epoch: 19 - Step: 41 - MSE loss: 0.0118792625 - KL loss: 0.1958333\n",
            "Epoch: 19 - Step: 42 - MSE loss: 0.011273048 - KL loss: 0.19268316\n",
            "Epoch: 19 - Step: 43 - MSE loss: 0.010993672 - KL loss: 0.20675375\n",
            "Epoch: 19 - Step: 44 - MSE loss: 0.010323261 - KL loss: 0.19947733\n",
            "Epoch: 19 - Step: 45 - MSE loss: 0.011102949 - KL loss: 0.20672955\n",
            "Epoch: 19 - Step: 46 - MSE loss: 0.01181237 - KL loss: 0.21020295\n",
            "Epoch: 19 - Step: 47 - MSE loss: 0.011566835 - KL loss: 0.20326482\n",
            "Epoch: 19 - Step: 48 - MSE loss: 0.012581129 - KL loss: 0.20600176\n",
            "Epoch: 19 - Step: 49 - MSE loss: 0.012875841 - KL loss: 0.20731708\n",
            "Epoch: 19 - Step: 50 - MSE loss: 0.013133346 - KL loss: 0.20089865\n",
            "Epoch: 19 - Step: 51 - MSE loss: 0.013218995 - KL loss: 0.1978625\n",
            "Epoch: 19 - Step: 52 - MSE loss: 0.014100061 - KL loss: 0.20925546\n",
            "Epoch: 19 - Step: 53 - MSE loss: 0.012852089 - KL loss: 0.20888352\n",
            "Epoch: 19 - Step: 54 - MSE loss: 0.013767171 - KL loss: 0.20456013\n",
            "Epoch: 19 - Step: 55 - MSE loss: 0.013573658 - KL loss: 0.20773558\n",
            "Epoch: 19 - Step: 56 - MSE loss: 0.013112363 - KL loss: 0.20188369\n",
            "Epoch: 19 - Step: 57 - MSE loss: 0.013311909 - KL loss: 0.20628113\n",
            "Epoch: 19 - Step: 58 - MSE loss: 0.013473763 - KL loss: 0.20712006\n",
            "Epoch: 19 - Step: 59 - MSE loss: 0.013922572 - KL loss: 0.21157081\n",
            "Epoch: 19 - Step: 60 - MSE loss: 0.013919831 - KL loss: 0.2200602\n",
            "Epoch: 19 - Step: 61 - MSE loss: 0.013348639 - KL loss: 0.22613183\n",
            "Epoch: 19 - Step: 62 - MSE loss: 0.013811874 - KL loss: 0.2170361\n",
            "Epoch: 19 - Step: 63 - MSE loss: 0.01383854 - KL loss: 0.22136545\n",
            "Epoch: 19 - Step: 64 - MSE loss: 0.01387988 - KL loss: 0.21868756\n",
            "Epoch: 19 - Step: 65 - MSE loss: 0.0141706625 - KL loss: 0.2205123\n",
            "Epoch: 19 - Step: 66 - MSE loss: 0.013860949 - KL loss: 0.19697252\n",
            "Epoch: 19 - Step: 67 - MSE loss: 0.011881545 - KL loss: 0.19847144\n",
            "Epoch: 19 - Step: 68 - MSE loss: 0.010748256 - KL loss: 0.18081936\n",
            "Epoch: 19 - Step: 69 - MSE loss: 0.010911796 - KL loss: 0.17747122\n",
            "Epoch: 19 - Step: 70 - MSE loss: 0.010055968 - KL loss: 0.1797857\n",
            "Epoch: 19 - Step: 71 - MSE loss: 0.008773368 - KL loss: 0.15996483\n",
            "Epoch: 19 - Step: 72 - MSE loss: 0.008402188 - KL loss: 0.15748662\n",
            "Epoch: 19 - Step: 73 - MSE loss: 0.007977734 - KL loss: 0.14626604\n",
            "Epoch: 19 - Step: 74 - MSE loss: 0.0078862365 - KL loss: 0.14094831\n",
            "Epoch: 19 - Step: 75 - MSE loss: 0.0075843576 - KL loss: 0.13189979\n",
            "Epoch: 19 - Step: 76 - MSE loss: 0.007513098 - KL loss: 0.12768537\n",
            "Epoch: 19 - Step: 77 - MSE loss: 0.0068182033 - KL loss: 0.13819847\n",
            "Epoch: 19 - Step: 78 - MSE loss: 0.007519662 - KL loss: 0.13704637\n",
            "Epoch: 19 - Step: 79 - MSE loss: 0.0068731685 - KL loss: 0.122797765\n",
            "Epoch: 19 - Step: 80 - MSE loss: 0.007426977 - KL loss: 0.13362232\n",
            "Epoch: 19 - Step: 81 - MSE loss: 0.007634872 - KL loss: 0.13580503\n",
            "Epoch: 19 - Step: 82 - MSE loss: 0.008463836 - KL loss: 0.15257826\n",
            "Epoch: 19 - Step: 83 - MSE loss: 0.0075056497 - KL loss: 0.13156131\n",
            "Epoch: 19 - Step: 84 - MSE loss: 0.0072046774 - KL loss: 0.1293926\n",
            "Epoch: 19 - Step: 85 - MSE loss: 0.008755804 - KL loss: 0.1353638\n",
            "Epoch: 19 - Step: 86 - MSE loss: 0.009242833 - KL loss: 0.1370709\n",
            "Epoch: 19 - Step: 87 - MSE loss: 0.009682727 - KL loss: 0.13351908\n",
            "Epoch: 19 - Step: 88 - MSE loss: 0.009216331 - KL loss: 0.1318666\n",
            "Epoch: 19 - Step: 89 - MSE loss: 0.0084449565 - KL loss: 0.13704622\n",
            "Epoch: 19 - Step: 90 - MSE loss: 0.0073546953 - KL loss: 0.14523776\n",
            "Epoch: 19 - Step: 91 - MSE loss: 0.0075533795 - KL loss: 0.15425642\n",
            "Epoch: 19 - Step: 92 - MSE loss: 0.0069429516 - KL loss: 0.14564577\n",
            "Epoch: 19 - Step: 93 - MSE loss: 0.0074128234 - KL loss: 0.14140825\n",
            "Epoch: 19 - Step: 94 - MSE loss: 0.0067547313 - KL loss: 0.14204225\n",
            "Epoch: 19 - Step: 95 - MSE loss: 0.008361821 - KL loss: 0.14815521\n",
            "Epoch: 19 - Step: 96 - MSE loss: 0.0068834014 - KL loss: 0.14168233\n",
            "Epoch: 19 - Step: 97 - MSE loss: 0.007870947 - KL loss: 0.14625055\n",
            "Epoch: 19 - Step: 98 - MSE loss: 0.0075002383 - KL loss: 0.14474338\n",
            "Epoch: 19 - Step: 99 - MSE loss: 0.0071862726 - KL loss: 0.14712512\n",
            "Epoch: 19 - Step: 100 - MSE loss: 0.007377653 - KL loss: 0.14469756\n",
            "Epoch: 19 - Step: 101 - MSE loss: 0.006878957 - KL loss: 0.14176844\n",
            "Epoch: 19 - Step: 102 - MSE loss: 0.007319184 - KL loss: 0.1445351\n",
            "Epoch: 19 - Step: 103 - MSE loss: 0.0067562857 - KL loss: 0.14288183\n",
            "Epoch: 19 - Step: 104 - MSE loss: 0.0074523953 - KL loss: 0.14826725\n",
            "Epoch: 19 - Step: 105 - MSE loss: 0.008171275 - KL loss: 0.16716656\n",
            "Epoch: 19 - Step: 106 - MSE loss: 0.008967286 - KL loss: 0.171647\n",
            "Epoch: 19 - Step: 107 - MSE loss: 0.010267439 - KL loss: 0.18085378\n",
            "Epoch: 19 - Step: 108 - MSE loss: 0.010863741 - KL loss: 0.19295987\n",
            "Epoch: 19 - Step: 109 - MSE loss: 0.010553851 - KL loss: 0.19288087\n",
            "Epoch: 19 - Step: 110 - MSE loss: 0.009805639 - KL loss: 0.18808408\n",
            "Epoch: 19 - Step: 111 - MSE loss: 0.0106039 - KL loss: 0.19138268\n",
            "Epoch: 19 - Step: 112 - MSE loss: 0.01279677 - KL loss: 0.20697254\n",
            "Epoch: 19 - Step: 113 - MSE loss: 0.012270126 - KL loss: 0.20588695\n",
            "Epoch: 19 - Step: 114 - MSE loss: 0.013372411 - KL loss: 0.1985907\n",
            "Epoch: 19 - Step: 115 - MSE loss: 0.012880082 - KL loss: 0.20635115\n",
            "Epoch: 19 - Step: 116 - MSE loss: 0.0128386915 - KL loss: 0.21302542\n",
            "Epoch: 19 - Step: 117 - MSE loss: 0.013028563 - KL loss: 0.20979975\n",
            "Epoch: 19 - Step: 118 - MSE loss: 0.013078496 - KL loss: 0.20789722\n",
            "Epoch: 19 - Step: 119 - MSE loss: 0.012023676 - KL loss: 0.20416714\n",
            "Epoch: 19 - Step: 120 - MSE loss: 0.011802907 - KL loss: 0.21062456\n",
            "Epoch: 19 - Step: 121 - MSE loss: 0.012012062 - KL loss: 0.19939214\n",
            "Epoch: 19 - Step: 122 - MSE loss: 0.012173164 - KL loss: 0.20789853\n",
            "Epoch: 19 - Step: 123 - MSE loss: 0.012110319 - KL loss: 0.21394597\n",
            "Epoch: 19 - Step: 124 - MSE loss: 0.012555722 - KL loss: 0.20043774\n",
            "Epoch: 19 - Step: 125 - MSE loss: 0.0137210535 - KL loss: 0.21801594\n",
            "Epoch: 19 - Step: 126 - MSE loss: 0.014441689 - KL loss: 0.20283234\n",
            "Epoch: 19 - Step: 127 - MSE loss: 0.01315105 - KL loss: 0.21340905\n",
            "Epoch: 19 - Step: 128 - MSE loss: 0.012142382 - KL loss: 0.20917204\n",
            "Epoch: 19 - Step: 129 - MSE loss: 0.012524362 - KL loss: 0.21483275\n",
            "Epoch: 19 - Step: 130 - MSE loss: 0.012661524 - KL loss: 0.21390757\n",
            "Epoch: 19 - Step: 131 - MSE loss: 0.012562617 - KL loss: 0.21429129\n",
            "Epoch: 19 - Step: 132 - MSE loss: 0.012752703 - KL loss: 0.22957526\n",
            "Epoch: 19 - Step: 133 - MSE loss: 0.014233417 - KL loss: 0.22517131\n",
            "Epoch: 19 - Step: 134 - MSE loss: 0.01475696 - KL loss: 0.22883955\n",
            "Epoch: 19 - Step: 135 - MSE loss: 0.013903749 - KL loss: 0.20556416\n",
            "Epoch: 19 - Step: 136 - MSE loss: 0.014106373 - KL loss: 0.20114428\n",
            "Epoch: 19 - Step: 137 - MSE loss: 0.013272271 - KL loss: 0.19790338\n",
            "Epoch: 19 - Step: 138 - MSE loss: 0.013784073 - KL loss: 0.20962778\n",
            "Epoch: 19 - Step: 139 - MSE loss: 0.014791156 - KL loss: 0.19483122\n",
            "Epoch: 19 - Step: 140 - MSE loss: 0.0136087565 - KL loss: 0.21236025\n",
            "Epoch: 19 - Step: 141 - MSE loss: 0.013012886 - KL loss: 0.1921053\n",
            "Epoch: 19 - Step: 142 - MSE loss: 0.012770413 - KL loss: 0.20900707\n",
            "Epoch: 19 - Step: 143 - MSE loss: 0.013687224 - KL loss: 0.20829917\n",
            "Epoch: 19 - Step: 144 - MSE loss: 0.013469042 - KL loss: 0.20652755\n",
            "Epoch:  20\n",
            "Epoch: 20 - Step: 0 - MSE loss: 0.006389354 - KL loss: 0.15068518\n",
            "Epoch: 20 - Step: 1 - MSE loss: 0.006479196 - KL loss: 0.15600368\n",
            "Epoch: 20 - Step: 2 - MSE loss: 0.0069012116 - KL loss: 0.15702857\n",
            "Epoch: 20 - Step: 3 - MSE loss: 0.007074086 - KL loss: 0.15277812\n",
            "Epoch: 20 - Step: 4 - MSE loss: 0.005956786 - KL loss: 0.1444857\n",
            "Epoch: 20 - Step: 5 - MSE loss: 0.00649342 - KL loss: 0.14101748\n",
            "Epoch: 20 - Step: 6 - MSE loss: 0.0063647474 - KL loss: 0.13795485\n",
            "Epoch: 20 - Step: 7 - MSE loss: 0.007725198 - KL loss: 0.14794986\n",
            "Epoch: 20 - Step: 8 - MSE loss: 0.0070446623 - KL loss: 0.14195316\n",
            "Epoch: 20 - Step: 9 - MSE loss: 0.0077184755 - KL loss: 0.14475481\n",
            "Epoch: 20 - Step: 10 - MSE loss: 0.007695479 - KL loss: 0.14398378\n",
            "Epoch: 20 - Step: 11 - MSE loss: 0.0078609 - KL loss: 0.14315331\n",
            "Epoch: 20 - Step: 12 - MSE loss: 0.0074746315 - KL loss: 0.14555395\n",
            "Epoch: 20 - Step: 13 - MSE loss: 0.007763862 - KL loss: 0.13425842\n",
            "Epoch: 20 - Step: 14 - MSE loss: 0.008298834 - KL loss: 0.1392693\n",
            "Epoch: 20 - Step: 15 - MSE loss: 0.008778844 - KL loss: 0.14341652\n",
            "Epoch: 20 - Step: 16 - MSE loss: 0.00819072 - KL loss: 0.13873944\n",
            "Epoch: 20 - Step: 17 - MSE loss: 0.007597614 - KL loss: 0.13155678\n",
            "Epoch: 20 - Step: 18 - MSE loss: 0.006638491 - KL loss: 0.12663387\n",
            "Epoch: 20 - Step: 19 - MSE loss: 0.006754371 - KL loss: 0.13411607\n",
            "Epoch: 20 - Step: 20 - MSE loss: 0.0067345356 - KL loss: 0.12994052\n",
            "Epoch: 20 - Step: 21 - MSE loss: 0.0065104794 - KL loss: 0.12173097\n",
            "Epoch: 20 - Step: 22 - MSE loss: 0.0063478276 - KL loss: 0.12451521\n",
            "Epoch: 20 - Step: 23 - MSE loss: 0.006513013 - KL loss: 0.13001247\n",
            "Epoch: 20 - Step: 24 - MSE loss: 0.00653459 - KL loss: 0.1273633\n",
            "Epoch: 20 - Step: 25 - MSE loss: 0.0062561743 - KL loss: 0.12896179\n",
            "Epoch: 20 - Step: 26 - MSE loss: 0.006416447 - KL loss: 0.12862268\n",
            "Epoch: 20 - Step: 27 - MSE loss: 0.0067574903 - KL loss: 0.124300376\n",
            "Epoch: 20 - Step: 28 - MSE loss: 0.0067730653 - KL loss: 0.12604044\n",
            "Epoch: 20 - Step: 29 - MSE loss: 0.00705811 - KL loss: 0.12700999\n",
            "Epoch: 20 - Step: 30 - MSE loss: 0.0058343387 - KL loss: 0.12105918\n",
            "Epoch: 20 - Step: 31 - MSE loss: 0.0055330377 - KL loss: 0.12371266\n",
            "Epoch: 20 - Step: 32 - MSE loss: 0.0072476235 - KL loss: 0.13085568\n",
            "Epoch: 20 - Step: 33 - MSE loss: 0.008212902 - KL loss: 0.13897286\n",
            "Epoch: 20 - Step: 34 - MSE loss: 0.007992944 - KL loss: 0.15534255\n",
            "Epoch: 20 - Step: 35 - MSE loss: 0.007753003 - KL loss: 0.15305167\n",
            "Epoch: 20 - Step: 36 - MSE loss: 0.008864816 - KL loss: 0.16405898\n",
            "Epoch: 20 - Step: 37 - MSE loss: 0.009281974 - KL loss: 0.18104741\n",
            "Epoch: 20 - Step: 38 - MSE loss: 0.00999141 - KL loss: 0.1892245\n",
            "Epoch: 20 - Step: 39 - MSE loss: 0.010810805 - KL loss: 0.19654316\n",
            "Epoch: 20 - Step: 40 - MSE loss: 0.011514078 - KL loss: 0.19575548\n",
            "Epoch: 20 - Step: 41 - MSE loss: 0.0117413765 - KL loss: 0.19375433\n",
            "Epoch: 20 - Step: 42 - MSE loss: 0.010154278 - KL loss: 0.18734112\n",
            "Epoch: 20 - Step: 43 - MSE loss: 0.0112148775 - KL loss: 0.19557656\n",
            "Epoch: 20 - Step: 44 - MSE loss: 0.011490162 - KL loss: 0.2008332\n",
            "Epoch: 20 - Step: 45 - MSE loss: 0.010081062 - KL loss: 0.19472024\n",
            "Epoch: 20 - Step: 46 - MSE loss: 0.011536422 - KL loss: 0.21028475\n",
            "Epoch: 20 - Step: 47 - MSE loss: 0.011409911 - KL loss: 0.20080866\n",
            "Epoch: 20 - Step: 48 - MSE loss: 0.011785962 - KL loss: 0.20891312\n",
            "Epoch: 20 - Step: 49 - MSE loss: 0.010888276 - KL loss: 0.18968582\n",
            "Epoch: 20 - Step: 50 - MSE loss: 0.011053219 - KL loss: 0.19723433\n",
            "Epoch: 20 - Step: 51 - MSE loss: 0.013501133 - KL loss: 0.20784658\n",
            "Epoch: 20 - Step: 52 - MSE loss: 0.013108924 - KL loss: 0.20885727\n",
            "Epoch: 20 - Step: 53 - MSE loss: 0.013621782 - KL loss: 0.2172856\n",
            "Epoch: 20 - Step: 54 - MSE loss: 0.012079413 - KL loss: 0.2005099\n",
            "Epoch: 20 - Step: 55 - MSE loss: 0.0134737035 - KL loss: 0.21580482\n",
            "Epoch: 20 - Step: 56 - MSE loss: 0.0142908385 - KL loss: 0.20401329\n",
            "Epoch: 20 - Step: 57 - MSE loss: 0.01507264 - KL loss: 0.20614731\n",
            "Epoch: 20 - Step: 58 - MSE loss: 0.01566761 - KL loss: 0.20061426\n",
            "Epoch: 20 - Step: 59 - MSE loss: 0.014767292 - KL loss: 0.21517192\n",
            "Epoch: 20 - Step: 60 - MSE loss: 0.014854313 - KL loss: 0.20330575\n",
            "Epoch: 20 - Step: 61 - MSE loss: 0.014999051 - KL loss: 0.23121703\n",
            "Epoch: 20 - Step: 62 - MSE loss: 0.014058593 - KL loss: 0.20782971\n",
            "Epoch: 20 - Step: 63 - MSE loss: 0.015001442 - KL loss: 0.22215931\n",
            "Epoch: 20 - Step: 64 - MSE loss: 0.013668713 - KL loss: 0.21942443\n",
            "Epoch: 20 - Step: 65 - MSE loss: 0.013991144 - KL loss: 0.20197609\n",
            "Epoch: 20 - Step: 66 - MSE loss: 0.013013751 - KL loss: 0.20045227\n",
            "Epoch: 20 - Step: 67 - MSE loss: 0.011548302 - KL loss: 0.18103535\n",
            "Epoch: 20 - Step: 68 - MSE loss: 0.011300174 - KL loss: 0.18901058\n",
            "Epoch: 20 - Step: 69 - MSE loss: 0.011079874 - KL loss: 0.1782166\n",
            "Epoch: 20 - Step: 70 - MSE loss: 0.00954858 - KL loss: 0.16304338\n",
            "Epoch: 20 - Step: 71 - MSE loss: 0.008516749 - KL loss: 0.15857345\n",
            "Epoch: 20 - Step: 72 - MSE loss: 0.008756854 - KL loss: 0.1552015\n",
            "Epoch: 20 - Step: 73 - MSE loss: 0.008059135 - KL loss: 0.15377964\n",
            "Epoch: 20 - Step: 74 - MSE loss: 0.008848194 - KL loss: 0.1556907\n",
            "Epoch: 20 - Step: 75 - MSE loss: 0.0073824115 - KL loss: 0.14435975\n",
            "Epoch: 20 - Step: 76 - MSE loss: 0.0069372193 - KL loss: 0.13860312\n",
            "Epoch: 20 - Step: 77 - MSE loss: 0.0075159543 - KL loss: 0.13843013\n",
            "Epoch: 20 - Step: 78 - MSE loss: 0.006727192 - KL loss: 0.12976271\n",
            "Epoch: 20 - Step: 79 - MSE loss: 0.0072475723 - KL loss: 0.13723657\n",
            "Epoch: 20 - Step: 80 - MSE loss: 0.0071816887 - KL loss: 0.13426638\n",
            "Epoch: 20 - Step: 81 - MSE loss: 0.0065408354 - KL loss: 0.13115487\n",
            "Epoch: 20 - Step: 82 - MSE loss: 0.0076720607 - KL loss: 0.13532856\n",
            "Epoch: 20 - Step: 83 - MSE loss: 0.0067093954 - KL loss: 0.12820171\n",
            "Epoch: 20 - Step: 84 - MSE loss: 0.0069672526 - KL loss: 0.13909164\n",
            "Epoch: 20 - Step: 85 - MSE loss: 0.007289127 - KL loss: 0.13808408\n",
            "Epoch: 20 - Step: 86 - MSE loss: 0.0074737943 - KL loss: 0.13799237\n",
            "Epoch: 20 - Step: 87 - MSE loss: 0.0072712847 - KL loss: 0.13666245\n",
            "Epoch: 20 - Step: 88 - MSE loss: 0.007687429 - KL loss: 0.13788946\n",
            "Epoch: 20 - Step: 89 - MSE loss: 0.006997041 - KL loss: 0.140648\n",
            "Epoch: 20 - Step: 90 - MSE loss: 0.0077540358 - KL loss: 0.15071042\n",
            "Epoch: 20 - Step: 91 - MSE loss: 0.0072938832 - KL loss: 0.14262454\n",
            "Epoch: 20 - Step: 92 - MSE loss: 0.007182265 - KL loss: 0.14304277\n",
            "Epoch: 20 - Step: 93 - MSE loss: 0.007198395 - KL loss: 0.14648119\n",
            "Epoch: 20 - Step: 94 - MSE loss: 0.0068911207 - KL loss: 0.15016115\n",
            "Epoch: 20 - Step: 95 - MSE loss: 0.007232802 - KL loss: 0.14323696\n",
            "Epoch: 20 - Step: 96 - MSE loss: 0.0068564005 - KL loss: 0.14585806\n",
            "Epoch: 20 - Step: 97 - MSE loss: 0.0070448252 - KL loss: 0.14160523\n",
            "Epoch: 20 - Step: 98 - MSE loss: 0.0072017 - KL loss: 0.1439406\n",
            "Epoch: 20 - Step: 99 - MSE loss: 0.0068272725 - KL loss: 0.14567602\n",
            "Epoch: 20 - Step: 100 - MSE loss: 0.007399783 - KL loss: 0.14305915\n",
            "Epoch: 20 - Step: 101 - MSE loss: 0.0064047663 - KL loss: 0.13337153\n",
            "Epoch: 20 - Step: 102 - MSE loss: 0.006916385 - KL loss: 0.14725937\n",
            "Epoch: 20 - Step: 103 - MSE loss: 0.006266778 - KL loss: 0.14225051\n",
            "Epoch: 20 - Step: 104 - MSE loss: 0.007180413 - KL loss: 0.14698526\n",
            "Epoch: 20 - Step: 105 - MSE loss: 0.008159592 - KL loss: 0.16586892\n",
            "Epoch: 20 - Step: 106 - MSE loss: 0.009760709 - KL loss: 0.173973\n",
            "Epoch: 20 - Step: 107 - MSE loss: 0.008898051 - KL loss: 0.17304716\n",
            "Epoch: 20 - Step: 108 - MSE loss: 0.008887772 - KL loss: 0.17834064\n",
            "Epoch: 20 - Step: 109 - MSE loss: 0.010634553 - KL loss: 0.19269148\n",
            "Epoch: 20 - Step: 110 - MSE loss: 0.0105420165 - KL loss: 0.18946627\n",
            "Epoch: 20 - Step: 111 - MSE loss: 0.010624555 - KL loss: 0.19748357\n",
            "Epoch: 20 - Step: 112 - MSE loss: 0.01072657 - KL loss: 0.18728265\n",
            "Epoch: 20 - Step: 113 - MSE loss: 0.012073525 - KL loss: 0.20421022\n",
            "Epoch: 20 - Step: 114 - MSE loss: 0.01246842 - KL loss: 0.20217723\n",
            "Epoch: 20 - Step: 115 - MSE loss: 0.012639864 - KL loss: 0.21122451\n",
            "Epoch: 20 - Step: 116 - MSE loss: 0.012846805 - KL loss: 0.19727156\n",
            "Epoch: 20 - Step: 117 - MSE loss: 0.013371627 - KL loss: 0.21212487\n",
            "Epoch: 20 - Step: 118 - MSE loss: 0.01274469 - KL loss: 0.19419599\n",
            "Epoch: 20 - Step: 119 - MSE loss: 0.012860861 - KL loss: 0.20389582\n",
            "Epoch: 20 - Step: 120 - MSE loss: 0.011884149 - KL loss: 0.20833826\n",
            "Epoch: 20 - Step: 121 - MSE loss: 0.010706178 - KL loss: 0.21832722\n",
            "Epoch: 20 - Step: 122 - MSE loss: 0.0115483785 - KL loss: 0.20411022\n",
            "Epoch: 20 - Step: 123 - MSE loss: 0.010864702 - KL loss: 0.22285813\n",
            "Epoch: 20 - Step: 124 - MSE loss: 0.0114042135 - KL loss: 0.21099761\n",
            "Epoch: 20 - Step: 125 - MSE loss: 0.011401922 - KL loss: 0.21037832\n",
            "Epoch: 20 - Step: 126 - MSE loss: 0.011678823 - KL loss: 0.20831951\n",
            "Epoch: 20 - Step: 127 - MSE loss: 0.011957611 - KL loss: 0.2126759\n",
            "Epoch: 20 - Step: 128 - MSE loss: 0.011796077 - KL loss: 0.20652564\n",
            "Epoch: 20 - Step: 129 - MSE loss: 0.011550763 - KL loss: 0.21118711\n",
            "Epoch: 20 - Step: 130 - MSE loss: 0.011808206 - KL loss: 0.21690309\n",
            "Epoch: 20 - Step: 131 - MSE loss: 0.012652438 - KL loss: 0.22170067\n",
            "Epoch: 20 - Step: 132 - MSE loss: 0.013617226 - KL loss: 0.22171098\n",
            "Epoch: 20 - Step: 133 - MSE loss: 0.0143902665 - KL loss: 0.2153392\n",
            "Epoch: 20 - Step: 134 - MSE loss: 0.0176677 - KL loss: 0.19715896\n",
            "Epoch: 20 - Step: 135 - MSE loss: 0.022255236 - KL loss: 0.2303583\n",
            "Epoch: 20 - Step: 136 - MSE loss: 0.022522146 - KL loss: 0.16761571\n",
            "Epoch: 20 - Step: 137 - MSE loss: 0.020431397 - KL loss: 0.17244822\n",
            "Epoch: 20 - Step: 138 - MSE loss: 0.01652201 - KL loss: 0.17864352\n",
            "Epoch: 20 - Step: 139 - MSE loss: 0.014822925 - KL loss: 0.21459666\n",
            "Epoch: 20 - Step: 140 - MSE loss: 0.014112208 - KL loss: 0.22326818\n",
            "Epoch: 20 - Step: 141 - MSE loss: 0.014700356 - KL loss: 0.216338\n",
            "Epoch: 20 - Step: 142 - MSE loss: 0.013316848 - KL loss: 0.21421777\n",
            "Epoch: 20 - Step: 143 - MSE loss: 0.013519763 - KL loss: 0.20991494\n",
            "Epoch: 20 - Step: 144 - MSE loss: 0.012847643 - KL loss: 0.19886842\n",
            "Epoch:  21\n",
            "Epoch: 21 - Step: 0 - MSE loss: 0.006446868 - KL loss: 0.150958\n",
            "Epoch: 21 - Step: 1 - MSE loss: 0.00713472 - KL loss: 0.152062\n",
            "Epoch: 21 - Step: 2 - MSE loss: 0.0075833946 - KL loss: 0.15479578\n",
            "Epoch: 21 - Step: 3 - MSE loss: 0.0074539147 - KL loss: 0.152941\n",
            "Epoch: 21 - Step: 4 - MSE loss: 0.006825648 - KL loss: 0.15575776\n",
            "Epoch: 21 - Step: 5 - MSE loss: 0.007543622 - KL loss: 0.14832883\n",
            "Epoch: 21 - Step: 6 - MSE loss: 0.006323021 - KL loss: 0.1369682\n",
            "Epoch: 21 - Step: 7 - MSE loss: 0.006609755 - KL loss: 0.14946285\n",
            "Epoch: 21 - Step: 8 - MSE loss: 0.007075779 - KL loss: 0.1467886\n",
            "Epoch: 21 - Step: 9 - MSE loss: 0.0066611166 - KL loss: 0.14852506\n",
            "Epoch: 21 - Step: 10 - MSE loss: 0.0076335836 - KL loss: 0.14863741\n",
            "Epoch: 21 - Step: 11 - MSE loss: 0.006707195 - KL loss: 0.14681572\n",
            "Epoch: 21 - Step: 12 - MSE loss: 0.007349537 - KL loss: 0.14652896\n",
            "Epoch: 21 - Step: 13 - MSE loss: 0.0068533868 - KL loss: 0.13849746\n",
            "Epoch: 21 - Step: 14 - MSE loss: 0.00761803 - KL loss: 0.14146301\n",
            "Epoch: 21 - Step: 15 - MSE loss: 0.0066239685 - KL loss: 0.14161466\n",
            "Epoch: 21 - Step: 16 - MSE loss: 0.0067766737 - KL loss: 0.13643837\n",
            "Epoch: 21 - Step: 17 - MSE loss: 0.006513868 - KL loss: 0.136244\n",
            "Epoch: 21 - Step: 18 - MSE loss: 0.00672939 - KL loss: 0.13025309\n",
            "Epoch: 21 - Step: 19 - MSE loss: 0.006633326 - KL loss: 0.13093701\n",
            "Epoch: 21 - Step: 20 - MSE loss: 0.006246719 - KL loss: 0.12785465\n",
            "Epoch: 21 - Step: 21 - MSE loss: 0.006616278 - KL loss: 0.13089412\n",
            "Epoch: 21 - Step: 22 - MSE loss: 0.0062940144 - KL loss: 0.12532821\n",
            "Epoch: 21 - Step: 23 - MSE loss: 0.0066015148 - KL loss: 0.13184477\n",
            "Epoch: 21 - Step: 24 - MSE loss: 0.006008563 - KL loss: 0.12408249\n",
            "Epoch: 21 - Step: 25 - MSE loss: 0.0063556526 - KL loss: 0.12960687\n",
            "Epoch: 21 - Step: 26 - MSE loss: 0.0060448754 - KL loss: 0.121982455\n",
            "Epoch: 21 - Step: 27 - MSE loss: 0.0061756955 - KL loss: 0.12371319\n",
            "Epoch: 21 - Step: 28 - MSE loss: 0.0064127822 - KL loss: 0.1295301\n",
            "Epoch: 21 - Step: 29 - MSE loss: 0.0062121954 - KL loss: 0.12267156\n",
            "Epoch: 21 - Step: 30 - MSE loss: 0.0052514947 - KL loss: 0.11877827\n",
            "Epoch: 21 - Step: 31 - MSE loss: 0.0060593006 - KL loss: 0.12842129\n",
            "Epoch: 21 - Step: 32 - MSE loss: 0.008077092 - KL loss: 0.14106959\n",
            "Epoch: 21 - Step: 33 - MSE loss: 0.008554261 - KL loss: 0.1526176\n",
            "Epoch: 21 - Step: 34 - MSE loss: 0.007192122 - KL loss: 0.14090484\n",
            "Epoch: 21 - Step: 35 - MSE loss: 0.008875831 - KL loss: 0.17188586\n",
            "Epoch: 21 - Step: 36 - MSE loss: 0.009031459 - KL loss: 0.17046839\n",
            "Epoch: 21 - Step: 37 - MSE loss: 0.008292422 - KL loss: 0.16869822\n",
            "Epoch: 21 - Step: 38 - MSE loss: 0.00977461 - KL loss: 0.18460944\n",
            "Epoch: 21 - Step: 39 - MSE loss: 0.011156424 - KL loss: 0.1885356\n",
            "Epoch: 21 - Step: 40 - MSE loss: 0.010164277 - KL loss: 0.18739252\n",
            "Epoch: 21 - Step: 41 - MSE loss: 0.01161705 - KL loss: 0.1998659\n",
            "Epoch: 21 - Step: 42 - MSE loss: 0.010128669 - KL loss: 0.1877935\n",
            "Epoch: 21 - Step: 43 - MSE loss: 0.010116215 - KL loss: 0.18502554\n",
            "Epoch: 21 - Step: 44 - MSE loss: 0.0108519355 - KL loss: 0.19616953\n",
            "Epoch: 21 - Step: 45 - MSE loss: 0.010034316 - KL loss: 0.19307613\n",
            "Epoch: 21 - Step: 46 - MSE loss: 0.010597312 - KL loss: 0.19939545\n",
            "Epoch: 21 - Step: 47 - MSE loss: 0.010063355 - KL loss: 0.20303473\n",
            "Epoch: 21 - Step: 48 - MSE loss: 0.010974038 - KL loss: 0.19950691\n",
            "Epoch: 21 - Step: 49 - MSE loss: 0.011519496 - KL loss: 0.20419048\n",
            "Epoch: 21 - Step: 50 - MSE loss: 0.012066212 - KL loss: 0.21000458\n",
            "Epoch: 21 - Step: 51 - MSE loss: 0.011901207 - KL loss: 0.20426169\n",
            "Epoch: 21 - Step: 52 - MSE loss: 0.011495911 - KL loss: 0.19749138\n",
            "Epoch: 21 - Step: 53 - MSE loss: 0.012731276 - KL loss: 0.20562223\n",
            "Epoch: 21 - Step: 54 - MSE loss: 0.012270011 - KL loss: 0.20039046\n",
            "Epoch: 21 - Step: 55 - MSE loss: 0.012120482 - KL loss: 0.20897649\n",
            "Epoch: 21 - Step: 56 - MSE loss: 0.013038926 - KL loss: 0.20856805\n",
            "Epoch: 21 - Step: 57 - MSE loss: 0.012142855 - KL loss: 0.2128667\n",
            "Epoch: 21 - Step: 58 - MSE loss: 0.013344366 - KL loss: 0.2074598\n",
            "Epoch: 21 - Step: 59 - MSE loss: 0.011957488 - KL loss: 0.2166386\n",
            "Epoch: 21 - Step: 60 - MSE loss: 0.013407044 - KL loss: 0.21208361\n",
            "Epoch: 21 - Step: 61 - MSE loss: 0.013070901 - KL loss: 0.21373421\n",
            "Epoch: 21 - Step: 62 - MSE loss: 0.012236498 - KL loss: 0.21567121\n",
            "Epoch: 21 - Step: 63 - MSE loss: 0.012552351 - KL loss: 0.22322823\n",
            "Epoch: 21 - Step: 64 - MSE loss: 0.012088171 - KL loss: 0.22163022\n",
            "Epoch: 21 - Step: 65 - MSE loss: 0.011889656 - KL loss: 0.20714766\n",
            "Epoch: 21 - Step: 66 - MSE loss: 0.011626068 - KL loss: 0.19977358\n",
            "Epoch: 21 - Step: 67 - MSE loss: 0.011459333 - KL loss: 0.19403353\n",
            "Epoch: 21 - Step: 68 - MSE loss: 0.010389666 - KL loss: 0.18822345\n",
            "Epoch: 21 - Step: 69 - MSE loss: 0.01074598 - KL loss: 0.17964156\n",
            "Epoch: 21 - Step: 70 - MSE loss: 0.009271062 - KL loss: 0.16439404\n",
            "Epoch: 21 - Step: 71 - MSE loss: 0.008514681 - KL loss: 0.16588661\n",
            "Epoch: 21 - Step: 72 - MSE loss: 0.007881832 - KL loss: 0.15800923\n",
            "Epoch: 21 - Step: 73 - MSE loss: 0.0074581257 - KL loss: 0.1513052\n",
            "Epoch: 21 - Step: 74 - MSE loss: 0.0077644163 - KL loss: 0.15516227\n",
            "Epoch: 21 - Step: 75 - MSE loss: 0.0065385886 - KL loss: 0.13259484\n",
            "Epoch: 21 - Step: 76 - MSE loss: 0.006871437 - KL loss: 0.13791804\n",
            "Epoch: 21 - Step: 77 - MSE loss: 0.006794162 - KL loss: 0.12859213\n",
            "Epoch: 21 - Step: 78 - MSE loss: 0.0063918526 - KL loss: 0.1254065\n",
            "Epoch: 21 - Step: 79 - MSE loss: 0.006742612 - KL loss: 0.124524556\n",
            "Epoch: 21 - Step: 80 - MSE loss: 0.0074612033 - KL loss: 0.13433224\n",
            "Epoch: 21 - Step: 81 - MSE loss: 0.0072056563 - KL loss: 0.13055673\n",
            "Epoch: 21 - Step: 82 - MSE loss: 0.007802708 - KL loss: 0.13758898\n",
            "Epoch: 21 - Step: 83 - MSE loss: 0.007777011 - KL loss: 0.1369263\n",
            "Epoch: 21 - Step: 84 - MSE loss: 0.0069716424 - KL loss: 0.13666826\n",
            "Epoch: 21 - Step: 85 - MSE loss: 0.0071810517 - KL loss: 0.13860618\n",
            "Epoch: 21 - Step: 86 - MSE loss: 0.00798539 - KL loss: 0.13469414\n",
            "Epoch: 21 - Step: 87 - MSE loss: 0.007267485 - KL loss: 0.13650993\n",
            "Epoch: 21 - Step: 88 - MSE loss: 0.0071766623 - KL loss: 0.14068928\n",
            "Epoch: 21 - Step: 89 - MSE loss: 0.006569386 - KL loss: 0.14178972\n",
            "Epoch: 21 - Step: 90 - MSE loss: 0.0071535017 - KL loss: 0.1461575\n",
            "Epoch: 21 - Step: 91 - MSE loss: 0.0065613114 - KL loss: 0.14224613\n",
            "Epoch: 21 - Step: 92 - MSE loss: 0.006449698 - KL loss: 0.1417085\n",
            "Epoch: 21 - Step: 93 - MSE loss: 0.0071146176 - KL loss: 0.142486\n",
            "Epoch: 21 - Step: 94 - MSE loss: 0.006881408 - KL loss: 0.14010328\n",
            "Epoch: 21 - Step: 95 - MSE loss: 0.0070073283 - KL loss: 0.1403833\n",
            "Epoch: 21 - Step: 96 - MSE loss: 0.0070292633 - KL loss: 0.14792955\n",
            "Epoch: 21 - Step: 97 - MSE loss: 0.0064415555 - KL loss: 0.14008231\n",
            "Epoch: 21 - Step: 98 - MSE loss: 0.0068417923 - KL loss: 0.14424591\n",
            "Epoch: 21 - Step: 99 - MSE loss: 0.006786693 - KL loss: 0.14653704\n",
            "Epoch: 21 - Step: 100 - MSE loss: 0.0072540324 - KL loss: 0.14812128\n",
            "Epoch: 21 - Step: 101 - MSE loss: 0.0067728027 - KL loss: 0.14773265\n",
            "Epoch: 21 - Step: 102 - MSE loss: 0.006400468 - KL loss: 0.13659352\n",
            "Epoch: 21 - Step: 103 - MSE loss: 0.006222088 - KL loss: 0.14550988\n",
            "Epoch: 21 - Step: 104 - MSE loss: 0.007867005 - KL loss: 0.15418676\n",
            "Epoch: 21 - Step: 105 - MSE loss: 0.008924753 - KL loss: 0.16630204\n",
            "Epoch: 21 - Step: 106 - MSE loss: 0.009098787 - KL loss: 0.17059293\n",
            "Epoch: 21 - Step: 107 - MSE loss: 0.009413778 - KL loss: 0.17850988\n",
            "Epoch: 21 - Step: 108 - MSE loss: 0.008770788 - KL loss: 0.18221635\n",
            "Epoch: 21 - Step: 109 - MSE loss: 0.009982954 - KL loss: 0.1929084\n",
            "Epoch: 21 - Step: 110 - MSE loss: 0.010072079 - KL loss: 0.1901396\n",
            "Epoch: 21 - Step: 111 - MSE loss: 0.010785144 - KL loss: 0.19969997\n",
            "Epoch: 21 - Step: 112 - MSE loss: 0.0114592835 - KL loss: 0.19224796\n",
            "Epoch: 21 - Step: 113 - MSE loss: 0.0120497 - KL loss: 0.19694111\n",
            "Epoch: 21 - Step: 114 - MSE loss: 0.013036887 - KL loss: 0.20036417\n",
            "Epoch: 21 - Step: 115 - MSE loss: 0.012134306 - KL loss: 0.1985957\n",
            "Epoch: 21 - Step: 116 - MSE loss: 0.013605662 - KL loss: 0.19701087\n",
            "Epoch: 21 - Step: 117 - MSE loss: 0.013389972 - KL loss: 0.21857509\n",
            "Epoch: 21 - Step: 118 - MSE loss: 0.013460637 - KL loss: 0.18887426\n",
            "Epoch: 21 - Step: 119 - MSE loss: 0.012004584 - KL loss: 0.20072469\n",
            "Epoch: 21 - Step: 120 - MSE loss: 0.011108138 - KL loss: 0.20833856\n",
            "Epoch: 21 - Step: 121 - MSE loss: 0.010984042 - KL loss: 0.21689454\n",
            "Epoch: 21 - Step: 122 - MSE loss: 0.010649775 - KL loss: 0.20751569\n",
            "Epoch: 21 - Step: 123 - MSE loss: 0.011725853 - KL loss: 0.21016236\n",
            "Epoch: 21 - Step: 124 - MSE loss: 0.010586654 - KL loss: 0.20784014\n",
            "Epoch: 21 - Step: 125 - MSE loss: 0.0109140845 - KL loss: 0.21578366\n",
            "Epoch: 21 - Step: 126 - MSE loss: 0.011388672 - KL loss: 0.21188064\n",
            "Epoch: 21 - Step: 127 - MSE loss: 0.010577631 - KL loss: 0.21051899\n",
            "Epoch: 21 - Step: 128 - MSE loss: 0.010390796 - KL loss: 0.21460393\n",
            "Epoch: 21 - Step: 129 - MSE loss: 0.010742515 - KL loss: 0.21021223\n",
            "Epoch: 21 - Step: 130 - MSE loss: 0.011224311 - KL loss: 0.21043083\n",
            "Epoch: 21 - Step: 131 - MSE loss: 0.011695634 - KL loss: 0.21521184\n",
            "Epoch: 21 - Step: 132 - MSE loss: 0.012263063 - KL loss: 0.21453117\n",
            "Epoch: 21 - Step: 133 - MSE loss: 0.01204064 - KL loss: 0.20881137\n",
            "Epoch: 21 - Step: 134 - MSE loss: 0.0126539925 - KL loss: 0.21152496\n",
            "Epoch: 21 - Step: 135 - MSE loss: 0.01263648 - KL loss: 0.21026377\n",
            "Epoch: 21 - Step: 136 - MSE loss: 0.013600302 - KL loss: 0.20547062\n",
            "Epoch: 21 - Step: 137 - MSE loss: 0.013153593 - KL loss: 0.20798922\n",
            "Epoch: 21 - Step: 138 - MSE loss: 0.013063016 - KL loss: 0.20044798\n",
            "Epoch: 21 - Step: 139 - MSE loss: 0.013811517 - KL loss: 0.21587576\n",
            "Epoch: 21 - Step: 140 - MSE loss: 0.013901259 - KL loss: 0.1929177\n",
            "Epoch: 21 - Step: 141 - MSE loss: 0.013226387 - KL loss: 0.21040285\n",
            "Epoch: 21 - Step: 142 - MSE loss: 0.012700406 - KL loss: 0.18534757\n",
            "Epoch: 21 - Step: 143 - MSE loss: 0.012495794 - KL loss: 0.20286429\n",
            "Epoch: 21 - Step: 144 - MSE loss: 0.013385336 - KL loss: 0.20234594\n",
            "Epoch:  22\n",
            "Epoch: 22 - Step: 0 - MSE loss: 0.006012864 - KL loss: 0.14298274\n",
            "Epoch: 22 - Step: 1 - MSE loss: 0.00701289 - KL loss: 0.1504561\n",
            "Epoch: 22 - Step: 2 - MSE loss: 0.0065773246 - KL loss: 0.14760102\n",
            "Epoch: 22 - Step: 3 - MSE loss: 0.0064619035 - KL loss: 0.14799145\n",
            "Epoch: 22 - Step: 4 - MSE loss: 0.00559225 - KL loss: 0.1313589\n",
            "Epoch: 22 - Step: 5 - MSE loss: 0.0058506397 - KL loss: 0.13736688\n",
            "Epoch: 22 - Step: 6 - MSE loss: 0.006527866 - KL loss: 0.14133948\n",
            "Epoch: 22 - Step: 7 - MSE loss: 0.006675705 - KL loss: 0.14387074\n",
            "Epoch: 22 - Step: 8 - MSE loss: 0.006572664 - KL loss: 0.14579032\n",
            "Epoch: 22 - Step: 9 - MSE loss: 0.007069412 - KL loss: 0.1465671\n",
            "Epoch: 22 - Step: 10 - MSE loss: 0.0065920223 - KL loss: 0.14380485\n",
            "Epoch: 22 - Step: 11 - MSE loss: 0.0064949146 - KL loss: 0.13649943\n",
            "Epoch: 22 - Step: 12 - MSE loss: 0.0064322925 - KL loss: 0.13695759\n",
            "Epoch: 22 - Step: 13 - MSE loss: 0.0067949765 - KL loss: 0.13646409\n",
            "Epoch: 22 - Step: 14 - MSE loss: 0.0077219526 - KL loss: 0.1400454\n",
            "Epoch: 22 - Step: 15 - MSE loss: 0.006993946 - KL loss: 0.13765311\n",
            "Epoch: 22 - Step: 16 - MSE loss: 0.007250992 - KL loss: 0.1422255\n",
            "Epoch: 22 - Step: 17 - MSE loss: 0.0068397983 - KL loss: 0.1346319\n",
            "Epoch: 22 - Step: 18 - MSE loss: 0.0062020416 - KL loss: 0.128634\n",
            "Epoch: 22 - Step: 19 - MSE loss: 0.00594767 - KL loss: 0.12729302\n",
            "Epoch: 22 - Step: 20 - MSE loss: 0.0059965104 - KL loss: 0.12946051\n",
            "Epoch: 22 - Step: 21 - MSE loss: 0.006471231 - KL loss: 0.12896974\n",
            "Epoch: 22 - Step: 22 - MSE loss: 0.0063747447 - KL loss: 0.12289883\n",
            "Epoch: 22 - Step: 23 - MSE loss: 0.0061366376 - KL loss: 0.12660436\n",
            "Epoch: 22 - Step: 24 - MSE loss: 0.0063728504 - KL loss: 0.12932813\n",
            "Epoch: 22 - Step: 25 - MSE loss: 0.0061605643 - KL loss: 0.12761539\n",
            "Epoch: 22 - Step: 26 - MSE loss: 0.006256487 - KL loss: 0.12669815\n",
            "Epoch: 22 - Step: 27 - MSE loss: 0.0062077064 - KL loss: 0.12738067\n",
            "Epoch: 22 - Step: 28 - MSE loss: 0.0063788122 - KL loss: 0.1238962\n",
            "Epoch: 22 - Step: 29 - MSE loss: 0.0059127505 - KL loss: 0.12010017\n",
            "Epoch: 22 - Step: 30 - MSE loss: 0.0056306217 - KL loss: 0.12071699\n",
            "Epoch: 22 - Step: 31 - MSE loss: 0.005934578 - KL loss: 0.12416014\n",
            "Epoch: 22 - Step: 32 - MSE loss: 0.007219059 - KL loss: 0.13997407\n",
            "Epoch: 22 - Step: 33 - MSE loss: 0.0074751507 - KL loss: 0.13906777\n",
            "Epoch: 22 - Step: 34 - MSE loss: 0.007535787 - KL loss: 0.14424229\n",
            "Epoch: 22 - Step: 35 - MSE loss: 0.007880016 - KL loss: 0.15073909\n",
            "Epoch: 22 - Step: 36 - MSE loss: 0.008979445 - KL loss: 0.1683027\n",
            "Epoch: 22 - Step: 37 - MSE loss: 0.00896315 - KL loss: 0.18269151\n",
            "Epoch: 22 - Step: 38 - MSE loss: 0.010020015 - KL loss: 0.19178373\n",
            "Epoch: 22 - Step: 39 - MSE loss: 0.010103084 - KL loss: 0.18431444\n",
            "Epoch: 22 - Step: 40 - MSE loss: 0.009428757 - KL loss: 0.17158544\n",
            "Epoch: 22 - Step: 41 - MSE loss: 0.011184976 - KL loss: 0.18545742\n",
            "Epoch: 22 - Step: 42 - MSE loss: 0.0098740235 - KL loss: 0.19617654\n",
            "Epoch: 22 - Step: 43 - MSE loss: 0.009278666 - KL loss: 0.18889411\n",
            "Epoch: 22 - Step: 44 - MSE loss: 0.009181156 - KL loss: 0.1873155\n",
            "Epoch: 22 - Step: 45 - MSE loss: 0.009214752 - KL loss: 0.1862596\n",
            "Epoch: 22 - Step: 46 - MSE loss: 0.010780889 - KL loss: 0.1946584\n",
            "Epoch: 22 - Step: 47 - MSE loss: 0.01038306 - KL loss: 0.20081487\n",
            "Epoch: 22 - Step: 48 - MSE loss: 0.010385191 - KL loss: 0.20566557\n",
            "Epoch: 22 - Step: 49 - MSE loss: 0.010564533 - KL loss: 0.19274423\n",
            "Epoch: 22 - Step: 50 - MSE loss: 0.011250331 - KL loss: 0.19950715\n",
            "Epoch: 22 - Step: 51 - MSE loss: 0.010825097 - KL loss: 0.205047\n",
            "Epoch: 22 - Step: 52 - MSE loss: 0.011475932 - KL loss: 0.19827944\n",
            "Epoch: 22 - Step: 53 - MSE loss: 0.012139793 - KL loss: 0.21139333\n",
            "Epoch: 22 - Step: 54 - MSE loss: 0.011607283 - KL loss: 0.20980571\n",
            "Epoch: 22 - Step: 55 - MSE loss: 0.012248204 - KL loss: 0.2064803\n",
            "Epoch: 22 - Step: 56 - MSE loss: 0.012223185 - KL loss: 0.2031215\n",
            "Epoch: 22 - Step: 57 - MSE loss: 0.0128728645 - KL loss: 0.20764975\n",
            "Epoch: 22 - Step: 58 - MSE loss: 0.013073716 - KL loss: 0.20421757\n",
            "Epoch: 22 - Step: 59 - MSE loss: 0.012966341 - KL loss: 0.21574712\n",
            "Epoch: 22 - Step: 60 - MSE loss: 0.012435849 - KL loss: 0.2054636\n",
            "Epoch: 22 - Step: 61 - MSE loss: 0.011727686 - KL loss: 0.2185567\n",
            "Epoch: 22 - Step: 62 - MSE loss: 0.012210302 - KL loss: 0.21791726\n",
            "Epoch: 22 - Step: 63 - MSE loss: 0.013529136 - KL loss: 0.22369535\n",
            "Epoch: 22 - Step: 64 - MSE loss: 0.013031269 - KL loss: 0.22196776\n",
            "Epoch: 22 - Step: 65 - MSE loss: 0.013107222 - KL loss: 0.22638768\n",
            "Epoch: 22 - Step: 66 - MSE loss: 0.012924556 - KL loss: 0.17959991\n",
            "Epoch: 22 - Step: 67 - MSE loss: 0.012609955 - KL loss: 0.19289845\n",
            "Epoch: 22 - Step: 68 - MSE loss: 0.01151123 - KL loss: 0.16529775\n",
            "Epoch: 22 - Step: 69 - MSE loss: 0.010002874 - KL loss: 0.16010088\n",
            "Epoch: 22 - Step: 70 - MSE loss: 0.010022899 - KL loss: 0.17216237\n",
            "Epoch: 22 - Step: 71 - MSE loss: 0.008829264 - KL loss: 0.1540806\n",
            "Epoch: 22 - Step: 72 - MSE loss: 0.007379019 - KL loss: 0.1495939\n",
            "Epoch: 22 - Step: 73 - MSE loss: 0.0074949805 - KL loss: 0.15278801\n",
            "Epoch: 22 - Step: 74 - MSE loss: 0.0069728973 - KL loss: 0.14774176\n",
            "Epoch: 22 - Step: 75 - MSE loss: 0.0072249644 - KL loss: 0.14937769\n",
            "Epoch: 22 - Step: 76 - MSE loss: 0.005882668 - KL loss: 0.12864037\n",
            "Epoch: 22 - Step: 77 - MSE loss: 0.007705835 - KL loss: 0.14560218\n",
            "Epoch: 22 - Step: 78 - MSE loss: 0.006591045 - KL loss: 0.1275257\n",
            "Epoch: 22 - Step: 79 - MSE loss: 0.006530851 - KL loss: 0.12930657\n",
            "Epoch: 22 - Step: 80 - MSE loss: 0.00683373 - KL loss: 0.1326176\n",
            "Epoch: 22 - Step: 81 - MSE loss: 0.0066588316 - KL loss: 0.13336214\n",
            "Epoch: 22 - Step: 82 - MSE loss: 0.0071050543 - KL loss: 0.13201392\n",
            "Epoch: 22 - Step: 83 - MSE loss: 0.0064384877 - KL loss: 0.1363076\n",
            "Epoch: 22 - Step: 84 - MSE loss: 0.006358366 - KL loss: 0.13176563\n",
            "Epoch: 22 - Step: 85 - MSE loss: 0.006824394 - KL loss: 0.13841112\n",
            "Epoch: 22 - Step: 86 - MSE loss: 0.0069782324 - KL loss: 0.13762663\n",
            "Epoch: 22 - Step: 87 - MSE loss: 0.006665153 - KL loss: 0.13668358\n",
            "Epoch: 22 - Step: 88 - MSE loss: 0.0066620572 - KL loss: 0.13774312\n",
            "Epoch: 22 - Step: 89 - MSE loss: 0.0063490663 - KL loss: 0.14625627\n",
            "Epoch: 22 - Step: 90 - MSE loss: 0.0068470114 - KL loss: 0.14302969\n",
            "Epoch: 22 - Step: 91 - MSE loss: 0.007108901 - KL loss: 0.14342202\n",
            "Epoch: 22 - Step: 92 - MSE loss: 0.0063122194 - KL loss: 0.14105159\n",
            "Epoch: 22 - Step: 93 - MSE loss: 0.006512731 - KL loss: 0.1400939\n",
            "Epoch: 22 - Step: 94 - MSE loss: 0.006630898 - KL loss: 0.13815187\n",
            "Epoch: 22 - Step: 95 - MSE loss: 0.0066443398 - KL loss: 0.14636554\n",
            "Epoch: 22 - Step: 96 - MSE loss: 0.0071487227 - KL loss: 0.14109126\n",
            "Epoch: 22 - Step: 97 - MSE loss: 0.0069280006 - KL loss: 0.14281183\n",
            "Epoch: 22 - Step: 98 - MSE loss: 0.006746106 - KL loss: 0.14206341\n",
            "Epoch: 22 - Step: 99 - MSE loss: 0.0067951716 - KL loss: 0.14096302\n",
            "Epoch: 22 - Step: 100 - MSE loss: 0.007111631 - KL loss: 0.14691101\n",
            "Epoch: 22 - Step: 101 - MSE loss: 0.0069308574 - KL loss: 0.1460996\n",
            "Epoch: 22 - Step: 102 - MSE loss: 0.0063635726 - KL loss: 0.13841473\n",
            "Epoch: 22 - Step: 103 - MSE loss: 0.006345682 - KL loss: 0.14074424\n",
            "Epoch: 22 - Step: 104 - MSE loss: 0.0070361267 - KL loss: 0.14882663\n",
            "Epoch: 22 - Step: 105 - MSE loss: 0.0076241824 - KL loss: 0.1608172\n",
            "Epoch: 22 - Step: 106 - MSE loss: 0.007933477 - KL loss: 0.16050518\n",
            "Epoch: 22 - Step: 107 - MSE loss: 0.009318717 - KL loss: 0.18488395\n",
            "Epoch: 22 - Step: 108 - MSE loss: 0.008176518 - KL loss: 0.17544034\n",
            "Epoch: 22 - Step: 109 - MSE loss: 0.008757128 - KL loss: 0.18212412\n",
            "Epoch: 22 - Step: 110 - MSE loss: 0.009504789 - KL loss: 0.19082636\n",
            "Epoch: 22 - Step: 111 - MSE loss: 0.009608494 - KL loss: 0.19009796\n",
            "Epoch: 22 - Step: 112 - MSE loss: 0.0115622515 - KL loss: 0.20132405\n",
            "Epoch: 22 - Step: 113 - MSE loss: 0.011506061 - KL loss: 0.19840142\n",
            "Epoch: 22 - Step: 114 - MSE loss: 0.011619889 - KL loss: 0.20167866\n",
            "Epoch: 22 - Step: 115 - MSE loss: 0.012516721 - KL loss: 0.20078821\n",
            "Epoch: 22 - Step: 116 - MSE loss: 0.012017071 - KL loss: 0.20276326\n",
            "Epoch: 22 - Step: 117 - MSE loss: 0.011245306 - KL loss: 0.20001961\n",
            "Epoch: 22 - Step: 118 - MSE loss: 0.0115478365 - KL loss: 0.21023753\n",
            "Epoch: 22 - Step: 119 - MSE loss: 0.010757509 - KL loss: 0.2109257\n",
            "Epoch: 22 - Step: 120 - MSE loss: 0.010268848 - KL loss: 0.21045092\n",
            "Epoch: 22 - Step: 121 - MSE loss: 0.010100757 - KL loss: 0.18828054\n",
            "Epoch: 22 - Step: 122 - MSE loss: 0.01041891 - KL loss: 0.19779685\n",
            "Epoch: 22 - Step: 123 - MSE loss: 0.010467553 - KL loss: 0.20055649\n",
            "Epoch: 22 - Step: 124 - MSE loss: 0.01066614 - KL loss: 0.20807531\n",
            "Epoch: 22 - Step: 125 - MSE loss: 0.010712478 - KL loss: 0.20102486\n",
            "Epoch: 22 - Step: 126 - MSE loss: 0.011192956 - KL loss: 0.21670294\n",
            "Epoch: 22 - Step: 127 - MSE loss: 0.011049959 - KL loss: 0.2031534\n",
            "Epoch: 22 - Step: 128 - MSE loss: 0.011155388 - KL loss: 0.21397273\n",
            "Epoch: 22 - Step: 129 - MSE loss: 0.0116399275 - KL loss: 0.19921416\n",
            "Epoch: 22 - Step: 130 - MSE loss: 0.012735783 - KL loss: 0.21805185\n",
            "Epoch: 22 - Step: 131 - MSE loss: 0.015543847 - KL loss: 0.19442922\n",
            "Epoch: 22 - Step: 132 - MSE loss: 0.01652495 - KL loss: 0.22396365\n",
            "Epoch: 22 - Step: 133 - MSE loss: 0.01896236 - KL loss: 0.20382598\n",
            "Epoch: 22 - Step: 134 - MSE loss: 0.01990919 - KL loss: 0.20100054\n",
            "Epoch: 22 - Step: 135 - MSE loss: 0.016768174 - KL loss: 0.17308849\n",
            "Epoch: 22 - Step: 136 - MSE loss: 0.014762674 - KL loss: 0.18156594\n",
            "Epoch: 22 - Step: 137 - MSE loss: 0.0145671265 - KL loss: 0.20158589\n",
            "Epoch: 22 - Step: 138 - MSE loss: 0.014348664 - KL loss: 0.19228926\n",
            "Epoch: 22 - Step: 139 - MSE loss: 0.013130717 - KL loss: 0.21166083\n",
            "Epoch: 22 - Step: 140 - MSE loss: 0.013450906 - KL loss: 0.2065892\n",
            "Epoch: 22 - Step: 141 - MSE loss: 0.012513635 - KL loss: 0.21230595\n",
            "Epoch: 22 - Step: 142 - MSE loss: 0.013033636 - KL loss: 0.20647992\n",
            "Epoch: 22 - Step: 143 - MSE loss: 0.0121506145 - KL loss: 0.19512433\n",
            "Epoch: 22 - Step: 144 - MSE loss: 0.011646677 - KL loss: 0.20814228\n",
            "Epoch:  23\n",
            "Epoch: 23 - Step: 0 - MSE loss: 0.0056496016 - KL loss: 0.14288823\n",
            "Epoch: 23 - Step: 1 - MSE loss: 0.0057366793 - KL loss: 0.15345356\n",
            "Epoch: 23 - Step: 2 - MSE loss: 0.0059548765 - KL loss: 0.14864437\n",
            "Epoch: 23 - Step: 3 - MSE loss: 0.00678614 - KL loss: 0.15295783\n",
            "Epoch: 23 - Step: 4 - MSE loss: 0.0069271456 - KL loss: 0.14219964\n",
            "Epoch: 23 - Step: 5 - MSE loss: 0.007378181 - KL loss: 0.14489079\n",
            "Epoch: 23 - Step: 6 - MSE loss: 0.0067092646 - KL loss: 0.13602267\n",
            "Epoch: 23 - Step: 7 - MSE loss: 0.006487467 - KL loss: 0.14038354\n",
            "Epoch: 23 - Step: 8 - MSE loss: 0.006485389 - KL loss: 0.14290601\n",
            "Epoch: 23 - Step: 9 - MSE loss: 0.0069079823 - KL loss: 0.14307067\n",
            "Epoch: 23 - Step: 10 - MSE loss: 0.006710106 - KL loss: 0.14151575\n",
            "Epoch: 23 - Step: 11 - MSE loss: 0.007170918 - KL loss: 0.14088273\n",
            "Epoch: 23 - Step: 12 - MSE loss: 0.006881578 - KL loss: 0.14434478\n",
            "Epoch: 23 - Step: 13 - MSE loss: 0.006558916 - KL loss: 0.13721679\n",
            "Epoch: 23 - Step: 14 - MSE loss: 0.00701436 - KL loss: 0.14020744\n",
            "Epoch: 23 - Step: 15 - MSE loss: 0.0065574734 - KL loss: 0.1392278\n",
            "Epoch: 23 - Step: 16 - MSE loss: 0.007090729 - KL loss: 0.15034088\n",
            "Epoch: 23 - Step: 17 - MSE loss: 0.0062297564 - KL loss: 0.14236715\n",
            "Epoch: 23 - Step: 18 - MSE loss: 0.006177465 - KL loss: 0.13682877\n",
            "Epoch: 23 - Step: 19 - MSE loss: 0.0059995023 - KL loss: 0.12560868\n",
            "Epoch: 23 - Step: 20 - MSE loss: 0.0060290266 - KL loss: 0.13284302\n",
            "Epoch: 23 - Step: 21 - MSE loss: 0.006149635 - KL loss: 0.124299854\n",
            "Epoch: 23 - Step: 22 - MSE loss: 0.0062746145 - KL loss: 0.1260761\n",
            "Epoch: 23 - Step: 23 - MSE loss: 0.0063988175 - KL loss: 0.12954418\n",
            "Epoch: 23 - Step: 24 - MSE loss: 0.00601152 - KL loss: 0.13172205\n",
            "Epoch: 23 - Step: 25 - MSE loss: 0.006271299 - KL loss: 0.12512164\n",
            "Epoch: 23 - Step: 26 - MSE loss: 0.005813521 - KL loss: 0.121121295\n",
            "Epoch: 23 - Step: 27 - MSE loss: 0.0058721495 - KL loss: 0.122994795\n",
            "Epoch: 23 - Step: 28 - MSE loss: 0.0065131676 - KL loss: 0.13243642\n",
            "Epoch: 23 - Step: 29 - MSE loss: 0.005732938 - KL loss: 0.12240811\n",
            "Epoch: 23 - Step: 30 - MSE loss: 0.0057538077 - KL loss: 0.11956527\n",
            "Epoch: 23 - Step: 31 - MSE loss: 0.0054680756 - KL loss: 0.12013996\n",
            "Epoch: 23 - Step: 32 - MSE loss: 0.0069689653 - KL loss: 0.13570604\n",
            "Epoch: 23 - Step: 33 - MSE loss: 0.007733077 - KL loss: 0.14243826\n",
            "Epoch: 23 - Step: 34 - MSE loss: 0.006799314 - KL loss: 0.14121026\n",
            "Epoch: 23 - Step: 35 - MSE loss: 0.007215698 - KL loss: 0.14931297\n",
            "Epoch: 23 - Step: 36 - MSE loss: 0.008205346 - KL loss: 0.16140008\n",
            "Epoch: 23 - Step: 37 - MSE loss: 0.0094590755 - KL loss: 0.17807318\n",
            "Epoch: 23 - Step: 38 - MSE loss: 0.009443968 - KL loss: 0.18274869\n",
            "Epoch: 23 - Step: 39 - MSE loss: 0.009839856 - KL loss: 0.1881024\n",
            "Epoch: 23 - Step: 40 - MSE loss: 0.010092641 - KL loss: 0.18816954\n",
            "Epoch: 23 - Step: 41 - MSE loss: 0.010516793 - KL loss: 0.18895587\n",
            "Epoch: 23 - Step: 42 - MSE loss: 0.009627566 - KL loss: 0.19192262\n",
            "Epoch: 23 - Step: 43 - MSE loss: 0.008924753 - KL loss: 0.19491078\n",
            "Epoch: 23 - Step: 44 - MSE loss: 0.010109598 - KL loss: 0.18748944\n",
            "Epoch: 23 - Step: 45 - MSE loss: 0.009920689 - KL loss: 0.19054143\n",
            "Epoch: 23 - Step: 46 - MSE loss: 0.009619883 - KL loss: 0.19398008\n",
            "Epoch: 23 - Step: 47 - MSE loss: 0.009564609 - KL loss: 0.1865566\n",
            "Epoch: 23 - Step: 48 - MSE loss: 0.010666956 - KL loss: 0.20619972\n",
            "Epoch: 23 - Step: 49 - MSE loss: 0.0105329305 - KL loss: 0.1993146\n",
            "Epoch: 23 - Step: 50 - MSE loss: 0.010613817 - KL loss: 0.19921562\n",
            "Epoch: 23 - Step: 51 - MSE loss: 0.011178023 - KL loss: 0.20826904\n",
            "Epoch: 23 - Step: 52 - MSE loss: 0.010948009 - KL loss: 0.2017441\n",
            "Epoch: 23 - Step: 53 - MSE loss: 0.011863817 - KL loss: 0.20604858\n",
            "Epoch: 23 - Step: 54 - MSE loss: 0.010881445 - KL loss: 0.19874829\n",
            "Epoch: 23 - Step: 55 - MSE loss: 0.010654769 - KL loss: 0.20596921\n",
            "Epoch: 23 - Step: 56 - MSE loss: 0.011091107 - KL loss: 0.20416734\n",
            "Epoch: 23 - Step: 57 - MSE loss: 0.011241921 - KL loss: 0.21066062\n",
            "Epoch: 23 - Step: 58 - MSE loss: 0.011075105 - KL loss: 0.20256585\n",
            "Epoch: 23 - Step: 59 - MSE loss: 0.012018866 - KL loss: 0.2074132\n",
            "Epoch: 23 - Step: 60 - MSE loss: 0.01230947 - KL loss: 0.20371518\n",
            "Epoch: 23 - Step: 61 - MSE loss: 0.01209807 - KL loss: 0.20855486\n",
            "Epoch: 23 - Step: 62 - MSE loss: 0.011451535 - KL loss: 0.21625179\n",
            "Epoch: 23 - Step: 63 - MSE loss: 0.011774001 - KL loss: 0.2054089\n",
            "Epoch: 23 - Step: 64 - MSE loss: 0.013341998 - KL loss: 0.22599427\n",
            "Epoch: 23 - Step: 65 - MSE loss: 0.012458381 - KL loss: 0.22028953\n",
            "Epoch: 23 - Step: 66 - MSE loss: 0.010367471 - KL loss: 0.20086817\n",
            "Epoch: 23 - Step: 67 - MSE loss: 0.010883607 - KL loss: 0.19651954\n",
            "Epoch: 23 - Step: 68 - MSE loss: 0.00861258 - KL loss: 0.17259604\n",
            "Epoch: 23 - Step: 69 - MSE loss: 0.0095214 - KL loss: 0.16828786\n",
            "Epoch: 23 - Step: 70 - MSE loss: 0.00938382 - KL loss: 0.16243303\n",
            "Epoch: 23 - Step: 71 - MSE loss: 0.007269362 - KL loss: 0.15161142\n",
            "Epoch: 23 - Step: 72 - MSE loss: 0.00705996 - KL loss: 0.1536729\n",
            "Epoch: 23 - Step: 73 - MSE loss: 0.007196184 - KL loss: 0.14487234\n",
            "Epoch: 23 - Step: 74 - MSE loss: 0.006603375 - KL loss: 0.14226872\n",
            "Epoch: 23 - Step: 75 - MSE loss: 0.00671421 - KL loss: 0.13359584\n",
            "Epoch: 23 - Step: 76 - MSE loss: 0.006681181 - KL loss: 0.13504605\n",
            "Epoch: 23 - Step: 77 - MSE loss: 0.00689487 - KL loss: 0.13809687\n",
            "Epoch: 23 - Step: 78 - MSE loss: 0.0067699547 - KL loss: 0.1302406\n",
            "Epoch: 23 - Step: 79 - MSE loss: 0.006448639 - KL loss: 0.13512133\n",
            "Epoch: 23 - Step: 80 - MSE loss: 0.0070259734 - KL loss: 0.13754523\n",
            "Epoch: 23 - Step: 81 - MSE loss: 0.0063370112 - KL loss: 0.12877712\n",
            "Epoch: 23 - Step: 82 - MSE loss: 0.0066780155 - KL loss: 0.13182425\n",
            "Epoch: 23 - Step: 83 - MSE loss: 0.0069102463 - KL loss: 0.13886881\n",
            "Epoch: 23 - Step: 84 - MSE loss: 0.0061635934 - KL loss: 0.13476035\n",
            "Epoch: 23 - Step: 85 - MSE loss: 0.0065522804 - KL loss: 0.13104254\n",
            "Epoch: 23 - Step: 86 - MSE loss: 0.0072765 - KL loss: 0.13660519\n",
            "Epoch: 23 - Step: 87 - MSE loss: 0.0070748534 - KL loss: 0.13463211\n",
            "Epoch: 23 - Step: 88 - MSE loss: 0.007449539 - KL loss: 0.14157611\n",
            "Epoch: 23 - Step: 89 - MSE loss: 0.007081956 - KL loss: 0.1424937\n",
            "Epoch: 23 - Step: 90 - MSE loss: 0.0075149066 - KL loss: 0.1504692\n",
            "Epoch: 23 - Step: 91 - MSE loss: 0.006068716 - KL loss: 0.14300683\n",
            "Epoch: 23 - Step: 92 - MSE loss: 0.0063504498 - KL loss: 0.13861698\n",
            "Epoch: 23 - Step: 93 - MSE loss: 0.0062574204 - KL loss: 0.13856003\n",
            "Epoch: 23 - Step: 94 - MSE loss: 0.006413085 - KL loss: 0.14381194\n",
            "Epoch: 23 - Step: 95 - MSE loss: 0.0068263398 - KL loss: 0.14263639\n",
            "Epoch: 23 - Step: 96 - MSE loss: 0.006624863 - KL loss: 0.14228177\n",
            "Epoch: 23 - Step: 97 - MSE loss: 0.0064240205 - KL loss: 0.13598208\n",
            "Epoch: 23 - Step: 98 - MSE loss: 0.006520387 - KL loss: 0.14368854\n",
            "Epoch: 23 - Step: 99 - MSE loss: 0.0065197553 - KL loss: 0.14205484\n",
            "Epoch: 23 - Step: 100 - MSE loss: 0.007009905 - KL loss: 0.15090457\n",
            "Epoch: 23 - Step: 101 - MSE loss: 0.0060511916 - KL loss: 0.14416802\n",
            "Epoch: 23 - Step: 102 - MSE loss: 0.0058460664 - KL loss: 0.13805473\n",
            "Epoch: 23 - Step: 103 - MSE loss: 0.005704777 - KL loss: 0.14521417\n",
            "Epoch: 23 - Step: 104 - MSE loss: 0.0062254635 - KL loss: 0.14872715\n",
            "Epoch: 23 - Step: 105 - MSE loss: 0.0073888437 - KL loss: 0.15970689\n",
            "Epoch: 23 - Step: 106 - MSE loss: 0.007582825 - KL loss: 0.16049217\n",
            "Epoch: 23 - Step: 107 - MSE loss: 0.0073672836 - KL loss: 0.15604009\n",
            "Epoch: 23 - Step: 108 - MSE loss: 0.008717949 - KL loss: 0.17270333\n",
            "Epoch: 23 - Step: 109 - MSE loss: 0.0087571405 - KL loss: 0.19054355\n",
            "Epoch: 23 - Step: 110 - MSE loss: 0.009250656 - KL loss: 0.18863094\n",
            "Epoch: 23 - Step: 111 - MSE loss: 0.010171802 - KL loss: 0.2046673\n",
            "Epoch: 23 - Step: 112 - MSE loss: 0.011492855 - KL loss: 0.1972366\n",
            "Epoch: 23 - Step: 113 - MSE loss: 0.010738672 - KL loss: 0.19823687\n",
            "Epoch: 23 - Step: 114 - MSE loss: 0.009711662 - KL loss: 0.19134839\n",
            "Epoch: 23 - Step: 115 - MSE loss: 0.010765704 - KL loss: 0.19596618\n",
            "Epoch: 23 - Step: 116 - MSE loss: 0.011406724 - KL loss: 0.2053414\n",
            "Epoch: 23 - Step: 117 - MSE loss: 0.010734771 - KL loss: 0.19740637\n",
            "Epoch: 23 - Step: 118 - MSE loss: 0.011005718 - KL loss: 0.19123757\n",
            "Epoch: 23 - Step: 119 - MSE loss: 0.011804941 - KL loss: 0.2089621\n",
            "Epoch: 23 - Step: 120 - MSE loss: 0.011793341 - KL loss: 0.19151506\n",
            "Epoch: 23 - Step: 121 - MSE loss: 0.013290356 - KL loss: 0.21864599\n",
            "Epoch: 23 - Step: 122 - MSE loss: 0.016643254 - KL loss: 0.18342571\n",
            "Epoch: 23 - Step: 123 - MSE loss: 0.014514995 - KL loss: 0.20519972\n",
            "Epoch: 23 - Step: 124 - MSE loss: 0.012010195 - KL loss: 0.19971715\n",
            "Epoch: 23 - Step: 125 - MSE loss: 0.012048412 - KL loss: 0.19717468\n",
            "Epoch: 23 - Step: 126 - MSE loss: 0.012330827 - KL loss: 0.20759462\n",
            "Epoch: 23 - Step: 127 - MSE loss: 0.0099569885 - KL loss: 0.20855616\n",
            "Epoch: 23 - Step: 128 - MSE loss: 0.010414529 - KL loss: 0.2155512\n",
            "Epoch: 23 - Step: 129 - MSE loss: 0.010755925 - KL loss: 0.21530333\n",
            "Epoch: 23 - Step: 130 - MSE loss: 0.010123598 - KL loss: 0.21096277\n",
            "Epoch: 23 - Step: 131 - MSE loss: 0.010170838 - KL loss: 0.21294487\n",
            "Epoch: 23 - Step: 132 - MSE loss: 0.010843263 - KL loss: 0.2219224\n",
            "Epoch: 23 - Step: 133 - MSE loss: 0.012969933 - KL loss: 0.21216229\n",
            "Epoch: 23 - Step: 134 - MSE loss: 0.011624277 - KL loss: 0.21158314\n",
            "Epoch: 23 - Step: 135 - MSE loss: 0.012629558 - KL loss: 0.20314504\n",
            "Epoch: 23 - Step: 136 - MSE loss: 0.011254271 - KL loss: 0.2073807\n",
            "Epoch: 23 - Step: 137 - MSE loss: 0.01181493 - KL loss: 0.20887008\n",
            "Epoch: 23 - Step: 138 - MSE loss: 0.012312067 - KL loss: 0.20672148\n",
            "Epoch: 23 - Step: 139 - MSE loss: 0.012075356 - KL loss: 0.21640185\n",
            "Epoch: 23 - Step: 140 - MSE loss: 0.011196221 - KL loss: 0.20767266\n",
            "Epoch: 23 - Step: 141 - MSE loss: 0.011152841 - KL loss: 0.19914982\n",
            "Epoch: 23 - Step: 142 - MSE loss: 0.01258057 - KL loss: 0.20647202\n",
            "Epoch: 23 - Step: 143 - MSE loss: 0.012487784 - KL loss: 0.20487282\n",
            "Epoch: 23 - Step: 144 - MSE loss: 0.012256029 - KL loss: 0.19676493\n",
            "Epoch:  24\n",
            "Epoch: 24 - Step: 0 - MSE loss: 0.005627066 - KL loss: 0.13936348\n",
            "Epoch: 24 - Step: 1 - MSE loss: 0.005703807 - KL loss: 0.14146885\n",
            "Epoch: 24 - Step: 2 - MSE loss: 0.0058341897 - KL loss: 0.1513018\n",
            "Epoch: 24 - Step: 3 - MSE loss: 0.006539216 - KL loss: 0.14037672\n",
            "Epoch: 24 - Step: 4 - MSE loss: 0.0065010195 - KL loss: 0.13937995\n",
            "Epoch: 24 - Step: 5 - MSE loss: 0.006253591 - KL loss: 0.13892964\n",
            "Epoch: 24 - Step: 6 - MSE loss: 0.0066293017 - KL loss: 0.13732298\n",
            "Epoch: 24 - Step: 7 - MSE loss: 0.006732106 - KL loss: 0.14624462\n",
            "Epoch: 24 - Step: 8 - MSE loss: 0.006698144 - KL loss: 0.1412437\n",
            "Epoch: 24 - Step: 9 - MSE loss: 0.006708655 - KL loss: 0.14274065\n",
            "Epoch: 24 - Step: 10 - MSE loss: 0.0068425904 - KL loss: 0.14132383\n",
            "Epoch: 24 - Step: 11 - MSE loss: 0.006136101 - KL loss: 0.14173242\n",
            "Epoch: 24 - Step: 12 - MSE loss: 0.006170463 - KL loss: 0.1376041\n",
            "Epoch: 24 - Step: 13 - MSE loss: 0.0062343073 - KL loss: 0.13372374\n",
            "Epoch: 24 - Step: 14 - MSE loss: 0.006264373 - KL loss: 0.13980126\n",
            "Epoch: 24 - Step: 15 - MSE loss: 0.0062540644 - KL loss: 0.14223778\n",
            "Epoch: 24 - Step: 16 - MSE loss: 0.0065592895 - KL loss: 0.14338127\n",
            "Epoch: 24 - Step: 17 - MSE loss: 0.006255787 - KL loss: 0.13938415\n",
            "Epoch: 24 - Step: 18 - MSE loss: 0.0056289895 - KL loss: 0.12631087\n",
            "Epoch: 24 - Step: 19 - MSE loss: 0.005648257 - KL loss: 0.12664548\n",
            "Epoch: 24 - Step: 20 - MSE loss: 0.005657326 - KL loss: 0.12744036\n",
            "Epoch: 24 - Step: 21 - MSE loss: 0.0059366203 - KL loss: 0.12870139\n",
            "Epoch: 24 - Step: 22 - MSE loss: 0.006081119 - KL loss: 0.12333658\n",
            "Epoch: 24 - Step: 23 - MSE loss: 0.0060723466 - KL loss: 0.12556632\n",
            "Epoch: 24 - Step: 24 - MSE loss: 0.006548513 - KL loss: 0.12722722\n",
            "Epoch: 24 - Step: 25 - MSE loss: 0.0058126356 - KL loss: 0.1299323\n",
            "Epoch: 24 - Step: 26 - MSE loss: 0.005807283 - KL loss: 0.117246404\n",
            "Epoch: 24 - Step: 27 - MSE loss: 0.0059637413 - KL loss: 0.12850726\n",
            "Epoch: 24 - Step: 28 - MSE loss: 0.0061064977 - KL loss: 0.12265071\n",
            "Epoch: 24 - Step: 29 - MSE loss: 0.0058168806 - KL loss: 0.11812328\n",
            "Epoch: 24 - Step: 30 - MSE loss: 0.005077606 - KL loss: 0.11832121\n",
            "Epoch: 24 - Step: 31 - MSE loss: 0.005520605 - KL loss: 0.12068316\n",
            "Epoch: 24 - Step: 32 - MSE loss: 0.0065688207 - KL loss: 0.1359658\n",
            "Epoch: 24 - Step: 33 - MSE loss: 0.0073601827 - KL loss: 0.14128432\n",
            "Epoch: 24 - Step: 34 - MSE loss: 0.006753227 - KL loss: 0.14749658\n",
            "Epoch: 24 - Step: 35 - MSE loss: 0.0075374283 - KL loss: 0.15301903\n",
            "Epoch: 24 - Step: 36 - MSE loss: 0.008080912 - KL loss: 0.1685679\n",
            "Epoch: 24 - Step: 37 - MSE loss: 0.00860767 - KL loss: 0.17159696\n",
            "Epoch: 24 - Step: 38 - MSE loss: 0.008660496 - KL loss: 0.1775063\n",
            "Epoch: 24 - Step: 39 - MSE loss: 0.009581736 - KL loss: 0.18030217\n",
            "Epoch: 24 - Step: 40 - MSE loss: 0.010839312 - KL loss: 0.18550566\n",
            "Epoch: 24 - Step: 41 - MSE loss: 0.009957294 - KL loss: 0.18574205\n",
            "Epoch: 24 - Step: 42 - MSE loss: 0.009483556 - KL loss: 0.18645848\n",
            "Epoch: 24 - Step: 43 - MSE loss: 0.008863377 - KL loss: 0.18566017\n",
            "Epoch: 24 - Step: 44 - MSE loss: 0.009249474 - KL loss: 0.18222353\n",
            "Epoch: 24 - Step: 45 - MSE loss: 0.008879882 - KL loss: 0.18584129\n",
            "Epoch: 24 - Step: 46 - MSE loss: 0.0098075485 - KL loss: 0.18726498\n",
            "Epoch: 24 - Step: 47 - MSE loss: 0.009964428 - KL loss: 0.20031181\n",
            "Epoch: 24 - Step: 48 - MSE loss: 0.010391726 - KL loss: 0.21164599\n",
            "Epoch: 24 - Step: 49 - MSE loss: 0.009642317 - KL loss: 0.19662476\n",
            "Epoch: 24 - Step: 50 - MSE loss: 0.010632691 - KL loss: 0.18722203\n",
            "Epoch: 24 - Step: 51 - MSE loss: 0.009686343 - KL loss: 0.19243565\n",
            "Epoch: 24 - Step: 52 - MSE loss: 0.011030202 - KL loss: 0.19544399\n",
            "Epoch: 24 - Step: 53 - MSE loss: 0.011596672 - KL loss: 0.21296498\n",
            "Epoch: 24 - Step: 54 - MSE loss: 0.012428984 - KL loss: 0.20266554\n",
            "Epoch: 24 - Step: 55 - MSE loss: 0.010618131 - KL loss: 0.20379433\n",
            "Epoch: 24 - Step: 56 - MSE loss: 0.011772332 - KL loss: 0.20198041\n",
            "Epoch: 24 - Step: 57 - MSE loss: 0.011425148 - KL loss: 0.19855613\n",
            "Epoch: 24 - Step: 58 - MSE loss: 0.010897282 - KL loss: 0.20332241\n",
            "Epoch: 24 - Step: 59 - MSE loss: 0.011988115 - KL loss: 0.20638591\n",
            "Epoch: 24 - Step: 60 - MSE loss: 0.012365649 - KL loss: 0.20882884\n",
            "Epoch: 24 - Step: 61 - MSE loss: 0.012401572 - KL loss: 0.20987296\n",
            "Epoch: 24 - Step: 62 - MSE loss: 0.0117155565 - KL loss: 0.2169418\n",
            "Epoch: 24 - Step: 63 - MSE loss: 0.01337809 - KL loss: 0.19724596\n",
            "Epoch: 24 - Step: 64 - MSE loss: 0.0135193085 - KL loss: 0.22077891\n",
            "Epoch: 24 - Step: 65 - MSE loss: 0.012854834 - KL loss: 0.1951391\n",
            "Epoch: 24 - Step: 66 - MSE loss: 0.0113419285 - KL loss: 0.19988465\n",
            "Epoch: 24 - Step: 67 - MSE loss: 0.010911298 - KL loss: 0.18580109\n",
            "Epoch: 24 - Step: 68 - MSE loss: 0.009685325 - KL loss: 0.17838264\n",
            "Epoch: 24 - Step: 69 - MSE loss: 0.009812323 - KL loss: 0.16942286\n",
            "Epoch: 24 - Step: 70 - MSE loss: 0.008378921 - KL loss: 0.15819132\n",
            "Epoch: 24 - Step: 71 - MSE loss: 0.008381409 - KL loss: 0.15950231\n",
            "Epoch: 24 - Step: 72 - MSE loss: 0.0066462196 - KL loss: 0.14514871\n",
            "Epoch: 24 - Step: 73 - MSE loss: 0.0068997494 - KL loss: 0.14771202\n",
            "Epoch: 24 - Step: 74 - MSE loss: 0.0061815456 - KL loss: 0.13321243\n",
            "Epoch: 24 - Step: 75 - MSE loss: 0.006343007 - KL loss: 0.13666552\n",
            "Epoch: 24 - Step: 76 - MSE loss: 0.006145913 - KL loss: 0.1332627\n",
            "Epoch: 24 - Step: 77 - MSE loss: 0.0064104446 - KL loss: 0.13517793\n",
            "Epoch: 24 - Step: 78 - MSE loss: 0.006630603 - KL loss: 0.12856118\n",
            "Epoch: 24 - Step: 79 - MSE loss: 0.007007578 - KL loss: 0.13673985\n",
            "Epoch: 24 - Step: 80 - MSE loss: 0.006547064 - KL loss: 0.13957767\n",
            "Epoch: 24 - Step: 81 - MSE loss: 0.006314661 - KL loss: 0.13079137\n",
            "Epoch: 24 - Step: 82 - MSE loss: 0.0071144905 - KL loss: 0.13803326\n",
            "Epoch: 24 - Step: 83 - MSE loss: 0.0065123294 - KL loss: 0.1387958\n",
            "Epoch: 24 - Step: 84 - MSE loss: 0.0069160894 - KL loss: 0.13992375\n",
            "Epoch: 24 - Step: 85 - MSE loss: 0.006278681 - KL loss: 0.13751782\n",
            "Epoch: 24 - Step: 86 - MSE loss: 0.0071023875 - KL loss: 0.13930398\n",
            "Epoch: 24 - Step: 87 - MSE loss: 0.0065610367 - KL loss: 0.13455361\n",
            "Epoch: 24 - Step: 88 - MSE loss: 0.006479142 - KL loss: 0.13753729\n",
            "Epoch: 24 - Step: 89 - MSE loss: 0.006581725 - KL loss: 0.14062434\n",
            "Epoch: 24 - Step: 90 - MSE loss: 0.006768743 - KL loss: 0.14426488\n",
            "Epoch: 24 - Step: 91 - MSE loss: 0.0065668053 - KL loss: 0.14666244\n",
            "Epoch: 24 - Step: 92 - MSE loss: 0.006190017 - KL loss: 0.14520723\n",
            "Epoch: 24 - Step: 93 - MSE loss: 0.006059365 - KL loss: 0.13583614\n",
            "Epoch: 24 - Step: 94 - MSE loss: 0.006167983 - KL loss: 0.14135799\n",
            "Epoch: 24 - Step: 95 - MSE loss: 0.0065330863 - KL loss: 0.14113978\n",
            "Epoch: 24 - Step: 96 - MSE loss: 0.0060927332 - KL loss: 0.14206263\n",
            "Epoch: 24 - Step: 97 - MSE loss: 0.006070065 - KL loss: 0.1405057\n",
            "Epoch: 24 - Step: 98 - MSE loss: 0.006263077 - KL loss: 0.14099802\n",
            "Epoch: 24 - Step: 99 - MSE loss: 0.0067306906 - KL loss: 0.1398343\n",
            "Epoch: 24 - Step: 100 - MSE loss: 0.0064139236 - KL loss: 0.14042851\n",
            "Epoch: 24 - Step: 101 - MSE loss: 0.006560802 - KL loss: 0.13908169\n",
            "Epoch: 24 - Step: 102 - MSE loss: 0.006558873 - KL loss: 0.14245078\n",
            "Epoch: 24 - Step: 103 - MSE loss: 0.0062845335 - KL loss: 0.1428366\n",
            "Epoch: 24 - Step: 104 - MSE loss: 0.00626813 - KL loss: 0.14510469\n",
            "Epoch: 24 - Step: 105 - MSE loss: 0.006458158 - KL loss: 0.15021658\n",
            "Epoch: 24 - Step: 106 - MSE loss: 0.008053855 - KL loss: 0.16983142\n",
            "Epoch: 24 - Step: 107 - MSE loss: 0.008399658 - KL loss: 0.16429345\n",
            "Epoch: 24 - Step: 108 - MSE loss: 0.009347581 - KL loss: 0.1776472\n",
            "Epoch: 24 - Step: 109 - MSE loss: 0.008185375 - KL loss: 0.18289635\n",
            "Epoch: 24 - Step: 110 - MSE loss: 0.008946579 - KL loss: 0.19023487\n",
            "Epoch: 24 - Step: 111 - MSE loss: 0.009511153 - KL loss: 0.19522935\n",
            "Epoch: 24 - Step: 112 - MSE loss: 0.010379109 - KL loss: 0.19110416\n",
            "Epoch: 24 - Step: 113 - MSE loss: 0.010878266 - KL loss: 0.19618885\n",
            "Epoch: 24 - Step: 114 - MSE loss: 0.0097806025 - KL loss: 0.19405547\n",
            "Epoch: 24 - Step: 115 - MSE loss: 0.010322089 - KL loss: 0.19913465\n",
            "Epoch: 24 - Step: 116 - MSE loss: 0.011624097 - KL loss: 0.20328459\n",
            "Epoch: 24 - Step: 117 - MSE loss: 0.010616313 - KL loss: 0.18827751\n",
            "Epoch: 24 - Step: 118 - MSE loss: 0.010826737 - KL loss: 0.20802997\n",
            "Epoch: 24 - Step: 119 - MSE loss: 0.011295359 - KL loss: 0.20003659\n",
            "Epoch: 24 - Step: 120 - MSE loss: 0.00945898 - KL loss: 0.19729146\n",
            "Epoch: 24 - Step: 121 - MSE loss: 0.009063971 - KL loss: 0.1964243\n",
            "Epoch: 24 - Step: 122 - MSE loss: 0.009317802 - KL loss: 0.19557443\n",
            "Epoch: 24 - Step: 123 - MSE loss: 0.009104701 - KL loss: 0.19503093\n",
            "Epoch: 24 - Step: 124 - MSE loss: 0.009688397 - KL loss: 0.19740298\n",
            "Epoch: 24 - Step: 125 - MSE loss: 0.010228418 - KL loss: 0.20360196\n",
            "Epoch: 24 - Step: 126 - MSE loss: 0.010081031 - KL loss: 0.21480256\n",
            "Epoch: 24 - Step: 127 - MSE loss: 0.009478199 - KL loss: 0.21027647\n",
            "Epoch: 24 - Step: 128 - MSE loss: 0.009966586 - KL loss: 0.20456758\n",
            "Epoch: 24 - Step: 129 - MSE loss: 0.010132977 - KL loss: 0.20682612\n",
            "Epoch: 24 - Step: 130 - MSE loss: 0.010986873 - KL loss: 0.20924738\n",
            "Epoch: 24 - Step: 131 - MSE loss: 0.0103039015 - KL loss: 0.21786869\n",
            "Epoch: 24 - Step: 132 - MSE loss: 0.012143 - KL loss: 0.20086062\n",
            "Epoch: 24 - Step: 133 - MSE loss: 0.012003977 - KL loss: 0.19824046\n",
            "Epoch: 24 - Step: 134 - MSE loss: 0.013638494 - KL loss: 0.19840269\n",
            "Epoch: 24 - Step: 135 - MSE loss: 0.015151721 - KL loss: 0.20065148\n",
            "Epoch: 24 - Step: 136 - MSE loss: 0.015100867 - KL loss: 0.18196675\n",
            "Epoch: 24 - Step: 137 - MSE loss: 0.0156217255 - KL loss: 0.20926142\n",
            "Epoch: 24 - Step: 138 - MSE loss: 0.014690515 - KL loss: 0.18727224\n",
            "Epoch: 24 - Step: 139 - MSE loss: 0.012609967 - KL loss: 0.18706919\n",
            "Epoch: 24 - Step: 140 - MSE loss: 0.013047573 - KL loss: 0.19019483\n",
            "Epoch: 24 - Step: 141 - MSE loss: 0.0129659595 - KL loss: 0.20356615\n",
            "Epoch: 24 - Step: 142 - MSE loss: 0.012477834 - KL loss: 0.21326773\n",
            "Epoch: 24 - Step: 143 - MSE loss: 0.011263866 - KL loss: 0.20180416\n",
            "Epoch: 24 - Step: 144 - MSE loss: 0.011626458 - KL loss: 0.20955329\n",
            "Epoch:  25\n",
            "Epoch: 25 - Step: 0 - MSE loss: 0.0052651856 - KL loss: 0.1447652\n",
            "Epoch: 25 - Step: 1 - MSE loss: 0.005217075 - KL loss: 0.14448589\n",
            "Epoch: 25 - Step: 2 - MSE loss: 0.005412616 - KL loss: 0.15082185\n",
            "Epoch: 25 - Step: 3 - MSE loss: 0.0051770355 - KL loss: 0.14361176\n",
            "Epoch: 25 - Step: 4 - MSE loss: 0.0056136786 - KL loss: 0.14363334\n",
            "Epoch: 25 - Step: 5 - MSE loss: 0.0053347126 - KL loss: 0.1428165\n",
            "Epoch: 25 - Step: 6 - MSE loss: 0.006002271 - KL loss: 0.1396098\n",
            "Epoch: 25 - Step: 7 - MSE loss: 0.0057731005 - KL loss: 0.13524243\n",
            "Epoch: 25 - Step: 8 - MSE loss: 0.0059352913 - KL loss: 0.14314368\n",
            "Epoch: 25 - Step: 9 - MSE loss: 0.006559063 - KL loss: 0.14583997\n",
            "Epoch: 25 - Step: 10 - MSE loss: 0.006612793 - KL loss: 0.1372273\n",
            "Epoch: 25 - Step: 11 - MSE loss: 0.006322218 - KL loss: 0.13810527\n",
            "Epoch: 25 - Step: 12 - MSE loss: 0.006156241 - KL loss: 0.14146894\n",
            "Epoch: 25 - Step: 13 - MSE loss: 0.006511942 - KL loss: 0.1430763\n",
            "Epoch: 25 - Step: 14 - MSE loss: 0.0064776386 - KL loss: 0.13673227\n",
            "Epoch: 25 - Step: 15 - MSE loss: 0.0057179085 - KL loss: 0.14048406\n",
            "Epoch: 25 - Step: 16 - MSE loss: 0.0061360006 - KL loss: 0.14316727\n",
            "Epoch: 25 - Step: 17 - MSE loss: 0.005722554 - KL loss: 0.13582027\n",
            "Epoch: 25 - Step: 18 - MSE loss: 0.0057310015 - KL loss: 0.1268081\n",
            "Epoch: 25 - Step: 19 - MSE loss: 0.005305433 - KL loss: 0.12420621\n",
            "Epoch: 25 - Step: 20 - MSE loss: 0.005631009 - KL loss: 0.124689326\n",
            "Epoch: 25 - Step: 21 - MSE loss: 0.0056162938 - KL loss: 0.1232214\n",
            "Epoch: 25 - Step: 22 - MSE loss: 0.0058780913 - KL loss: 0.12598462\n",
            "Epoch: 25 - Step: 23 - MSE loss: 0.0059185084 - KL loss: 0.12856549\n",
            "Epoch: 25 - Step: 24 - MSE loss: 0.0056872 - KL loss: 0.12164412\n",
            "Epoch: 25 - Step: 25 - MSE loss: 0.005607831 - KL loss: 0.119229764\n",
            "Epoch: 25 - Step: 26 - MSE loss: 0.0060928906 - KL loss: 0.12286691\n",
            "Epoch: 25 - Step: 27 - MSE loss: 0.005807303 - KL loss: 0.12324816\n",
            "Epoch: 25 - Step: 28 - MSE loss: 0.0062930644 - KL loss: 0.12586118\n",
            "Epoch: 25 - Step: 29 - MSE loss: 0.005759085 - KL loss: 0.12623015\n",
            "Epoch: 25 - Step: 30 - MSE loss: 0.005717427 - KL loss: 0.11884286\n",
            "Epoch: 25 - Step: 31 - MSE loss: 0.005755628 - KL loss: 0.12026338\n",
            "Epoch: 25 - Step: 32 - MSE loss: 0.006346434 - KL loss: 0.12914798\n",
            "Epoch: 25 - Step: 33 - MSE loss: 0.0067126327 - KL loss: 0.13956735\n",
            "Epoch: 25 - Step: 34 - MSE loss: 0.0071874172 - KL loss: 0.14757532\n",
            "Epoch: 25 - Step: 35 - MSE loss: 0.007083827 - KL loss: 0.15056694\n",
            "Epoch: 25 - Step: 36 - MSE loss: 0.0077932947 - KL loss: 0.15599942\n",
            "Epoch: 25 - Step: 37 - MSE loss: 0.008137219 - KL loss: 0.16701767\n",
            "Epoch: 25 - Step: 38 - MSE loss: 0.009850081 - KL loss: 0.17919236\n",
            "Epoch: 25 - Step: 39 - MSE loss: 0.00852709 - KL loss: 0.18163198\n",
            "Epoch: 25 - Step: 40 - MSE loss: 0.009393158 - KL loss: 0.18780258\n",
            "Epoch: 25 - Step: 41 - MSE loss: 0.00911745 - KL loss: 0.1775786\n",
            "Epoch: 25 - Step: 42 - MSE loss: 0.009243797 - KL loss: 0.18192582\n",
            "Epoch: 25 - Step: 43 - MSE loss: 0.009723254 - KL loss: 0.19685508\n",
            "Epoch: 25 - Step: 44 - MSE loss: 0.008747934 - KL loss: 0.18991484\n",
            "Epoch: 25 - Step: 45 - MSE loss: 0.009513945 - KL loss: 0.18710917\n",
            "Epoch: 25 - Step: 46 - MSE loss: 0.009503539 - KL loss: 0.18607472\n",
            "Epoch: 25 - Step: 47 - MSE loss: 0.009570376 - KL loss: 0.19114566\n",
            "Epoch: 25 - Step: 48 - MSE loss: 0.009586994 - KL loss: 0.19650847\n",
            "Epoch: 25 - Step: 49 - MSE loss: 0.010152323 - KL loss: 0.19930913\n",
            "Epoch: 25 - Step: 50 - MSE loss: 0.009173456 - KL loss: 0.19259301\n",
            "Epoch: 25 - Step: 51 - MSE loss: 0.010115101 - KL loss: 0.19925794\n",
            "Epoch: 25 - Step: 52 - MSE loss: 0.010123729 - KL loss: 0.19210818\n",
            "Epoch: 25 - Step: 53 - MSE loss: 0.010568709 - KL loss: 0.20257168\n",
            "Epoch: 25 - Step: 54 - MSE loss: 0.011549878 - KL loss: 0.19649632\n",
            "Epoch: 25 - Step: 55 - MSE loss: 0.01091389 - KL loss: 0.20480359\n",
            "Epoch: 25 - Step: 56 - MSE loss: 0.010791157 - KL loss: 0.19381735\n",
            "Epoch: 25 - Step: 57 - MSE loss: 0.011277739 - KL loss: 0.20696016\n",
            "Epoch: 25 - Step: 58 - MSE loss: 0.010698528 - KL loss: 0.19271061\n",
            "Epoch: 25 - Step: 59 - MSE loss: 0.01066206 - KL loss: 0.20551157\n",
            "Epoch: 25 - Step: 60 - MSE loss: 0.011876562 - KL loss: 0.20028198\n",
            "Epoch: 25 - Step: 61 - MSE loss: 0.011133838 - KL loss: 0.20474514\n",
            "Epoch: 25 - Step: 62 - MSE loss: 0.0110702 - KL loss: 0.21615815\n",
            "Epoch: 25 - Step: 63 - MSE loss: 0.0113981 - KL loss: 0.20801765\n",
            "Epoch: 25 - Step: 64 - MSE loss: 0.012516483 - KL loss: 0.213756\n",
            "Epoch: 25 - Step: 65 - MSE loss: 0.012538888 - KL loss: 0.19956855\n",
            "Epoch: 25 - Step: 66 - MSE loss: 0.011646773 - KL loss: 0.19484577\n",
            "Epoch: 25 - Step: 67 - MSE loss: 0.010991762 - KL loss: 0.16837198\n",
            "Epoch: 25 - Step: 68 - MSE loss: 0.010609149 - KL loss: 0.17323995\n",
            "Epoch: 25 - Step: 69 - MSE loss: 0.0093283625 - KL loss: 0.17757756\n",
            "Epoch: 25 - Step: 70 - MSE loss: 0.008327024 - KL loss: 0.16475399\n",
            "Epoch: 25 - Step: 71 - MSE loss: 0.007549556 - KL loss: 0.16021022\n",
            "Epoch: 25 - Step: 72 - MSE loss: 0.0075742076 - KL loss: 0.15932488\n",
            "Epoch: 25 - Step: 73 - MSE loss: 0.006441402 - KL loss: 0.14735614\n",
            "Epoch: 25 - Step: 74 - MSE loss: 0.006591726 - KL loss: 0.14219707\n",
            "Epoch: 25 - Step: 75 - MSE loss: 0.0057578576 - KL loss: 0.12790132\n",
            "Epoch: 25 - Step: 76 - MSE loss: 0.005448215 - KL loss: 0.13510299\n",
            "Epoch: 25 - Step: 77 - MSE loss: 0.00581942 - KL loss: 0.12817925\n",
            "Epoch: 25 - Step: 78 - MSE loss: 0.006199343 - KL loss: 0.12855923\n",
            "Epoch: 25 - Step: 79 - MSE loss: 0.0065278676 - KL loss: 0.13571495\n",
            "Epoch: 25 - Step: 80 - MSE loss: 0.005601848 - KL loss: 0.12548672\n",
            "Epoch: 25 - Step: 81 - MSE loss: 0.006129096 - KL loss: 0.13308337\n",
            "Epoch: 25 - Step: 82 - MSE loss: 0.0063883574 - KL loss: 0.1334047\n",
            "Epoch: 25 - Step: 83 - MSE loss: 0.006101009 - KL loss: 0.13336194\n",
            "Epoch: 25 - Step: 84 - MSE loss: 0.0067068744 - KL loss: 0.13744394\n",
            "Epoch: 25 - Step: 85 - MSE loss: 0.0065242555 - KL loss: 0.1433869\n",
            "Epoch: 25 - Step: 86 - MSE loss: 0.006669614 - KL loss: 0.13614285\n",
            "Epoch: 25 - Step: 87 - MSE loss: 0.0061270143 - KL loss: 0.14239128\n",
            "Epoch: 25 - Step: 88 - MSE loss: 0.0064625666 - KL loss: 0.14446041\n",
            "Epoch: 25 - Step: 89 - MSE loss: 0.0059864656 - KL loss: 0.14026749\n",
            "Epoch: 25 - Step: 90 - MSE loss: 0.00587707 - KL loss: 0.13976982\n",
            "Epoch: 25 - Step: 91 - MSE loss: 0.0063732234 - KL loss: 0.14546533\n",
            "Epoch: 25 - Step: 92 - MSE loss: 0.0060589896 - KL loss: 0.14865611\n",
            "Epoch: 25 - Step: 93 - MSE loss: 0.0060299966 - KL loss: 0.14230773\n",
            "Epoch: 25 - Step: 94 - MSE loss: 0.0059861024 - KL loss: 0.13222066\n",
            "Epoch: 25 - Step: 95 - MSE loss: 0.0066323914 - KL loss: 0.13745907\n",
            "Epoch: 25 - Step: 96 - MSE loss: 0.0068709557 - KL loss: 0.13850656\n",
            "Epoch: 25 - Step: 97 - MSE loss: 0.006426902 - KL loss: 0.13925488\n",
            "Epoch: 25 - Step: 98 - MSE loss: 0.0063091903 - KL loss: 0.13749327\n",
            "Epoch: 25 - Step: 99 - MSE loss: 0.006777637 - KL loss: 0.14265448\n",
            "Epoch: 25 - Step: 100 - MSE loss: 0.00673601 - KL loss: 0.14953622\n",
            "Epoch: 25 - Step: 101 - MSE loss: 0.006137661 - KL loss: 0.13848343\n",
            "Epoch: 25 - Step: 102 - MSE loss: 0.0061975042 - KL loss: 0.14032295\n",
            "Epoch: 25 - Step: 103 - MSE loss: 0.0061978563 - KL loss: 0.13537729\n",
            "Epoch: 25 - Step: 104 - MSE loss: 0.0067680576 - KL loss: 0.14488558\n",
            "Epoch: 25 - Step: 105 - MSE loss: 0.0071124616 - KL loss: 0.15487787\n",
            "Epoch: 25 - Step: 106 - MSE loss: 0.007772397 - KL loss: 0.16257982\n",
            "Epoch: 25 - Step: 107 - MSE loss: 0.007864145 - KL loss: 0.16248286\n",
            "Epoch: 25 - Step: 108 - MSE loss: 0.0078021474 - KL loss: 0.17006433\n",
            "Epoch: 25 - Step: 109 - MSE loss: 0.008143257 - KL loss: 0.18513459\n",
            "Epoch: 25 - Step: 110 - MSE loss: 0.008298048 - KL loss: 0.17577147\n",
            "Epoch: 25 - Step: 111 - MSE loss: 0.009470695 - KL loss: 0.19878617\n",
            "Epoch: 25 - Step: 112 - MSE loss: 0.010440788 - KL loss: 0.18474987\n",
            "Epoch: 25 - Step: 113 - MSE loss: 0.010114994 - KL loss: 0.19933453\n",
            "Epoch: 25 - Step: 114 - MSE loss: 0.010410548 - KL loss: 0.19402152\n",
            "Epoch: 25 - Step: 115 - MSE loss: 0.01036297 - KL loss: 0.19141777\n",
            "Epoch: 25 - Step: 116 - MSE loss: 0.010594585 - KL loss: 0.21059018\n",
            "Epoch: 25 - Step: 117 - MSE loss: 0.010451297 - KL loss: 0.1935302\n",
            "Epoch: 25 - Step: 118 - MSE loss: 0.011116237 - KL loss: 0.21074992\n",
            "Epoch: 25 - Step: 119 - MSE loss: 0.010767066 - KL loss: 0.18006557\n",
            "Epoch: 25 - Step: 120 - MSE loss: 0.010292274 - KL loss: 0.19258821\n",
            "Epoch: 25 - Step: 121 - MSE loss: 0.0095649455 - KL loss: 0.19312795\n",
            "Epoch: 25 - Step: 122 - MSE loss: 0.00976945 - KL loss: 0.19746386\n",
            "Epoch: 25 - Step: 123 - MSE loss: 0.010112881 - KL loss: 0.19562921\n",
            "Epoch: 25 - Step: 124 - MSE loss: 0.009623103 - KL loss: 0.20218506\n",
            "Epoch: 25 - Step: 125 - MSE loss: 0.00986082 - KL loss: 0.19973044\n",
            "Epoch: 25 - Step: 126 - MSE loss: 0.010184883 - KL loss: 0.20521703\n",
            "Epoch: 25 - Step: 127 - MSE loss: 0.010345555 - KL loss: 0.19269934\n",
            "Epoch: 25 - Step: 128 - MSE loss: 0.009614703 - KL loss: 0.19826108\n",
            "Epoch: 25 - Step: 129 - MSE loss: 0.00980797 - KL loss: 0.20152617\n",
            "Epoch: 25 - Step: 130 - MSE loss: 0.0109835295 - KL loss: 0.20889549\n",
            "Epoch: 25 - Step: 131 - MSE loss: 0.010469701 - KL loss: 0.19632298\n",
            "Epoch: 25 - Step: 132 - MSE loss: 0.011083677 - KL loss: 0.2064566\n",
            "Epoch: 25 - Step: 133 - MSE loss: 0.01098228 - KL loss: 0.20550373\n",
            "Epoch: 25 - Step: 134 - MSE loss: 0.012129902 - KL loss: 0.20759128\n",
            "Epoch: 25 - Step: 135 - MSE loss: 0.01082873 - KL loss: 0.20224093\n",
            "Epoch: 25 - Step: 136 - MSE loss: 0.01209415 - KL loss: 0.21298158\n",
            "Epoch: 25 - Step: 137 - MSE loss: 0.011162209 - KL loss: 0.20400108\n",
            "Epoch: 25 - Step: 138 - MSE loss: 0.010719024 - KL loss: 0.20033386\n",
            "Epoch: 25 - Step: 139 - MSE loss: 0.010956881 - KL loss: 0.20897838\n",
            "Epoch: 25 - Step: 140 - MSE loss: 0.010985136 - KL loss: 0.19514678\n",
            "Epoch: 25 - Step: 141 - MSE loss: 0.011378202 - KL loss: 0.20282602\n",
            "Epoch: 25 - Step: 142 - MSE loss: 0.010621057 - KL loss: 0.19561133\n",
            "Epoch: 25 - Step: 143 - MSE loss: 0.011633678 - KL loss: 0.20226078\n",
            "Epoch: 25 - Step: 144 - MSE loss: 0.011802903 - KL loss: 0.2040989\n",
            "Epoch:  26\n",
            "Epoch: 26 - Step: 0 - MSE loss: 0.00500888 - KL loss: 0.13448507\n",
            "Epoch: 26 - Step: 1 - MSE loss: 0.005608784 - KL loss: 0.14032423\n",
            "Epoch: 26 - Step: 2 - MSE loss: 0.0059928526 - KL loss: 0.14458065\n",
            "Epoch: 26 - Step: 3 - MSE loss: 0.0055273287 - KL loss: 0.1437102\n",
            "Epoch: 26 - Step: 4 - MSE loss: 0.0055097155 - KL loss: 0.13703823\n",
            "Epoch: 26 - Step: 5 - MSE loss: 0.005428428 - KL loss: 0.12875193\n",
            "Epoch: 26 - Step: 6 - MSE loss: 0.006457735 - KL loss: 0.13031848\n",
            "Epoch: 26 - Step: 7 - MSE loss: 0.0061830706 - KL loss: 0.13655324\n",
            "Epoch: 26 - Step: 8 - MSE loss: 0.005947896 - KL loss: 0.13291577\n",
            "Epoch: 26 - Step: 9 - MSE loss: 0.005878301 - KL loss: 0.13309386\n",
            "Epoch: 26 - Step: 10 - MSE loss: 0.006850429 - KL loss: 0.14256603\n",
            "Epoch: 26 - Step: 11 - MSE loss: 0.0061178505 - KL loss: 0.13828972\n",
            "Epoch: 26 - Step: 12 - MSE loss: 0.006066076 - KL loss: 0.13682911\n",
            "Epoch: 26 - Step: 13 - MSE loss: 0.0059160884 - KL loss: 0.13954146\n",
            "Epoch: 26 - Step: 14 - MSE loss: 0.0068355873 - KL loss: 0.13873672\n",
            "Epoch: 26 - Step: 15 - MSE loss: 0.00663346 - KL loss: 0.14471166\n",
            "Epoch: 26 - Step: 16 - MSE loss: 0.006754467 - KL loss: 0.13718045\n",
            "Epoch: 26 - Step: 17 - MSE loss: 0.0066173673 - KL loss: 0.13781185\n",
            "Epoch: 26 - Step: 18 - MSE loss: 0.0062769367 - KL loss: 0.12967002\n",
            "Epoch: 26 - Step: 19 - MSE loss: 0.005323842 - KL loss: 0.12624559\n",
            "Epoch: 26 - Step: 20 - MSE loss: 0.005684411 - KL loss: 0.1231164\n",
            "Epoch: 26 - Step: 21 - MSE loss: 0.0056487643 - KL loss: 0.12138869\n",
            "Epoch: 26 - Step: 22 - MSE loss: 0.0057038437 - KL loss: 0.122358024\n",
            "Epoch: 26 - Step: 23 - MSE loss: 0.005978364 - KL loss: 0.1256114\n",
            "Epoch: 26 - Step: 24 - MSE loss: 0.0054932353 - KL loss: 0.12367494\n",
            "Epoch: 26 - Step: 25 - MSE loss: 0.0058132946 - KL loss: 0.1252259\n",
            "Epoch: 26 - Step: 26 - MSE loss: 0.005495254 - KL loss: 0.121864125\n",
            "Epoch: 26 - Step: 27 - MSE loss: 0.006021394 - KL loss: 0.122299775\n",
            "Epoch: 26 - Step: 28 - MSE loss: 0.0053467774 - KL loss: 0.12162405\n",
            "Epoch: 26 - Step: 29 - MSE loss: 0.0054926234 - KL loss: 0.12107973\n",
            "Epoch: 26 - Step: 30 - MSE loss: 0.0054698116 - KL loss: 0.11939329\n",
            "Epoch: 26 - Step: 31 - MSE loss: 0.004909077 - KL loss: 0.114859626\n",
            "Epoch: 26 - Step: 32 - MSE loss: 0.006007137 - KL loss: 0.130169\n",
            "Epoch: 26 - Step: 33 - MSE loss: 0.006634979 - KL loss: 0.13572234\n",
            "Epoch: 26 - Step: 34 - MSE loss: 0.0071952622 - KL loss: 0.14735763\n",
            "Epoch: 26 - Step: 35 - MSE loss: 0.0072547984 - KL loss: 0.147396\n",
            "Epoch: 26 - Step: 36 - MSE loss: 0.007682456 - KL loss: 0.15701225\n",
            "Epoch: 26 - Step: 37 - MSE loss: 0.0081282975 - KL loss: 0.17262545\n",
            "Epoch: 26 - Step: 38 - MSE loss: 0.008758993 - KL loss: 0.17528051\n",
            "Epoch: 26 - Step: 39 - MSE loss: 0.009600663 - KL loss: 0.19140233\n",
            "Epoch: 26 - Step: 40 - MSE loss: 0.009464617 - KL loss: 0.17501092\n",
            "Epoch: 26 - Step: 41 - MSE loss: 0.00965226 - KL loss: 0.1850439\n",
            "Epoch: 26 - Step: 42 - MSE loss: 0.008198961 - KL loss: 0.17495134\n",
            "Epoch: 26 - Step: 43 - MSE loss: 0.008698997 - KL loss: 0.19377702\n",
            "Epoch: 26 - Step: 44 - MSE loss: 0.007972372 - KL loss: 0.17957109\n",
            "Epoch: 26 - Step: 45 - MSE loss: 0.008909722 - KL loss: 0.18894947\n",
            "Epoch: 26 - Step: 46 - MSE loss: 0.009833691 - KL loss: 0.19422725\n",
            "Epoch: 26 - Step: 47 - MSE loss: 0.008760068 - KL loss: 0.19260171\n",
            "Epoch: 26 - Step: 48 - MSE loss: 0.009259815 - KL loss: 0.1934833\n",
            "Epoch: 26 - Step: 49 - MSE loss: 0.010252363 - KL loss: 0.195247\n",
            "Epoch: 26 - Step: 50 - MSE loss: 0.008813663 - KL loss: 0.18851894\n",
            "Epoch: 26 - Step: 51 - MSE loss: 0.010163392 - KL loss: 0.19321671\n",
            "Epoch: 26 - Step: 52 - MSE loss: 0.010603816 - KL loss: 0.20220453\n",
            "Epoch: 26 - Step: 53 - MSE loss: 0.010299471 - KL loss: 0.19570589\n",
            "Epoch: 26 - Step: 54 - MSE loss: 0.010176242 - KL loss: 0.1955137\n",
            "Epoch: 26 - Step: 55 - MSE loss: 0.01018984 - KL loss: 0.19929755\n",
            "Epoch: 26 - Step: 56 - MSE loss: 0.009996778 - KL loss: 0.21007614\n",
            "Epoch: 26 - Step: 57 - MSE loss: 0.010306318 - KL loss: 0.19601966\n",
            "Epoch: 26 - Step: 58 - MSE loss: 0.010846534 - KL loss: 0.20326573\n",
            "Epoch: 26 - Step: 59 - MSE loss: 0.011480086 - KL loss: 0.19939233\n",
            "Epoch: 26 - Step: 60 - MSE loss: 0.0110712135 - KL loss: 0.20887911\n",
            "Epoch: 26 - Step: 61 - MSE loss: 0.010161617 - KL loss: 0.20313555\n",
            "Epoch: 26 - Step: 62 - MSE loss: 0.010048366 - KL loss: 0.20428051\n",
            "Epoch: 26 - Step: 63 - MSE loss: 0.011440239 - KL loss: 0.21177728\n",
            "Epoch: 26 - Step: 64 - MSE loss: 0.0113309035 - KL loss: 0.21936676\n",
            "Epoch: 26 - Step: 65 - MSE loss: 0.013158069 - KL loss: 0.19519272\n",
            "Epoch: 26 - Step: 66 - MSE loss: 0.0119219385 - KL loss: 0.20116779\n",
            "Epoch: 26 - Step: 67 - MSE loss: 0.013032029 - KL loss: 0.16630033\n",
            "Epoch: 26 - Step: 68 - MSE loss: 0.011133042 - KL loss: 0.16237995\n",
            "Epoch: 26 - Step: 69 - MSE loss: 0.009329301 - KL loss: 0.15998873\n",
            "Epoch: 26 - Step: 70 - MSE loss: 0.00834144 - KL loss: 0.15818156\n",
            "Epoch: 26 - Step: 71 - MSE loss: 0.008099527 - KL loss: 0.1659411\n",
            "Epoch: 26 - Step: 72 - MSE loss: 0.007203836 - KL loss: 0.15467246\n",
            "Epoch: 26 - Step: 73 - MSE loss: 0.007127927 - KL loss: 0.14625202\n",
            "Epoch: 26 - Step: 74 - MSE loss: 0.0064960844 - KL loss: 0.13672748\n",
            "Epoch: 26 - Step: 75 - MSE loss: 0.0064814626 - KL loss: 0.1381731\n",
            "Epoch: 26 - Step: 76 - MSE loss: 0.006325092 - KL loss: 0.12938453\n",
            "Epoch: 26 - Step: 77 - MSE loss: 0.0055524106 - KL loss: 0.1234735\n",
            "Epoch: 26 - Step: 78 - MSE loss: 0.005898814 - KL loss: 0.12708479\n",
            "Epoch: 26 - Step: 79 - MSE loss: 0.00642756 - KL loss: 0.13319099\n",
            "Epoch: 26 - Step: 80 - MSE loss: 0.0068341414 - KL loss: 0.13811947\n",
            "Epoch: 26 - Step: 81 - MSE loss: 0.006124366 - KL loss: 0.12808692\n",
            "Epoch: 26 - Step: 82 - MSE loss: 0.0058142487 - KL loss: 0.13271508\n",
            "Epoch: 26 - Step: 83 - MSE loss: 0.006231192 - KL loss: 0.12753855\n",
            "Epoch: 26 - Step: 84 - MSE loss: 0.006497869 - KL loss: 0.13477027\n",
            "Epoch: 26 - Step: 85 - MSE loss: 0.0058730985 - KL loss: 0.12786661\n",
            "Epoch: 26 - Step: 86 - MSE loss: 0.0061240825 - KL loss: 0.141292\n",
            "Epoch: 26 - Step: 87 - MSE loss: 0.0062469724 - KL loss: 0.1358704\n",
            "Epoch: 26 - Step: 88 - MSE loss: 0.006218271 - KL loss: 0.14225276\n",
            "Epoch: 26 - Step: 89 - MSE loss: 0.0059504714 - KL loss: 0.13847633\n",
            "Epoch: 26 - Step: 90 - MSE loss: 0.0057206047 - KL loss: 0.13756499\n",
            "Epoch: 26 - Step: 91 - MSE loss: 0.0056077726 - KL loss: 0.14140934\n",
            "Epoch: 26 - Step: 92 - MSE loss: 0.0061789746 - KL loss: 0.13654087\n",
            "Epoch: 26 - Step: 93 - MSE loss: 0.005777528 - KL loss: 0.13957793\n",
            "Epoch: 26 - Step: 94 - MSE loss: 0.0061410093 - KL loss: 0.13859311\n",
            "Epoch: 26 - Step: 95 - MSE loss: 0.0061306786 - KL loss: 0.14114356\n",
            "Epoch: 26 - Step: 96 - MSE loss: 0.006224913 - KL loss: 0.14206693\n",
            "Epoch: 26 - Step: 97 - MSE loss: 0.005957015 - KL loss: 0.13775042\n",
            "Epoch: 26 - Step: 98 - MSE loss: 0.0062869363 - KL loss: 0.14265603\n",
            "Epoch: 26 - Step: 99 - MSE loss: 0.0063598915 - KL loss: 0.1427944\n",
            "Epoch: 26 - Step: 100 - MSE loss: 0.0062072673 - KL loss: 0.14723557\n",
            "Epoch: 26 - Step: 101 - MSE loss: 0.0057347915 - KL loss: 0.13246268\n",
            "Epoch: 26 - Step: 102 - MSE loss: 0.005870678 - KL loss: 0.14137246\n",
            "Epoch: 26 - Step: 103 - MSE loss: 0.005121263 - KL loss: 0.13716689\n",
            "Epoch: 26 - Step: 104 - MSE loss: 0.005490625 - KL loss: 0.1427562\n",
            "Epoch: 26 - Step: 105 - MSE loss: 0.0066675064 - KL loss: 0.14781967\n",
            "Epoch: 26 - Step: 106 - MSE loss: 0.007311592 - KL loss: 0.1628572\n",
            "Epoch: 26 - Step: 107 - MSE loss: 0.007972732 - KL loss: 0.16582054\n",
            "Epoch: 26 - Step: 108 - MSE loss: 0.0073346845 - KL loss: 0.169155\n",
            "Epoch: 26 - Step: 109 - MSE loss: 0.007992334 - KL loss: 0.1738211\n",
            "Epoch: 26 - Step: 110 - MSE loss: 0.007871437 - KL loss: 0.1818803\n",
            "Epoch: 26 - Step: 111 - MSE loss: 0.009205982 - KL loss: 0.18718469\n",
            "Epoch: 26 - Step: 112 - MSE loss: 0.009275152 - KL loss: 0.18087369\n",
            "Epoch: 26 - Step: 113 - MSE loss: 0.010389852 - KL loss: 0.19216461\n",
            "Epoch: 26 - Step: 114 - MSE loss: 0.010447546 - KL loss: 0.19759876\n",
            "Epoch: 26 - Step: 115 - MSE loss: 0.01062584 - KL loss: 0.19782531\n",
            "Epoch: 26 - Step: 116 - MSE loss: 0.010584543 - KL loss: 0.20349395\n",
            "Epoch: 26 - Step: 117 - MSE loss: 0.01047619 - KL loss: 0.18651043\n",
            "Epoch: 26 - Step: 118 - MSE loss: 0.010480854 - KL loss: 0.20728952\n",
            "Epoch: 26 - Step: 119 - MSE loss: 0.010549474 - KL loss: 0.1838561\n",
            "Epoch: 26 - Step: 120 - MSE loss: 0.009825337 - KL loss: 0.18628305\n",
            "Epoch: 26 - Step: 121 - MSE loss: 0.008974 - KL loss: 0.18836209\n",
            "Epoch: 26 - Step: 122 - MSE loss: 0.010207377 - KL loss: 0.204429\n",
            "Epoch: 26 - Step: 123 - MSE loss: 0.009185503 - KL loss: 0.19534113\n",
            "Epoch: 26 - Step: 124 - MSE loss: 0.009121909 - KL loss: 0.19373927\n",
            "Epoch: 26 - Step: 125 - MSE loss: 0.009505514 - KL loss: 0.2010189\n",
            "Epoch: 26 - Step: 126 - MSE loss: 0.009862932 - KL loss: 0.20766325\n",
            "Epoch: 26 - Step: 127 - MSE loss: 0.008894552 - KL loss: 0.19791627\n",
            "Epoch: 26 - Step: 128 - MSE loss: 0.009772717 - KL loss: 0.19686462\n",
            "Epoch: 26 - Step: 129 - MSE loss: 0.009828738 - KL loss: 0.19385931\n",
            "Epoch: 26 - Step: 130 - MSE loss: 0.009274573 - KL loss: 0.19910108\n",
            "Epoch: 26 - Step: 131 - MSE loss: 0.0101372 - KL loss: 0.2045874\n",
            "Epoch: 26 - Step: 132 - MSE loss: 0.011321622 - KL loss: 0.20394003\n",
            "Epoch: 26 - Step: 133 - MSE loss: 0.013466085 - KL loss: 0.21919122\n",
            "Epoch: 26 - Step: 134 - MSE loss: 0.016308721 - KL loss: 0.18080752\n",
            "Epoch: 26 - Step: 135 - MSE loss: 0.015259263 - KL loss: 0.20152566\n",
            "Epoch: 26 - Step: 136 - MSE loss: 0.013800219 - KL loss: 0.19308105\n",
            "Epoch: 26 - Step: 137 - MSE loss: 0.012381435 - KL loss: 0.20039664\n",
            "Epoch: 26 - Step: 138 - MSE loss: 0.011561339 - KL loss: 0.18594743\n",
            "Epoch: 26 - Step: 139 - MSE loss: 0.011897661 - KL loss: 0.19786929\n",
            "Epoch: 26 - Step: 140 - MSE loss: 0.010671034 - KL loss: 0.20544697\n",
            "Epoch: 26 - Step: 141 - MSE loss: 0.01093815 - KL loss: 0.20686463\n",
            "Epoch: 26 - Step: 142 - MSE loss: 0.011389689 - KL loss: 0.20239642\n",
            "Epoch: 26 - Step: 143 - MSE loss: 0.011913099 - KL loss: 0.19794124\n",
            "Epoch: 26 - Step: 144 - MSE loss: 0.011727016 - KL loss: 0.20413618\n",
            "Epoch:  27\n",
            "Epoch: 27 - Step: 0 - MSE loss: 0.005675927 - KL loss: 0.1318095\n",
            "Epoch: 27 - Step: 1 - MSE loss: 0.0056030364 - KL loss: 0.14873701\n",
            "Epoch: 27 - Step: 2 - MSE loss: 0.0057200524 - KL loss: 0.1534358\n",
            "Epoch: 27 - Step: 3 - MSE loss: 0.0057788454 - KL loss: 0.13627934\n",
            "Epoch: 27 - Step: 4 - MSE loss: 0.0068162675 - KL loss: 0.13766915\n",
            "Epoch: 27 - Step: 5 - MSE loss: 0.007124076 - KL loss: 0.13583705\n",
            "Epoch: 27 - Step: 6 - MSE loss: 0.006682785 - KL loss: 0.13388142\n",
            "Epoch: 27 - Step: 7 - MSE loss: 0.005983887 - KL loss: 0.13434485\n",
            "Epoch: 27 - Step: 8 - MSE loss: 0.00635614 - KL loss: 0.14140224\n",
            "Epoch: 27 - Step: 9 - MSE loss: 0.006552778 - KL loss: 0.14257959\n",
            "Epoch: 27 - Step: 10 - MSE loss: 0.005999936 - KL loss: 0.13807032\n",
            "Epoch: 27 - Step: 11 - MSE loss: 0.0058743297 - KL loss: 0.13799238\n",
            "Epoch: 27 - Step: 12 - MSE loss: 0.005959377 - KL loss: 0.13930488\n",
            "Epoch: 27 - Step: 13 - MSE loss: 0.005979128 - KL loss: 0.1361495\n",
            "Epoch: 27 - Step: 14 - MSE loss: 0.006354081 - KL loss: 0.13256612\n",
            "Epoch: 27 - Step: 15 - MSE loss: 0.006091945 - KL loss: 0.14090963\n",
            "Epoch: 27 - Step: 16 - MSE loss: 0.0059930845 - KL loss: 0.13303396\n",
            "Epoch: 27 - Step: 17 - MSE loss: 0.0057132333 - KL loss: 0.13544878\n",
            "Epoch: 27 - Step: 18 - MSE loss: 0.0053988234 - KL loss: 0.13526365\n",
            "Epoch: 27 - Step: 19 - MSE loss: 0.005111259 - KL loss: 0.124150485\n",
            "Epoch: 27 - Step: 20 - MSE loss: 0.005092111 - KL loss: 0.11981304\n",
            "Epoch: 27 - Step: 21 - MSE loss: 0.005481368 - KL loss: 0.1200238\n",
            "Epoch: 27 - Step: 22 - MSE loss: 0.0059046294 - KL loss: 0.12338128\n",
            "Epoch: 27 - Step: 23 - MSE loss: 0.0056710546 - KL loss: 0.123374335\n",
            "Epoch: 27 - Step: 24 - MSE loss: 0.005256079 - KL loss: 0.12420426\n",
            "Epoch: 27 - Step: 25 - MSE loss: 0.005631123 - KL loss: 0.12394139\n",
            "Epoch: 27 - Step: 26 - MSE loss: 0.005782749 - KL loss: 0.12503137\n",
            "Epoch: 27 - Step: 27 - MSE loss: 0.005892774 - KL loss: 0.12532255\n",
            "Epoch: 27 - Step: 28 - MSE loss: 0.0058005494 - KL loss: 0.12663773\n",
            "Epoch: 27 - Step: 29 - MSE loss: 0.0054756994 - KL loss: 0.117963344\n",
            "Epoch: 27 - Step: 30 - MSE loss: 0.0054071136 - KL loss: 0.118734166\n",
            "Epoch: 27 - Step: 31 - MSE loss: 0.00549317 - KL loss: 0.12044047\n",
            "Epoch: 27 - Step: 32 - MSE loss: 0.006180573 - KL loss: 0.13211688\n",
            "Epoch: 27 - Step: 33 - MSE loss: 0.006171743 - KL loss: 0.13618863\n",
            "Epoch: 27 - Step: 34 - MSE loss: 0.007146588 - KL loss: 0.1520666\n",
            "Epoch: 27 - Step: 35 - MSE loss: 0.007193882 - KL loss: 0.15005307\n",
            "Epoch: 27 - Step: 36 - MSE loss: 0.00791202 - KL loss: 0.16301435\n",
            "Epoch: 27 - Step: 37 - MSE loss: 0.007828208 - KL loss: 0.16906169\n",
            "Epoch: 27 - Step: 38 - MSE loss: 0.007969908 - KL loss: 0.17618312\n",
            "Epoch: 27 - Step: 39 - MSE loss: 0.008982557 - KL loss: 0.18203437\n",
            "Epoch: 27 - Step: 40 - MSE loss: 0.009211061 - KL loss: 0.17796832\n",
            "Epoch: 27 - Step: 41 - MSE loss: 0.009092991 - KL loss: 0.17906782\n",
            "Epoch: 27 - Step: 42 - MSE loss: 0.00803627 - KL loss: 0.17533909\n",
            "Epoch: 27 - Step: 43 - MSE loss: 0.009296798 - KL loss: 0.1825642\n",
            "Epoch: 27 - Step: 44 - MSE loss: 0.00840695 - KL loss: 0.18704936\n",
            "Epoch: 27 - Step: 45 - MSE loss: 0.008360952 - KL loss: 0.18171768\n",
            "Epoch: 27 - Step: 46 - MSE loss: 0.009322518 - KL loss: 0.18890753\n",
            "Epoch: 27 - Step: 47 - MSE loss: 0.008767912 - KL loss: 0.18845697\n",
            "Epoch: 27 - Step: 48 - MSE loss: 0.009320634 - KL loss: 0.18807562\n",
            "Epoch: 27 - Step: 49 - MSE loss: 0.009655549 - KL loss: 0.19326812\n",
            "Epoch: 27 - Step: 50 - MSE loss: 0.009374726 - KL loss: 0.19685462\n",
            "Epoch: 27 - Step: 51 - MSE loss: 0.009804213 - KL loss: 0.19738519\n",
            "Epoch: 27 - Step: 52 - MSE loss: 0.010025998 - KL loss: 0.18933478\n",
            "Epoch: 27 - Step: 53 - MSE loss: 0.010393714 - KL loss: 0.19029921\n",
            "Epoch: 27 - Step: 54 - MSE loss: 0.010156548 - KL loss: 0.19488291\n",
            "Epoch: 27 - Step: 55 - MSE loss: 0.010545609 - KL loss: 0.20408162\n",
            "Epoch: 27 - Step: 56 - MSE loss: 0.010046013 - KL loss: 0.19211766\n",
            "Epoch: 27 - Step: 57 - MSE loss: 0.010442932 - KL loss: 0.1951965\n",
            "Epoch: 27 - Step: 58 - MSE loss: 0.010131753 - KL loss: 0.19939333\n",
            "Epoch: 27 - Step: 59 - MSE loss: 0.010241971 - KL loss: 0.20637399\n",
            "Epoch: 27 - Step: 60 - MSE loss: 0.011201389 - KL loss: 0.21031302\n",
            "Epoch: 27 - Step: 61 - MSE loss: 0.010685329 - KL loss: 0.20699328\n",
            "Epoch: 27 - Step: 62 - MSE loss: 0.011087357 - KL loss: 0.21253678\n",
            "Epoch: 27 - Step: 63 - MSE loss: 0.01096686 - KL loss: 0.19483393\n",
            "Epoch: 27 - Step: 64 - MSE loss: 0.011639059 - KL loss: 0.21173166\n",
            "Epoch: 27 - Step: 65 - MSE loss: 0.01104428 - KL loss: 0.20617831\n",
            "Epoch: 27 - Step: 66 - MSE loss: 0.009575105 - KL loss: 0.19004588\n",
            "Epoch: 27 - Step: 67 - MSE loss: 0.00896639 - KL loss: 0.18207932\n",
            "Epoch: 27 - Step: 68 - MSE loss: 0.009134183 - KL loss: 0.17017356\n",
            "Epoch: 27 - Step: 69 - MSE loss: 0.008601913 - KL loss: 0.17520866\n",
            "Epoch: 27 - Step: 70 - MSE loss: 0.008725767 - KL loss: 0.17469639\n",
            "Epoch: 27 - Step: 71 - MSE loss: 0.0073308726 - KL loss: 0.14738634\n",
            "Epoch: 27 - Step: 72 - MSE loss: 0.00663312 - KL loss: 0.1478272\n",
            "Epoch: 27 - Step: 73 - MSE loss: 0.0063791745 - KL loss: 0.1399438\n",
            "Epoch: 27 - Step: 74 - MSE loss: 0.005633069 - KL loss: 0.12849072\n",
            "Epoch: 27 - Step: 75 - MSE loss: 0.006382305 - KL loss: 0.13297576\n",
            "Epoch: 27 - Step: 76 - MSE loss: 0.0058086663 - KL loss: 0.1271067\n",
            "Epoch: 27 - Step: 77 - MSE loss: 0.0062602144 - KL loss: 0.12922423\n",
            "Epoch: 27 - Step: 78 - MSE loss: 0.0060580787 - KL loss: 0.123024926\n",
            "Epoch: 27 - Step: 79 - MSE loss: 0.0065688672 - KL loss: 0.12974843\n",
            "Epoch: 27 - Step: 80 - MSE loss: 0.0058014193 - KL loss: 0.12727329\n",
            "Epoch: 27 - Step: 81 - MSE loss: 0.0063158907 - KL loss: 0.13439053\n",
            "Epoch: 27 - Step: 82 - MSE loss: 0.0060803946 - KL loss: 0.13392094\n",
            "Epoch: 27 - Step: 83 - MSE loss: 0.0061957645 - KL loss: 0.13382886\n",
            "Epoch: 27 - Step: 84 - MSE loss: 0.0062027504 - KL loss: 0.1337735\n",
            "Epoch: 27 - Step: 85 - MSE loss: 0.0058394335 - KL loss: 0.12984586\n",
            "Epoch: 27 - Step: 86 - MSE loss: 0.005867576 - KL loss: 0.12978959\n",
            "Epoch: 27 - Step: 87 - MSE loss: 0.006216859 - KL loss: 0.13546467\n",
            "Epoch: 27 - Step: 88 - MSE loss: 0.0064645833 - KL loss: 0.13595963\n",
            "Epoch: 27 - Step: 89 - MSE loss: 0.0059165023 - KL loss: 0.13741677\n",
            "Epoch: 27 - Step: 90 - MSE loss: 0.005959149 - KL loss: 0.14010084\n",
            "Epoch: 27 - Step: 91 - MSE loss: 0.0060621276 - KL loss: 0.13913946\n",
            "Epoch: 27 - Step: 92 - MSE loss: 0.0058847466 - KL loss: 0.13833003\n",
            "Epoch: 27 - Step: 93 - MSE loss: 0.005607827 - KL loss: 0.14114453\n",
            "Epoch: 27 - Step: 94 - MSE loss: 0.005729558 - KL loss: 0.1360528\n",
            "Epoch: 27 - Step: 95 - MSE loss: 0.0054804645 - KL loss: 0.13943338\n",
            "Epoch: 27 - Step: 96 - MSE loss: 0.005755858 - KL loss: 0.13686809\n",
            "Epoch: 27 - Step: 97 - MSE loss: 0.006492996 - KL loss: 0.1435915\n",
            "Epoch: 27 - Step: 98 - MSE loss: 0.005728822 - KL loss: 0.14535524\n",
            "Epoch: 27 - Step: 99 - MSE loss: 0.0061095916 - KL loss: 0.14004365\n",
            "Epoch: 27 - Step: 100 - MSE loss: 0.0058540273 - KL loss: 0.13411847\n",
            "Epoch: 27 - Step: 101 - MSE loss: 0.005354864 - KL loss: 0.13900232\n",
            "Epoch: 27 - Step: 102 - MSE loss: 0.005470121 - KL loss: 0.13382617\n",
            "Epoch: 27 - Step: 103 - MSE loss: 0.005085674 - KL loss: 0.13170443\n",
            "Epoch: 27 - Step: 104 - MSE loss: 0.0056616943 - KL loss: 0.14479306\n",
            "Epoch: 27 - Step: 105 - MSE loss: 0.006571227 - KL loss: 0.15004271\n",
            "Epoch: 27 - Step: 106 - MSE loss: 0.0061606183 - KL loss: 0.15776917\n",
            "Epoch: 27 - Step: 107 - MSE loss: 0.008643536 - KL loss: 0.17653364\n",
            "Epoch: 27 - Step: 108 - MSE loss: 0.007286956 - KL loss: 0.16091576\n",
            "Epoch: 27 - Step: 109 - MSE loss: 0.0077905445 - KL loss: 0.1719033\n",
            "Epoch: 27 - Step: 110 - MSE loss: 0.008833638 - KL loss: 0.18542638\n",
            "Epoch: 27 - Step: 111 - MSE loss: 0.0088376375 - KL loss: 0.19143735\n",
            "Epoch: 27 - Step: 112 - MSE loss: 0.00857697 - KL loss: 0.17865224\n",
            "Epoch: 27 - Step: 113 - MSE loss: 0.009684036 - KL loss: 0.18801756\n",
            "Epoch: 27 - Step: 114 - MSE loss: 0.009775332 - KL loss: 0.1947062\n",
            "Epoch: 27 - Step: 115 - MSE loss: 0.010253641 - KL loss: 0.1836451\n",
            "Epoch: 27 - Step: 116 - MSE loss: 0.010355684 - KL loss: 0.1891955\n",
            "Epoch: 27 - Step: 117 - MSE loss: 0.010412821 - KL loss: 0.19068934\n",
            "Epoch: 27 - Step: 118 - MSE loss: 0.010517159 - KL loss: 0.20337301\n",
            "Epoch: 27 - Step: 119 - MSE loss: 0.010268526 - KL loss: 0.19168516\n",
            "Epoch: 27 - Step: 120 - MSE loss: 0.009516815 - KL loss: 0.20119813\n",
            "Epoch: 27 - Step: 121 - MSE loss: 0.009347488 - KL loss: 0.19351427\n",
            "Epoch: 27 - Step: 122 - MSE loss: 0.008225605 - KL loss: 0.19457258\n",
            "Epoch: 27 - Step: 123 - MSE loss: 0.008980527 - KL loss: 0.18434505\n",
            "Epoch: 27 - Step: 124 - MSE loss: 0.008647193 - KL loss: 0.19582433\n",
            "Epoch: 27 - Step: 125 - MSE loss: 0.008608375 - KL loss: 0.19131263\n",
            "Epoch: 27 - Step: 126 - MSE loss: 0.00895307 - KL loss: 0.19435668\n",
            "Epoch: 27 - Step: 127 - MSE loss: 0.009086451 - KL loss: 0.19617148\n",
            "Epoch: 27 - Step: 128 - MSE loss: 0.009053526 - KL loss: 0.19613115\n",
            "Epoch: 27 - Step: 129 - MSE loss: 0.009781999 - KL loss: 0.20756502\n",
            "Epoch: 27 - Step: 130 - MSE loss: 0.0097754095 - KL loss: 0.19077274\n",
            "Epoch: 27 - Step: 131 - MSE loss: 0.01063595 - KL loss: 0.20263346\n",
            "Epoch: 27 - Step: 132 - MSE loss: 0.011753012 - KL loss: 0.20641036\n",
            "Epoch: 27 - Step: 133 - MSE loss: 0.012134044 - KL loss: 0.1880885\n",
            "Epoch: 27 - Step: 134 - MSE loss: 0.013171158 - KL loss: 0.21366487\n",
            "Epoch: 27 - Step: 135 - MSE loss: 0.01292944 - KL loss: 0.18927386\n",
            "Epoch: 27 - Step: 136 - MSE loss: 0.011276919 - KL loss: 0.19396642\n",
            "Epoch: 27 - Step: 137 - MSE loss: 0.011935656 - KL loss: 0.19122995\n",
            "Epoch: 27 - Step: 138 - MSE loss: 0.0110353865 - KL loss: 0.19989249\n",
            "Epoch: 27 - Step: 139 - MSE loss: 0.010917178 - KL loss: 0.19405743\n",
            "Epoch: 27 - Step: 140 - MSE loss: 0.011829342 - KL loss: 0.20053186\n",
            "Epoch: 27 - Step: 141 - MSE loss: 0.011170433 - KL loss: 0.19324842\n",
            "Epoch: 27 - Step: 142 - MSE loss: 0.009971458 - KL loss: 0.1970253\n",
            "Epoch: 27 - Step: 143 - MSE loss: 0.010246207 - KL loss: 0.19232418\n",
            "Epoch: 27 - Step: 144 - MSE loss: 0.010696973 - KL loss: 0.20348316\n",
            "Epoch:  28\n",
            "Epoch: 28 - Step: 0 - MSE loss: 0.0047427057 - KL loss: 0.13631877\n",
            "Epoch: 28 - Step: 1 - MSE loss: 0.0052818474 - KL loss: 0.13859776\n",
            "Epoch: 28 - Step: 2 - MSE loss: 0.0051862714 - KL loss: 0.14338315\n",
            "Epoch: 28 - Step: 3 - MSE loss: 0.0051608304 - KL loss: 0.14238337\n",
            "Epoch: 28 - Step: 4 - MSE loss: 0.005191162 - KL loss: 0.13993081\n",
            "Epoch: 28 - Step: 5 - MSE loss: 0.0054045483 - KL loss: 0.13045768\n",
            "Epoch: 28 - Step: 6 - MSE loss: 0.0055800336 - KL loss: 0.12994072\n",
            "Epoch: 28 - Step: 7 - MSE loss: 0.0056444127 - KL loss: 0.133383\n",
            "Epoch: 28 - Step: 8 - MSE loss: 0.0059895385 - KL loss: 0.1385653\n",
            "Epoch: 28 - Step: 9 - MSE loss: 0.0063859764 - KL loss: 0.13364868\n",
            "Epoch: 28 - Step: 10 - MSE loss: 0.006146207 - KL loss: 0.13452274\n",
            "Epoch: 28 - Step: 11 - MSE loss: 0.0056851506 - KL loss: 0.13264513\n",
            "Epoch: 28 - Step: 12 - MSE loss: 0.006143168 - KL loss: 0.13740432\n",
            "Epoch: 28 - Step: 13 - MSE loss: 0.0059104636 - KL loss: 0.13513786\n",
            "Epoch: 28 - Step: 14 - MSE loss: 0.0060776807 - KL loss: 0.13929354\n",
            "Epoch: 28 - Step: 15 - MSE loss: 0.006297915 - KL loss: 0.13697043\n",
            "Epoch: 28 - Step: 16 - MSE loss: 0.0057683135 - KL loss: 0.13936388\n",
            "Epoch: 28 - Step: 17 - MSE loss: 0.0054282914 - KL loss: 0.14033926\n",
            "Epoch: 28 - Step: 18 - MSE loss: 0.0051865284 - KL loss: 0.1279668\n",
            "Epoch: 28 - Step: 19 - MSE loss: 0.004955448 - KL loss: 0.12890795\n",
            "Epoch: 28 - Step: 20 - MSE loss: 0.005173193 - KL loss: 0.11847666\n",
            "Epoch: 28 - Step: 21 - MSE loss: 0.005154573 - KL loss: 0.120098464\n",
            "Epoch: 28 - Step: 22 - MSE loss: 0.005798496 - KL loss: 0.12398656\n",
            "Epoch: 28 - Step: 23 - MSE loss: 0.005758144 - KL loss: 0.12586783\n",
            "Epoch: 28 - Step: 24 - MSE loss: 0.0053324043 - KL loss: 0.12008479\n",
            "Epoch: 28 - Step: 25 - MSE loss: 0.0054906285 - KL loss: 0.12515762\n",
            "Epoch: 28 - Step: 26 - MSE loss: 0.0057561155 - KL loss: 0.12302834\n",
            "Epoch: 28 - Step: 27 - MSE loss: 0.0057763713 - KL loss: 0.121934265\n",
            "Epoch: 28 - Step: 28 - MSE loss: 0.005903315 - KL loss: 0.11945702\n",
            "Epoch: 28 - Step: 29 - MSE loss: 0.005211701 - KL loss: 0.1180611\n",
            "Epoch: 28 - Step: 30 - MSE loss: 0.0050779725 - KL loss: 0.11886771\n",
            "Epoch: 28 - Step: 31 - MSE loss: 0.00505699 - KL loss: 0.11900063\n",
            "Epoch: 28 - Step: 32 - MSE loss: 0.0063957144 - KL loss: 0.1343927\n",
            "Epoch: 28 - Step: 33 - MSE loss: 0.0062161125 - KL loss: 0.127995\n",
            "Epoch: 28 - Step: 34 - MSE loss: 0.007067615 - KL loss: 0.14082992\n",
            "Epoch: 28 - Step: 35 - MSE loss: 0.0059512816 - KL loss: 0.14870554\n",
            "Epoch: 28 - Step: 36 - MSE loss: 0.0074916244 - KL loss: 0.16004047\n",
            "Epoch: 28 - Step: 37 - MSE loss: 0.008167857 - KL loss: 0.16816333\n",
            "Epoch: 28 - Step: 38 - MSE loss: 0.0088849515 - KL loss: 0.17976162\n",
            "Epoch: 28 - Step: 39 - MSE loss: 0.009475436 - KL loss: 0.17767353\n",
            "Epoch: 28 - Step: 40 - MSE loss: 0.008810199 - KL loss: 0.18101667\n",
            "Epoch: 28 - Step: 41 - MSE loss: 0.00806835 - KL loss: 0.15979514\n",
            "Epoch: 28 - Step: 42 - MSE loss: 0.008415336 - KL loss: 0.18352017\n",
            "Epoch: 28 - Step: 43 - MSE loss: 0.007807221 - KL loss: 0.17126358\n",
            "Epoch: 28 - Step: 44 - MSE loss: 0.008788286 - KL loss: 0.18054056\n",
            "Epoch: 28 - Step: 45 - MSE loss: 0.008419578 - KL loss: 0.18307528\n",
            "Epoch: 28 - Step: 46 - MSE loss: 0.008877416 - KL loss: 0.18312025\n",
            "Epoch: 28 - Step: 47 - MSE loss: 0.008114745 - KL loss: 0.17932639\n",
            "Epoch: 28 - Step: 48 - MSE loss: 0.008883537 - KL loss: 0.19268015\n",
            "Epoch: 28 - Step: 49 - MSE loss: 0.008731452 - KL loss: 0.18945408\n",
            "Epoch: 28 - Step: 50 - MSE loss: 0.008677981 - KL loss: 0.18176615\n",
            "Epoch: 28 - Step: 51 - MSE loss: 0.009836299 - KL loss: 0.1972738\n",
            "Epoch: 28 - Step: 52 - MSE loss: 0.009905403 - KL loss: 0.19674185\n",
            "Epoch: 28 - Step: 53 - MSE loss: 0.0099976165 - KL loss: 0.20179176\n",
            "Epoch: 28 - Step: 54 - MSE loss: 0.010166666 - KL loss: 0.19449197\n",
            "Epoch: 28 - Step: 55 - MSE loss: 0.009742003 - KL loss: 0.1873743\n",
            "Epoch: 28 - Step: 56 - MSE loss: 0.01000998 - KL loss: 0.20750704\n",
            "Epoch: 28 - Step: 57 - MSE loss: 0.010756674 - KL loss: 0.18876791\n",
            "Epoch: 28 - Step: 58 - MSE loss: 0.010589051 - KL loss: 0.20675533\n",
            "Epoch: 28 - Step: 59 - MSE loss: 0.01027466 - KL loss: 0.19319355\n",
            "Epoch: 28 - Step: 60 - MSE loss: 0.010457661 - KL loss: 0.19864655\n",
            "Epoch: 28 - Step: 61 - MSE loss: 0.011060181 - KL loss: 0.20534305\n",
            "Epoch: 28 - Step: 62 - MSE loss: 0.010237836 - KL loss: 0.20644362\n",
            "Epoch: 28 - Step: 63 - MSE loss: 0.010209348 - KL loss: 0.19326866\n",
            "Epoch: 28 - Step: 64 - MSE loss: 0.012165158 - KL loss: 0.22072119\n",
            "Epoch: 28 - Step: 65 - MSE loss: 0.011444427 - KL loss: 0.18661582\n",
            "Epoch: 28 - Step: 66 - MSE loss: 0.010197141 - KL loss: 0.1875404\n",
            "Epoch: 28 - Step: 67 - MSE loss: 0.009529365 - KL loss: 0.18037194\n",
            "Epoch: 28 - Step: 68 - MSE loss: 0.008731915 - KL loss: 0.16582887\n",
            "Epoch: 28 - Step: 69 - MSE loss: 0.00859552 - KL loss: 0.1734276\n",
            "Epoch: 28 - Step: 70 - MSE loss: 0.0074690855 - KL loss: 0.15855667\n",
            "Epoch: 28 - Step: 71 - MSE loss: 0.0068890653 - KL loss: 0.15046804\n",
            "Epoch: 28 - Step: 72 - MSE loss: 0.0070196656 - KL loss: 0.1517919\n",
            "Epoch: 28 - Step: 73 - MSE loss: 0.007157616 - KL loss: 0.14497107\n",
            "Epoch: 28 - Step: 74 - MSE loss: 0.005606169 - KL loss: 0.12870747\n",
            "Epoch: 28 - Step: 75 - MSE loss: 0.0057154666 - KL loss: 0.1299648\n",
            "Epoch: 28 - Step: 76 - MSE loss: 0.0062208916 - KL loss: 0.13815032\n",
            "Epoch: 28 - Step: 77 - MSE loss: 0.0059840153 - KL loss: 0.13190672\n",
            "Epoch: 28 - Step: 78 - MSE loss: 0.0060772873 - KL loss: 0.13037527\n",
            "Epoch: 28 - Step: 79 - MSE loss: 0.005649921 - KL loss: 0.1287097\n",
            "Epoch: 28 - Step: 80 - MSE loss: 0.005619008 - KL loss: 0.12697403\n",
            "Epoch: 28 - Step: 81 - MSE loss: 0.0059957444 - KL loss: 0.12366563\n",
            "Epoch: 28 - Step: 82 - MSE loss: 0.0057691815 - KL loss: 0.13215134\n",
            "Epoch: 28 - Step: 83 - MSE loss: 0.0056792363 - KL loss: 0.1308938\n",
            "Epoch: 28 - Step: 84 - MSE loss: 0.006010762 - KL loss: 0.13074724\n",
            "Epoch: 28 - Step: 85 - MSE loss: 0.0056211553 - KL loss: 0.13201085\n",
            "Epoch: 28 - Step: 86 - MSE loss: 0.0067325085 - KL loss: 0.13313875\n",
            "Epoch: 28 - Step: 87 - MSE loss: 0.006735822 - KL loss: 0.1336283\n",
            "Epoch: 28 - Step: 88 - MSE loss: 0.0063351872 - KL loss: 0.13095717\n",
            "Epoch: 28 - Step: 89 - MSE loss: 0.0066749174 - KL loss: 0.13486469\n",
            "Epoch: 28 - Step: 90 - MSE loss: 0.00593677 - KL loss: 0.13416061\n",
            "Epoch: 28 - Step: 91 - MSE loss: 0.005769776 - KL loss: 0.13832995\n",
            "Epoch: 28 - Step: 92 - MSE loss: 0.0053226594 - KL loss: 0.13510439\n",
            "Epoch: 28 - Step: 93 - MSE loss: 0.005504522 - KL loss: 0.13735914\n",
            "Epoch: 28 - Step: 94 - MSE loss: 0.0054935324 - KL loss: 0.13394135\n",
            "Epoch: 28 - Step: 95 - MSE loss: 0.006162776 - KL loss: 0.14406331\n",
            "Epoch: 28 - Step: 96 - MSE loss: 0.006317998 - KL loss: 0.13784258\n",
            "Epoch: 28 - Step: 97 - MSE loss: 0.0062134354 - KL loss: 0.14372042\n",
            "Epoch: 28 - Step: 98 - MSE loss: 0.0060951184 - KL loss: 0.13545844\n",
            "Epoch: 28 - Step: 99 - MSE loss: 0.0058645396 - KL loss: 0.14456692\n",
            "Epoch: 28 - Step: 100 - MSE loss: 0.0055125486 - KL loss: 0.14039898\n",
            "Epoch: 28 - Step: 101 - MSE loss: 0.0058186445 - KL loss: 0.13301368\n",
            "Epoch: 28 - Step: 102 - MSE loss: 0.0054741935 - KL loss: 0.13379423\n",
            "Epoch: 28 - Step: 103 - MSE loss: 0.0052063405 - KL loss: 0.13635424\n",
            "Epoch: 28 - Step: 104 - MSE loss: 0.00585649 - KL loss: 0.14208749\n",
            "Epoch: 28 - Step: 105 - MSE loss: 0.006256638 - KL loss: 0.14642948\n",
            "Epoch: 28 - Step: 106 - MSE loss: 0.0066192057 - KL loss: 0.14647555\n",
            "Epoch: 28 - Step: 107 - MSE loss: 0.007155509 - KL loss: 0.1647253\n",
            "Epoch: 28 - Step: 108 - MSE loss: 0.0073424517 - KL loss: 0.16752437\n",
            "Epoch: 28 - Step: 109 - MSE loss: 0.008222266 - KL loss: 0.16984253\n",
            "Epoch: 28 - Step: 110 - MSE loss: 0.007120218 - KL loss: 0.1730218\n",
            "Epoch: 28 - Step: 111 - MSE loss: 0.008528475 - KL loss: 0.19050632\n",
            "Epoch: 28 - Step: 112 - MSE loss: 0.008959656 - KL loss: 0.19567943\n",
            "Epoch: 28 - Step: 113 - MSE loss: 0.009754163 - KL loss: 0.19666666\n",
            "Epoch: 28 - Step: 114 - MSE loss: 0.009608139 - KL loss: 0.19828115\n",
            "Epoch: 28 - Step: 115 - MSE loss: 0.010784752 - KL loss: 0.19238967\n",
            "Epoch: 28 - Step: 116 - MSE loss: 0.01001907 - KL loss: 0.20119812\n",
            "Epoch: 28 - Step: 117 - MSE loss: 0.009682119 - KL loss: 0.18541253\n",
            "Epoch: 28 - Step: 118 - MSE loss: 0.010155226 - KL loss: 0.19051412\n",
            "Epoch: 28 - Step: 119 - MSE loss: 0.009208069 - KL loss: 0.18679929\n",
            "Epoch: 28 - Step: 120 - MSE loss: 0.008297709 - KL loss: 0.18976049\n",
            "Epoch: 28 - Step: 121 - MSE loss: 0.008726004 - KL loss: 0.1885858\n",
            "Epoch: 28 - Step: 122 - MSE loss: 0.008522644 - KL loss: 0.19119725\n",
            "Epoch: 28 - Step: 123 - MSE loss: 0.008541036 - KL loss: 0.19349307\n",
            "Epoch: 28 - Step: 124 - MSE loss: 0.008643315 - KL loss: 0.19191177\n",
            "Epoch: 28 - Step: 125 - MSE loss: 0.008243094 - KL loss: 0.19233476\n",
            "Epoch: 28 - Step: 126 - MSE loss: 0.008389886 - KL loss: 0.19120988\n",
            "Epoch: 28 - Step: 127 - MSE loss: 0.008547872 - KL loss: 0.18590125\n",
            "Epoch: 28 - Step: 128 - MSE loss: 0.00873403 - KL loss: 0.1920667\n",
            "Epoch: 28 - Step: 129 - MSE loss: 0.00830419 - KL loss: 0.18553302\n",
            "Epoch: 28 - Step: 130 - MSE loss: 0.009224492 - KL loss: 0.1991683\n",
            "Epoch: 28 - Step: 131 - MSE loss: 0.009363903 - KL loss: 0.19821002\n",
            "Epoch: 28 - Step: 132 - MSE loss: 0.009750435 - KL loss: 0.20186134\n",
            "Epoch: 28 - Step: 133 - MSE loss: 0.011619863 - KL loss: 0.2019963\n",
            "Epoch: 28 - Step: 134 - MSE loss: 0.012268887 - KL loss: 0.20641175\n",
            "Epoch: 28 - Step: 135 - MSE loss: 0.014337194 - KL loss: 0.18217742\n",
            "Epoch: 28 - Step: 136 - MSE loss: 0.013843856 - KL loss: 0.1992593\n",
            "Epoch: 28 - Step: 137 - MSE loss: 0.013142239 - KL loss: 0.17516528\n",
            "Epoch: 28 - Step: 138 - MSE loss: 0.013601395 - KL loss: 0.1944137\n",
            "Epoch: 28 - Step: 139 - MSE loss: 0.013459887 - KL loss: 0.18138665\n",
            "Epoch: 28 - Step: 140 - MSE loss: 0.014549118 - KL loss: 0.208184\n",
            "Epoch: 28 - Step: 141 - MSE loss: 0.015558003 - KL loss: 0.19023496\n",
            "Epoch: 28 - Step: 142 - MSE loss: 0.01690171 - KL loss: 0.18138337\n",
            "Epoch: 28 - Step: 143 - MSE loss: 0.014424149 - KL loss: 0.16296339\n",
            "Epoch: 28 - Step: 144 - MSE loss: 0.012779023 - KL loss: 0.19159603\n",
            "Epoch:  29\n",
            "Epoch: 29 - Step: 0 - MSE loss: 0.0066473726 - KL loss: 0.13267386\n",
            "Epoch: 29 - Step: 1 - MSE loss: 0.006955978 - KL loss: 0.14521012\n",
            "Epoch: 29 - Step: 2 - MSE loss: 0.006583719 - KL loss: 0.14703405\n",
            "Epoch: 29 - Step: 3 - MSE loss: 0.0058327243 - KL loss: 0.14171119\n",
            "Epoch: 29 - Step: 4 - MSE loss: 0.005437217 - KL loss: 0.14173959\n",
            "Epoch: 29 - Step: 5 - MSE loss: 0.0055241794 - KL loss: 0.14158297\n",
            "Epoch: 29 - Step: 6 - MSE loss: 0.0056648813 - KL loss: 0.1357032\n",
            "Epoch: 29 - Step: 7 - MSE loss: 0.00564529 - KL loss: 0.14306808\n",
            "Epoch: 29 - Step: 8 - MSE loss: 0.0058626295 - KL loss: 0.14043783\n",
            "Epoch: 29 - Step: 9 - MSE loss: 0.0058714454 - KL loss: 0.13220024\n",
            "Epoch: 29 - Step: 10 - MSE loss: 0.0063298936 - KL loss: 0.13291973\n",
            "Epoch: 29 - Step: 11 - MSE loss: 0.005652819 - KL loss: 0.13408642\n",
            "Epoch: 29 - Step: 12 - MSE loss: 0.00563357 - KL loss: 0.13461415\n",
            "Epoch: 29 - Step: 13 - MSE loss: 0.0055333953 - KL loss: 0.13762587\n",
            "Epoch: 29 - Step: 14 - MSE loss: 0.005962584 - KL loss: 0.13754643\n",
            "Epoch: 29 - Step: 15 - MSE loss: 0.00560493 - KL loss: 0.13795151\n",
            "Epoch: 29 - Step: 16 - MSE loss: 0.006052272 - KL loss: 0.13876948\n",
            "Epoch: 29 - Step: 17 - MSE loss: 0.0050203972 - KL loss: 0.12792052\n",
            "Epoch: 29 - Step: 18 - MSE loss: 0.0055913287 - KL loss: 0.121957295\n",
            "Epoch: 29 - Step: 19 - MSE loss: 0.004868319 - KL loss: 0.121192396\n",
            "Epoch: 29 - Step: 20 - MSE loss: 0.005324027 - KL loss: 0.12138327\n",
            "Epoch: 29 - Step: 21 - MSE loss: 0.005244522 - KL loss: 0.1234967\n",
            "Epoch: 29 - Step: 22 - MSE loss: 0.00566633 - KL loss: 0.12476593\n",
            "Epoch: 29 - Step: 23 - MSE loss: 0.0057338625 - KL loss: 0.12326704\n",
            "Epoch: 29 - Step: 24 - MSE loss: 0.0052399035 - KL loss: 0.123219386\n",
            "Epoch: 29 - Step: 25 - MSE loss: 0.0053258645 - KL loss: 0.12589456\n",
            "Epoch: 29 - Step: 26 - MSE loss: 0.005104789 - KL loss: 0.11617224\n",
            "Epoch: 29 - Step: 27 - MSE loss: 0.0053470233 - KL loss: 0.1225938\n",
            "Epoch: 29 - Step: 28 - MSE loss: 0.0053947535 - KL loss: 0.118711896\n",
            "Epoch: 29 - Step: 29 - MSE loss: 0.005289071 - KL loss: 0.11963455\n",
            "Epoch: 29 - Step: 30 - MSE loss: 0.004395577 - KL loss: 0.11365782\n",
            "Epoch: 29 - Step: 31 - MSE loss: 0.0050383094 - KL loss: 0.12337263\n",
            "Epoch: 29 - Step: 32 - MSE loss: 0.005600425 - KL loss: 0.12492544\n",
            "Epoch: 29 - Step: 33 - MSE loss: 0.0066037267 - KL loss: 0.13612573\n",
            "Epoch: 29 - Step: 34 - MSE loss: 0.00694892 - KL loss: 0.14467077\n",
            "Epoch: 29 - Step: 35 - MSE loss: 0.0069824294 - KL loss: 0.15780823\n",
            "Epoch: 29 - Step: 36 - MSE loss: 0.0071690963 - KL loss: 0.15968356\n",
            "Epoch: 29 - Step: 37 - MSE loss: 0.00754733 - KL loss: 0.16949266\n",
            "Epoch: 29 - Step: 38 - MSE loss: 0.008359461 - KL loss: 0.17284003\n",
            "Epoch: 29 - Step: 39 - MSE loss: 0.008291835 - KL loss: 0.17436266\n",
            "Epoch: 29 - Step: 40 - MSE loss: 0.009555919 - KL loss: 0.18233544\n",
            "Epoch: 29 - Step: 41 - MSE loss: 0.008748457 - KL loss: 0.17683786\n",
            "Epoch: 29 - Step: 42 - MSE loss: 0.007913357 - KL loss: 0.17295721\n",
            "Epoch: 29 - Step: 43 - MSE loss: 0.007854835 - KL loss: 0.17292854\n",
            "Epoch: 29 - Step: 44 - MSE loss: 0.008058804 - KL loss: 0.18327242\n",
            "Epoch: 29 - Step: 45 - MSE loss: 0.007450201 - KL loss: 0.17389089\n",
            "Epoch: 29 - Step: 46 - MSE loss: 0.007832869 - KL loss: 0.18174486\n",
            "Epoch: 29 - Step: 47 - MSE loss: 0.009414389 - KL loss: 0.19092715\n",
            "Epoch: 29 - Step: 48 - MSE loss: 0.008995038 - KL loss: 0.18873456\n",
            "Epoch: 29 - Step: 49 - MSE loss: 0.008666816 - KL loss: 0.18422109\n",
            "Epoch: 29 - Step: 50 - MSE loss: 0.008908075 - KL loss: 0.18657637\n",
            "Epoch: 29 - Step: 51 - MSE loss: 0.009566852 - KL loss: 0.19026017\n",
            "Epoch: 29 - Step: 52 - MSE loss: 0.009505909 - KL loss: 0.19621566\n",
            "Epoch: 29 - Step: 53 - MSE loss: 0.0107993195 - KL loss: 0.19441023\n",
            "Epoch: 29 - Step: 54 - MSE loss: 0.009922709 - KL loss: 0.19372465\n",
            "Epoch: 29 - Step: 55 - MSE loss: 0.010204627 - KL loss: 0.19845276\n",
            "Epoch: 29 - Step: 56 - MSE loss: 0.009000803 - KL loss: 0.19675145\n",
            "Epoch: 29 - Step: 57 - MSE loss: 0.009877301 - KL loss: 0.1930346\n",
            "Epoch: 29 - Step: 58 - MSE loss: 0.009513293 - KL loss: 0.19077128\n",
            "Epoch: 29 - Step: 59 - MSE loss: 0.00984292 - KL loss: 0.19358328\n",
            "Epoch: 29 - Step: 60 - MSE loss: 0.010545284 - KL loss: 0.20307675\n",
            "Epoch: 29 - Step: 61 - MSE loss: 0.009786524 - KL loss: 0.19820355\n",
            "Epoch: 29 - Step: 62 - MSE loss: 0.009485046 - KL loss: 0.21489519\n",
            "Epoch: 29 - Step: 63 - MSE loss: 0.009734253 - KL loss: 0.18921876\n",
            "Epoch: 29 - Step: 64 - MSE loss: 0.010803449 - KL loss: 0.19892678\n",
            "Epoch: 29 - Step: 65 - MSE loss: 0.010226564 - KL loss: 0.2060522\n",
            "Epoch: 29 - Step: 66 - MSE loss: 0.008983888 - KL loss: 0.18329202\n",
            "Epoch: 29 - Step: 67 - MSE loss: 0.009044115 - KL loss: 0.17714506\n",
            "Epoch: 29 - Step: 68 - MSE loss: 0.008248015 - KL loss: 0.16493264\n",
            "Epoch: 29 - Step: 69 - MSE loss: 0.008577723 - KL loss: 0.16998178\n",
            "Epoch: 29 - Step: 70 - MSE loss: 0.0075926855 - KL loss: 0.15878747\n",
            "Epoch: 29 - Step: 71 - MSE loss: 0.006912062 - KL loss: 0.14632782\n",
            "Epoch: 29 - Step: 72 - MSE loss: 0.0059400555 - KL loss: 0.14223802\n",
            "Epoch: 29 - Step: 73 - MSE loss: 0.006314399 - KL loss: 0.14013997\n",
            "Epoch: 29 - Step: 74 - MSE loss: 0.006172618 - KL loss: 0.13292418\n",
            "Epoch: 29 - Step: 75 - MSE loss: 0.0053726137 - KL loss: 0.12697434\n",
            "Epoch: 29 - Step: 76 - MSE loss: 0.0055687013 - KL loss: 0.1256209\n",
            "Epoch: 29 - Step: 77 - MSE loss: 0.0058054067 - KL loss: 0.124779865\n",
            "Epoch: 29 - Step: 78 - MSE loss: 0.006611292 - KL loss: 0.12981957\n",
            "Epoch: 29 - Step: 79 - MSE loss: 0.0059186206 - KL loss: 0.1288328\n",
            "Epoch: 29 - Step: 80 - MSE loss: 0.005535819 - KL loss: 0.1256776\n",
            "Epoch: 29 - Step: 81 - MSE loss: 0.005805086 - KL loss: 0.12854314\n",
            "Epoch: 29 - Step: 82 - MSE loss: 0.006048706 - KL loss: 0.12716123\n",
            "Epoch: 29 - Step: 83 - MSE loss: 0.006668909 - KL loss: 0.13328597\n",
            "Epoch: 29 - Step: 84 - MSE loss: 0.0062715127 - KL loss: 0.12805825\n",
            "Epoch: 29 - Step: 85 - MSE loss: 0.0059191263 - KL loss: 0.12863132\n",
            "Epoch: 29 - Step: 86 - MSE loss: 0.006064309 - KL loss: 0.13608715\n",
            "Epoch: 29 - Step: 87 - MSE loss: 0.0056155524 - KL loss: 0.1304558\n",
            "Epoch: 29 - Step: 88 - MSE loss: 0.0061272825 - KL loss: 0.1318813\n",
            "Epoch: 29 - Step: 89 - MSE loss: 0.005537892 - KL loss: 0.13474013\n",
            "Epoch: 29 - Step: 90 - MSE loss: 0.0058703334 - KL loss: 0.14210519\n",
            "Epoch: 29 - Step: 91 - MSE loss: 0.005811734 - KL loss: 0.14382404\n",
            "Epoch: 29 - Step: 92 - MSE loss: 0.005271817 - KL loss: 0.13862002\n",
            "Epoch: 29 - Step: 93 - MSE loss: 0.0055912235 - KL loss: 0.1375489\n",
            "Epoch: 29 - Step: 94 - MSE loss: 0.0051129526 - KL loss: 0.1359272\n",
            "Epoch: 29 - Step: 95 - MSE loss: 0.0058274525 - KL loss: 0.13637845\n",
            "Epoch: 29 - Step: 96 - MSE loss: 0.006370397 - KL loss: 0.14346021\n",
            "Epoch: 29 - Step: 97 - MSE loss: 0.005416837 - KL loss: 0.13152039\n",
            "Epoch: 29 - Step: 98 - MSE loss: 0.005688047 - KL loss: 0.13686912\n",
            "Epoch: 29 - Step: 99 - MSE loss: 0.0056884033 - KL loss: 0.1425258\n",
            "Epoch: 29 - Step: 100 - MSE loss: 0.0056202896 - KL loss: 0.14076754\n",
            "Epoch: 29 - Step: 101 - MSE loss: 0.0054408885 - KL loss: 0.12920722\n",
            "Epoch: 29 - Step: 102 - MSE loss: 0.00578654 - KL loss: 0.13582882\n",
            "Epoch: 29 - Step: 103 - MSE loss: 0.005081082 - KL loss: 0.1367709\n",
            "Epoch: 29 - Step: 104 - MSE loss: 0.0053121434 - KL loss: 0.1380597\n",
            "Epoch: 29 - Step: 105 - MSE loss: 0.005752787 - KL loss: 0.14581048\n",
            "Epoch: 29 - Step: 106 - MSE loss: 0.0064469283 - KL loss: 0.14494142\n",
            "Epoch: 29 - Step: 107 - MSE loss: 0.007570593 - KL loss: 0.1628435\n",
            "Epoch: 29 - Step: 108 - MSE loss: 0.0071830745 - KL loss: 0.16514145\n",
            "Epoch: 29 - Step: 109 - MSE loss: 0.007530264 - KL loss: 0.17711881\n",
            "Epoch: 29 - Step: 110 - MSE loss: 0.007790456 - KL loss: 0.18700965\n",
            "Epoch: 29 - Step: 111 - MSE loss: 0.008888685 - KL loss: 0.18227844\n",
            "Epoch: 29 - Step: 112 - MSE loss: 0.008265028 - KL loss: 0.18400204\n",
            "Epoch: 29 - Step: 113 - MSE loss: 0.008439885 - KL loss: 0.18118376\n",
            "Epoch: 29 - Step: 114 - MSE loss: 0.008615537 - KL loss: 0.18622217\n",
            "Epoch: 29 - Step: 115 - MSE loss: 0.009332097 - KL loss: 0.1910036\n",
            "Epoch: 29 - Step: 116 - MSE loss: 0.009407221 - KL loss: 0.18712932\n",
            "Epoch: 29 - Step: 117 - MSE loss: 0.009360963 - KL loss: 0.19891489\n",
            "Epoch: 29 - Step: 118 - MSE loss: 0.010116217 - KL loss: 0.19278471\n",
            "Epoch: 29 - Step: 119 - MSE loss: 0.008689224 - KL loss: 0.19007832\n",
            "Epoch: 29 - Step: 120 - MSE loss: 0.00854521 - KL loss: 0.18028527\n",
            "Epoch: 29 - Step: 121 - MSE loss: 0.008820959 - KL loss: 0.19025967\n",
            "Epoch: 29 - Step: 122 - MSE loss: 0.008885608 - KL loss: 0.18188362\n",
            "Epoch: 29 - Step: 123 - MSE loss: 0.008498384 - KL loss: 0.19448397\n",
            "Epoch: 29 - Step: 124 - MSE loss: 0.00937339 - KL loss: 0.18872067\n",
            "Epoch: 29 - Step: 125 - MSE loss: 0.008907581 - KL loss: 0.19516586\n",
            "Epoch: 29 - Step: 126 - MSE loss: 0.009301989 - KL loss: 0.19415204\n",
            "Epoch: 29 - Step: 127 - MSE loss: 0.009261926 - KL loss: 0.19314699\n",
            "Epoch: 29 - Step: 128 - MSE loss: 0.008774611 - KL loss: 0.18558154\n",
            "Epoch: 29 - Step: 129 - MSE loss: 0.008754009 - KL loss: 0.18983555\n",
            "Epoch: 29 - Step: 130 - MSE loss: 0.008856039 - KL loss: 0.19265588\n",
            "Epoch: 29 - Step: 131 - MSE loss: 0.009779594 - KL loss: 0.19910657\n",
            "Epoch: 29 - Step: 132 - MSE loss: 0.011365682 - KL loss: 0.19613491\n",
            "Epoch: 29 - Step: 133 - MSE loss: 0.010631003 - KL loss: 0.20244706\n",
            "Epoch: 29 - Step: 134 - MSE loss: 0.010416768 - KL loss: 0.18434349\n",
            "Epoch: 29 - Step: 135 - MSE loss: 0.010969675 - KL loss: 0.19721483\n",
            "Epoch: 29 - Step: 136 - MSE loss: 0.011401884 - KL loss: 0.18988547\n",
            "Epoch: 29 - Step: 137 - MSE loss: 0.010088141 - KL loss: 0.19321018\n",
            "Epoch: 29 - Step: 138 - MSE loss: 0.01082134 - KL loss: 0.20017743\n",
            "Epoch: 29 - Step: 139 - MSE loss: 0.010436793 - KL loss: 0.1961694\n",
            "Epoch: 29 - Step: 140 - MSE loss: 0.010178898 - KL loss: 0.2003484\n",
            "Epoch: 29 - Step: 141 - MSE loss: 0.009556581 - KL loss: 0.18924083\n",
            "Epoch: 29 - Step: 142 - MSE loss: 0.0102063045 - KL loss: 0.19246045\n",
            "Epoch: 29 - Step: 143 - MSE loss: 0.010859272 - KL loss: 0.18657285\n",
            "Epoch: 29 - Step: 144 - MSE loss: 0.010176463 - KL loss: 0.19943348\n",
            "Epoch:  30\n",
            "Epoch: 30 - Step: 0 - MSE loss: 0.0051239 - KL loss: 0.13287736\n",
            "Epoch: 30 - Step: 1 - MSE loss: 0.005302844 - KL loss: 0.13287616\n",
            "Epoch: 30 - Step: 2 - MSE loss: 0.0047639315 - KL loss: 0.14035697\n",
            "Epoch: 30 - Step: 3 - MSE loss: 0.004737729 - KL loss: 0.13819769\n",
            "Epoch: 30 - Step: 4 - MSE loss: 0.0042068684 - KL loss: 0.12733978\n",
            "Epoch: 30 - Step: 5 - MSE loss: 0.005038965 - KL loss: 0.13340865\n",
            "Epoch: 30 - Step: 6 - MSE loss: 0.0056477175 - KL loss: 0.13266021\n",
            "Epoch: 30 - Step: 7 - MSE loss: 0.006070873 - KL loss: 0.13904281\n",
            "Epoch: 30 - Step: 8 - MSE loss: 0.0062498096 - KL loss: 0.13688992\n",
            "Epoch: 30 - Step: 9 - MSE loss: 0.0063341265 - KL loss: 0.13240328\n",
            "Epoch: 30 - Step: 10 - MSE loss: 0.0063872323 - KL loss: 0.13460311\n",
            "Epoch: 30 - Step: 11 - MSE loss: 0.006195147 - KL loss: 0.13227534\n",
            "Epoch: 30 - Step: 12 - MSE loss: 0.00593059 - KL loss: 0.13308677\n",
            "Epoch: 30 - Step: 13 - MSE loss: 0.00549491 - KL loss: 0.12936279\n",
            "Epoch: 30 - Step: 14 - MSE loss: 0.00574781 - KL loss: 0.13616203\n",
            "Epoch: 30 - Step: 15 - MSE loss: 0.005630631 - KL loss: 0.13780679\n",
            "Epoch: 30 - Step: 16 - MSE loss: 0.00555817 - KL loss: 0.13241151\n",
            "Epoch: 30 - Step: 17 - MSE loss: 0.005097911 - KL loss: 0.12577656\n",
            "Epoch: 30 - Step: 18 - MSE loss: 0.005739052 - KL loss: 0.13099423\n",
            "Epoch: 30 - Step: 19 - MSE loss: 0.004984469 - KL loss: 0.12183088\n",
            "Epoch: 30 - Step: 20 - MSE loss: 0.005319951 - KL loss: 0.12071967\n",
            "Epoch: 30 - Step: 21 - MSE loss: 0.0056629987 - KL loss: 0.11882778\n",
            "Epoch: 30 - Step: 22 - MSE loss: 0.005386164 - KL loss: 0.121472724\n",
            "Epoch: 30 - Step: 23 - MSE loss: 0.0056606582 - KL loss: 0.12513968\n",
            "Epoch: 30 - Step: 24 - MSE loss: 0.0055278144 - KL loss: 0.12301344\n",
            "Epoch: 30 - Step: 25 - MSE loss: 0.00484925 - KL loss: 0.12353177\n",
            "Epoch: 30 - Step: 26 - MSE loss: 0.005148916 - KL loss: 0.1157431\n",
            "Epoch: 30 - Step: 27 - MSE loss: 0.005252313 - KL loss: 0.12055899\n",
            "Epoch: 30 - Step: 28 - MSE loss: 0.0056708567 - KL loss: 0.115021095\n",
            "Epoch: 30 - Step: 29 - MSE loss: 0.0054045734 - KL loss: 0.119797856\n",
            "Epoch: 30 - Step: 30 - MSE loss: 0.0051744464 - KL loss: 0.117676355\n",
            "Epoch: 30 - Step: 31 - MSE loss: 0.0049917265 - KL loss: 0.117584154\n",
            "Epoch: 30 - Step: 32 - MSE loss: 0.005386202 - KL loss: 0.12484857\n",
            "Epoch: 30 - Step: 33 - MSE loss: 0.006121201 - KL loss: 0.13474044\n",
            "Epoch: 30 - Step: 34 - MSE loss: 0.006202284 - KL loss: 0.14162278\n",
            "Epoch: 30 - Step: 35 - MSE loss: 0.006086647 - KL loss: 0.1411547\n",
            "Epoch: 30 - Step: 36 - MSE loss: 0.0071361735 - KL loss: 0.15401794\n",
            "Epoch: 30 - Step: 37 - MSE loss: 0.007584385 - KL loss: 0.17028704\n",
            "Epoch: 30 - Step: 38 - MSE loss: 0.008468174 - KL loss: 0.17530423\n",
            "Epoch: 30 - Step: 39 - MSE loss: 0.008076468 - KL loss: 0.17220774\n",
            "Epoch: 30 - Step: 40 - MSE loss: 0.00943921 - KL loss: 0.1710108\n",
            "Epoch: 30 - Step: 41 - MSE loss: 0.008248643 - KL loss: 0.1689229\n",
            "Epoch: 30 - Step: 42 - MSE loss: 0.008036711 - KL loss: 0.1711599\n",
            "Epoch: 30 - Step: 43 - MSE loss: 0.007027617 - KL loss: 0.17095408\n",
            "Epoch: 30 - Step: 44 - MSE loss: 0.007840871 - KL loss: 0.17874092\n",
            "Epoch: 30 - Step: 45 - MSE loss: 0.009052221 - KL loss: 0.18146336\n",
            "Epoch: 30 - Step: 46 - MSE loss: 0.007938432 - KL loss: 0.18448445\n",
            "Epoch: 30 - Step: 47 - MSE loss: 0.008441514 - KL loss: 0.18020575\n",
            "Epoch: 30 - Step: 48 - MSE loss: 0.00797795 - KL loss: 0.19179979\n",
            "Epoch: 30 - Step: 49 - MSE loss: 0.008006428 - KL loss: 0.18884522\n",
            "Epoch: 30 - Step: 50 - MSE loss: 0.008936297 - KL loss: 0.1868949\n",
            "Epoch: 30 - Step: 51 - MSE loss: 0.0087303445 - KL loss: 0.1827138\n",
            "Epoch: 30 - Step: 52 - MSE loss: 0.00982333 - KL loss: 0.19512095\n",
            "Epoch: 30 - Step: 53 - MSE loss: 0.009199114 - KL loss: 0.18950167\n",
            "Epoch: 30 - Step: 54 - MSE loss: 0.009972553 - KL loss: 0.1861702\n",
            "Epoch: 30 - Step: 55 - MSE loss: 0.010401254 - KL loss: 0.1910868\n",
            "Epoch: 30 - Step: 56 - MSE loss: 0.011302142 - KL loss: 0.18453622\n",
            "Epoch: 30 - Step: 57 - MSE loss: 0.009987706 - KL loss: 0.1917933\n",
            "Epoch: 30 - Step: 58 - MSE loss: 0.0096529415 - KL loss: 0.18756369\n",
            "Epoch: 30 - Step: 59 - MSE loss: 0.009687805 - KL loss: 0.1881604\n",
            "Epoch: 30 - Step: 60 - MSE loss: 0.009903769 - KL loss: 0.19894652\n",
            "Epoch: 30 - Step: 61 - MSE loss: 0.010185923 - KL loss: 0.19144887\n",
            "Epoch: 30 - Step: 62 - MSE loss: 0.009422018 - KL loss: 0.20547906\n",
            "Epoch: 30 - Step: 63 - MSE loss: 0.009820481 - KL loss: 0.19708213\n",
            "Epoch: 30 - Step: 64 - MSE loss: 0.010324506 - KL loss: 0.21056864\n",
            "Epoch: 30 - Step: 65 - MSE loss: 0.010331205 - KL loss: 0.19313073\n",
            "Epoch: 30 - Step: 66 - MSE loss: 0.01065781 - KL loss: 0.18786365\n",
            "Epoch: 30 - Step: 67 - MSE loss: 0.009695777 - KL loss: 0.16927023\n",
            "Epoch: 30 - Step: 68 - MSE loss: 0.0085814865 - KL loss: 0.17592335\n",
            "Epoch: 30 - Step: 69 - MSE loss: 0.00807558 - KL loss: 0.17587006\n",
            "Epoch: 30 - Step: 70 - MSE loss: 0.0072751716 - KL loss: 0.15713102\n",
            "Epoch: 30 - Step: 71 - MSE loss: 0.006285189 - KL loss: 0.14023978\n",
            "Epoch: 30 - Step: 72 - MSE loss: 0.0063132183 - KL loss: 0.14875954\n",
            "Epoch: 30 - Step: 73 - MSE loss: 0.0059234365 - KL loss: 0.14410248\n",
            "Epoch: 30 - Step: 74 - MSE loss: 0.005967349 - KL loss: 0.13554746\n",
            "Epoch: 30 - Step: 75 - MSE loss: 0.0058170264 - KL loss: 0.13210824\n",
            "Epoch: 30 - Step: 76 - MSE loss: 0.0050548734 - KL loss: 0.11982478\n",
            "Epoch: 30 - Step: 77 - MSE loss: 0.005436757 - KL loss: 0.11636255\n",
            "Epoch: 30 - Step: 78 - MSE loss: 0.005417736 - KL loss: 0.118572526\n",
            "Epoch: 30 - Step: 79 - MSE loss: 0.005333125 - KL loss: 0.12264065\n",
            "Epoch: 30 - Step: 80 - MSE loss: 0.005642164 - KL loss: 0.12099862\n",
            "Epoch: 30 - Step: 81 - MSE loss: 0.005986817 - KL loss: 0.13470885\n",
            "Epoch: 30 - Step: 82 - MSE loss: 0.0061159735 - KL loss: 0.13649058\n",
            "Epoch: 30 - Step: 83 - MSE loss: 0.005890917 - KL loss: 0.13183457\n",
            "Epoch: 30 - Step: 84 - MSE loss: 0.005911358 - KL loss: 0.13858134\n",
            "Epoch: 30 - Step: 85 - MSE loss: 0.005124138 - KL loss: 0.12787275\n",
            "Epoch: 30 - Step: 86 - MSE loss: 0.005902151 - KL loss: 0.13557754\n",
            "Epoch: 30 - Step: 87 - MSE loss: 0.0056836843 - KL loss: 0.13141523\n",
            "Epoch: 30 - Step: 88 - MSE loss: 0.0058597573 - KL loss: 0.1344566\n",
            "Epoch: 30 - Step: 89 - MSE loss: 0.0054615824 - KL loss: 0.13757084\n",
            "Epoch: 30 - Step: 90 - MSE loss: 0.0059857885 - KL loss: 0.13288575\n",
            "Epoch: 30 - Step: 91 - MSE loss: 0.0054749656 - KL loss: 0.13588655\n",
            "Epoch: 30 - Step: 92 - MSE loss: 0.0057698595 - KL loss: 0.14097545\n",
            "Epoch: 30 - Step: 93 - MSE loss: 0.0056404523 - KL loss: 0.13311322\n",
            "Epoch: 30 - Step: 94 - MSE loss: 0.0055917725 - KL loss: 0.13457307\n",
            "Epoch: 30 - Step: 95 - MSE loss: 0.005644833 - KL loss: 0.12877488\n",
            "Epoch: 30 - Step: 96 - MSE loss: 0.0056021824 - KL loss: 0.13587694\n",
            "Epoch: 30 - Step: 97 - MSE loss: 0.005799633 - KL loss: 0.13354094\n",
            "Epoch: 30 - Step: 98 - MSE loss: 0.0054141064 - KL loss: 0.13437629\n",
            "Epoch: 30 - Step: 99 - MSE loss: 0.00521816 - KL loss: 0.128515\n",
            "Epoch: 30 - Step: 100 - MSE loss: 0.005584002 - KL loss: 0.13766593\n",
            "Epoch: 30 - Step: 101 - MSE loss: 0.005266394 - KL loss: 0.13523936\n",
            "Epoch: 30 - Step: 102 - MSE loss: 0.0054863305 - KL loss: 0.13617644\n",
            "Epoch: 30 - Step: 103 - MSE loss: 0.004333208 - KL loss: 0.1279657\n",
            "Epoch: 30 - Step: 104 - MSE loss: 0.0053343712 - KL loss: 0.137587\n",
            "Epoch: 30 - Step: 105 - MSE loss: 0.005776296 - KL loss: 0.13953876\n",
            "Epoch: 30 - Step: 106 - MSE loss: 0.00637071 - KL loss: 0.15034673\n",
            "Epoch: 30 - Step: 107 - MSE loss: 0.0071096322 - KL loss: 0.15724468\n",
            "Epoch: 30 - Step: 108 - MSE loss: 0.0071224957 - KL loss: 0.17250563\n",
            "Epoch: 30 - Step: 109 - MSE loss: 0.007031617 - KL loss: 0.17241473\n",
            "Epoch: 30 - Step: 110 - MSE loss: 0.007841068 - KL loss: 0.1792998\n",
            "Epoch: 30 - Step: 111 - MSE loss: 0.008712284 - KL loss: 0.18381304\n",
            "Epoch: 30 - Step: 112 - MSE loss: 0.0086421305 - KL loss: 0.17567462\n",
            "Epoch: 30 - Step: 113 - MSE loss: 0.007962959 - KL loss: 0.18186599\n",
            "Epoch: 30 - Step: 114 - MSE loss: 0.0095539475 - KL loss: 0.20037642\n",
            "Epoch: 30 - Step: 115 - MSE loss: 0.008708895 - KL loss: 0.18263134\n",
            "Epoch: 30 - Step: 116 - MSE loss: 0.009528444 - KL loss: 0.19183166\n",
            "Epoch: 30 - Step: 117 - MSE loss: 0.008430787 - KL loss: 0.18613218\n",
            "Epoch: 30 - Step: 118 - MSE loss: 0.009762152 - KL loss: 0.19182676\n",
            "Epoch: 30 - Step: 119 - MSE loss: 0.009200288 - KL loss: 0.18621531\n",
            "Epoch: 30 - Step: 120 - MSE loss: 0.008571359 - KL loss: 0.19110289\n",
            "Epoch: 30 - Step: 121 - MSE loss: 0.008542103 - KL loss: 0.19484144\n",
            "Epoch: 30 - Step: 122 - MSE loss: 0.008048675 - KL loss: 0.18219712\n",
            "Epoch: 30 - Step: 123 - MSE loss: 0.008094119 - KL loss: 0.18559049\n",
            "Epoch: 30 - Step: 124 - MSE loss: 0.008504435 - KL loss: 0.18542331\n",
            "Epoch: 30 - Step: 125 - MSE loss: 0.00796226 - KL loss: 0.18560612\n",
            "Epoch: 30 - Step: 126 - MSE loss: 0.009021754 - KL loss: 0.18985908\n",
            "Epoch: 30 - Step: 127 - MSE loss: 0.008053821 - KL loss: 0.18834163\n",
            "Epoch: 30 - Step: 128 - MSE loss: 0.008375319 - KL loss: 0.18222797\n",
            "Epoch: 30 - Step: 129 - MSE loss: 0.008660703 - KL loss: 0.18816417\n",
            "Epoch: 30 - Step: 130 - MSE loss: 0.008485837 - KL loss: 0.19088224\n",
            "Epoch: 30 - Step: 131 - MSE loss: 0.008888605 - KL loss: 0.20397176\n",
            "Epoch: 30 - Step: 132 - MSE loss: 0.009824614 - KL loss: 0.19335066\n",
            "Epoch: 30 - Step: 133 - MSE loss: 0.010241958 - KL loss: 0.20708595\n",
            "Epoch: 30 - Step: 134 - MSE loss: 0.011628494 - KL loss: 0.18761891\n",
            "Epoch: 30 - Step: 135 - MSE loss: 0.012391854 - KL loss: 0.19246152\n",
            "Epoch: 30 - Step: 136 - MSE loss: 0.01297801 - KL loss: 0.17801446\n",
            "Epoch: 30 - Step: 137 - MSE loss: 0.011361613 - KL loss: 0.19104654\n",
            "Epoch: 30 - Step: 138 - MSE loss: 0.010975844 - KL loss: 0.18589357\n",
            "Epoch: 30 - Step: 139 - MSE loss: 0.011255201 - KL loss: 0.18902953\n",
            "Epoch: 30 - Step: 140 - MSE loss: 0.010625828 - KL loss: 0.19021654\n",
            "Epoch: 30 - Step: 141 - MSE loss: 0.010120835 - KL loss: 0.18757549\n",
            "Epoch: 30 - Step: 142 - MSE loss: 0.0097110905 - KL loss: 0.18490264\n",
            "Epoch: 30 - Step: 143 - MSE loss: 0.009684179 - KL loss: 0.19417912\n",
            "Epoch: 30 - Step: 144 - MSE loss: 0.009954315 - KL loss: 0.18373887\n",
            "Epoch:  31\n",
            "Epoch: 31 - Step: 0 - MSE loss: 0.0047481726 - KL loss: 0.13242276\n",
            "Epoch: 31 - Step: 1 - MSE loss: 0.0048638494 - KL loss: 0.13300577\n",
            "Epoch: 31 - Step: 2 - MSE loss: 0.0046325955 - KL loss: 0.13874939\n",
            "Epoch: 31 - Step: 3 - MSE loss: 0.004709507 - KL loss: 0.13062227\n",
            "Epoch: 31 - Step: 4 - MSE loss: 0.004846658 - KL loss: 0.13174826\n",
            "Epoch: 31 - Step: 5 - MSE loss: 0.0048202295 - KL loss: 0.13667274\n",
            "Epoch: 31 - Step: 6 - MSE loss: 0.004740944 - KL loss: 0.13775615\n",
            "Epoch: 31 - Step: 7 - MSE loss: 0.005376521 - KL loss: 0.13847321\n",
            "Epoch: 31 - Step: 8 - MSE loss: 0.005556099 - KL loss: 0.13762419\n",
            "Epoch: 31 - Step: 9 - MSE loss: 0.0051909625 - KL loss: 0.13204628\n",
            "Epoch: 31 - Step: 10 - MSE loss: 0.005704515 - KL loss: 0.12966716\n",
            "Epoch: 31 - Step: 11 - MSE loss: 0.0056698904 - KL loss: 0.13024032\n",
            "Epoch: 31 - Step: 12 - MSE loss: 0.0053196326 - KL loss: 0.1335788\n",
            "Epoch: 31 - Step: 13 - MSE loss: 0.0053085475 - KL loss: 0.13063997\n",
            "Epoch: 31 - Step: 14 - MSE loss: 0.0054504615 - KL loss: 0.13310832\n",
            "Epoch: 31 - Step: 15 - MSE loss: 0.005328951 - KL loss: 0.13473949\n",
            "Epoch: 31 - Step: 16 - MSE loss: 0.004937696 - KL loss: 0.13538837\n",
            "Epoch: 31 - Step: 17 - MSE loss: 0.005685653 - KL loss: 0.13190874\n",
            "Epoch: 31 - Step: 18 - MSE loss: 0.005416906 - KL loss: 0.13193578\n",
            "Epoch: 31 - Step: 19 - MSE loss: 0.0048738304 - KL loss: 0.12677042\n",
            "Epoch: 31 - Step: 20 - MSE loss: 0.00520462 - KL loss: 0.1250872\n",
            "Epoch: 31 - Step: 21 - MSE loss: 0.0054138093 - KL loss: 0.11993265\n",
            "Epoch: 31 - Step: 22 - MSE loss: 0.005857459 - KL loss: 0.120822385\n",
            "Epoch: 31 - Step: 23 - MSE loss: 0.0062504574 - KL loss: 0.12174791\n",
            "Epoch: 31 - Step: 24 - MSE loss: 0.00562687 - KL loss: 0.11627138\n",
            "Epoch: 31 - Step: 25 - MSE loss: 0.0057273493 - KL loss: 0.11584428\n",
            "Epoch: 31 - Step: 26 - MSE loss: 0.00562921 - KL loss: 0.117910795\n",
            "Epoch: 31 - Step: 27 - MSE loss: 0.0049523725 - KL loss: 0.117683575\n",
            "Epoch: 31 - Step: 28 - MSE loss: 0.005417406 - KL loss: 0.1201089\n",
            "Epoch: 31 - Step: 29 - MSE loss: 0.0050623897 - KL loss: 0.118484855\n",
            "Epoch: 31 - Step: 30 - MSE loss: 0.0048441873 - KL loss: 0.11942984\n",
            "Epoch: 31 - Step: 31 - MSE loss: 0.004624642 - KL loss: 0.116998166\n",
            "Epoch: 31 - Step: 32 - MSE loss: 0.0058727358 - KL loss: 0.13132694\n",
            "Epoch: 31 - Step: 33 - MSE loss: 0.0063832756 - KL loss: 0.13625729\n",
            "Epoch: 31 - Step: 34 - MSE loss: 0.0061551495 - KL loss: 0.13823557\n",
            "Epoch: 31 - Step: 35 - MSE loss: 0.0064436593 - KL loss: 0.14434354\n",
            "Epoch: 31 - Step: 36 - MSE loss: 0.007321116 - KL loss: 0.15533623\n",
            "Epoch: 31 - Step: 37 - MSE loss: 0.0063211024 - KL loss: 0.1510059\n",
            "Epoch: 31 - Step: 38 - MSE loss: 0.007946868 - KL loss: 0.17271495\n",
            "Epoch: 31 - Step: 39 - MSE loss: 0.008426014 - KL loss: 0.17091426\n",
            "Epoch: 31 - Step: 40 - MSE loss: 0.0082410555 - KL loss: 0.17593017\n",
            "Epoch: 31 - Step: 41 - MSE loss: 0.008417968 - KL loss: 0.1785296\n",
            "Epoch: 31 - Step: 42 - MSE loss: 0.007701809 - KL loss: 0.16507673\n",
            "Epoch: 31 - Step: 43 - MSE loss: 0.006972684 - KL loss: 0.16078112\n",
            "Epoch: 31 - Step: 44 - MSE loss: 0.008091186 - KL loss: 0.17493129\n",
            "Epoch: 31 - Step: 45 - MSE loss: 0.0075040865 - KL loss: 0.17942593\n",
            "Epoch: 31 - Step: 46 - MSE loss: 0.00796588 - KL loss: 0.17441855\n",
            "Epoch: 31 - Step: 47 - MSE loss: 0.007843873 - KL loss: 0.18462776\n",
            "Epoch: 31 - Step: 48 - MSE loss: 0.008218962 - KL loss: 0.19020066\n",
            "Epoch: 31 - Step: 49 - MSE loss: 0.008603239 - KL loss: 0.18275768\n",
            "Epoch: 31 - Step: 50 - MSE loss: 0.008747148 - KL loss: 0.19041637\n",
            "Epoch: 31 - Step: 51 - MSE loss: 0.008149081 - KL loss: 0.18423083\n",
            "Epoch: 31 - Step: 52 - MSE loss: 0.0084830485 - KL loss: 0.18657173\n",
            "Epoch: 31 - Step: 53 - MSE loss: 0.0097481655 - KL loss: 0.19285277\n",
            "Epoch: 31 - Step: 54 - MSE loss: 0.008869547 - KL loss: 0.19156468\n",
            "Epoch: 31 - Step: 55 - MSE loss: 0.009084112 - KL loss: 0.18571827\n",
            "Epoch: 31 - Step: 56 - MSE loss: 0.009213212 - KL loss: 0.19489747\n",
            "Epoch: 31 - Step: 57 - MSE loss: 0.009667969 - KL loss: 0.1879842\n",
            "Epoch: 31 - Step: 58 - MSE loss: 0.008996714 - KL loss: 0.19645497\n",
            "Epoch: 31 - Step: 59 - MSE loss: 0.009793936 - KL loss: 0.18561164\n",
            "Epoch: 31 - Step: 60 - MSE loss: 0.010326579 - KL loss: 0.19537263\n",
            "Epoch: 31 - Step: 61 - MSE loss: 0.009994494 - KL loss: 0.19522773\n",
            "Epoch: 31 - Step: 62 - MSE loss: 0.009503223 - KL loss: 0.20273805\n",
            "Epoch: 31 - Step: 63 - MSE loss: 0.010365475 - KL loss: 0.1976949\n",
            "Epoch: 31 - Step: 64 - MSE loss: 0.009835353 - KL loss: 0.20381439\n",
            "Epoch: 31 - Step: 65 - MSE loss: 0.011048359 - KL loss: 0.18661164\n",
            "Epoch: 31 - Step: 66 - MSE loss: 0.009000833 - KL loss: 0.18378404\n",
            "Epoch: 31 - Step: 67 - MSE loss: 0.007706041 - KL loss: 0.1656452\n",
            "Epoch: 31 - Step: 68 - MSE loss: 0.007830671 - KL loss: 0.16887952\n",
            "Epoch: 31 - Step: 69 - MSE loss: 0.008307618 - KL loss: 0.17175892\n",
            "Epoch: 31 - Step: 70 - MSE loss: 0.00717192 - KL loss: 0.16457793\n",
            "Epoch: 31 - Step: 71 - MSE loss: 0.0064129364 - KL loss: 0.14586745\n",
            "Epoch: 31 - Step: 72 - MSE loss: 0.005902371 - KL loss: 0.14303872\n",
            "Epoch: 31 - Step: 73 - MSE loss: 0.0052010114 - KL loss: 0.13843432\n",
            "Epoch: 31 - Step: 74 - MSE loss: 0.0060944525 - KL loss: 0.13138956\n",
            "Epoch: 31 - Step: 75 - MSE loss: 0.005604494 - KL loss: 0.13257203\n",
            "Epoch: 31 - Step: 76 - MSE loss: 0.0057743066 - KL loss: 0.12798172\n",
            "Epoch: 31 - Step: 77 - MSE loss: 0.005446942 - KL loss: 0.12136063\n",
            "Epoch: 31 - Step: 78 - MSE loss: 0.005677301 - KL loss: 0.120921895\n",
            "Epoch: 31 - Step: 79 - MSE loss: 0.0057027675 - KL loss: 0.12301725\n",
            "Epoch: 31 - Step: 80 - MSE loss: 0.0056150225 - KL loss: 0.12545393\n",
            "Epoch: 31 - Step: 81 - MSE loss: 0.005851457 - KL loss: 0.13060118\n",
            "Epoch: 31 - Step: 82 - MSE loss: 0.006145193 - KL loss: 0.12973197\n",
            "Epoch: 31 - Step: 83 - MSE loss: 0.0058588837 - KL loss: 0.13268587\n",
            "Epoch: 31 - Step: 84 - MSE loss: 0.0061150375 - KL loss: 0.12308799\n",
            "Epoch: 31 - Step: 85 - MSE loss: 0.0059296302 - KL loss: 0.12621617\n",
            "Epoch: 31 - Step: 86 - MSE loss: 0.0059113298 - KL loss: 0.1364033\n",
            "Epoch: 31 - Step: 87 - MSE loss: 0.005807057 - KL loss: 0.1359774\n",
            "Epoch: 31 - Step: 88 - MSE loss: 0.0053533297 - KL loss: 0.1345538\n",
            "Epoch: 31 - Step: 89 - MSE loss: 0.0051715276 - KL loss: 0.13748324\n",
            "Epoch: 31 - Step: 90 - MSE loss: 0.0053466535 - KL loss: 0.13261938\n",
            "Epoch: 31 - Step: 91 - MSE loss: 0.005198321 - KL loss: 0.13581708\n",
            "Epoch: 31 - Step: 92 - MSE loss: 0.0052299746 - KL loss: 0.13307112\n",
            "Epoch: 31 - Step: 93 - MSE loss: 0.0052122604 - KL loss: 0.13417983\n",
            "Epoch: 31 - Step: 94 - MSE loss: 0.0053034932 - KL loss: 0.12830698\n",
            "Epoch: 31 - Step: 95 - MSE loss: 0.005719351 - KL loss: 0.13613081\n",
            "Epoch: 31 - Step: 96 - MSE loss: 0.0053314515 - KL loss: 0.13760555\n",
            "Epoch: 31 - Step: 97 - MSE loss: 0.0055869767 - KL loss: 0.1365982\n",
            "Epoch: 31 - Step: 98 - MSE loss: 0.0056872107 - KL loss: 0.13223279\n",
            "Epoch: 31 - Step: 99 - MSE loss: 0.005197875 - KL loss: 0.13806033\n",
            "Epoch: 31 - Step: 100 - MSE loss: 0.005419651 - KL loss: 0.13860267\n",
            "Epoch: 31 - Step: 101 - MSE loss: 0.0053293933 - KL loss: 0.13067868\n",
            "Epoch: 31 - Step: 102 - MSE loss: 0.005181841 - KL loss: 0.1343086\n",
            "Epoch: 31 - Step: 103 - MSE loss: 0.004983545 - KL loss: 0.13303506\n",
            "Epoch: 31 - Step: 104 - MSE loss: 0.0053132605 - KL loss: 0.13012025\n",
            "Epoch: 31 - Step: 105 - MSE loss: 0.005815793 - KL loss: 0.14243805\n",
            "Epoch: 31 - Step: 106 - MSE loss: 0.0061702286 - KL loss: 0.147954\n",
            "Epoch: 31 - Step: 107 - MSE loss: 0.0074011423 - KL loss: 0.16426\n",
            "Epoch: 31 - Step: 108 - MSE loss: 0.0070438697 - KL loss: 0.16610259\n",
            "Epoch: 31 - Step: 109 - MSE loss: 0.007470641 - KL loss: 0.1716135\n",
            "Epoch: 31 - Step: 110 - MSE loss: 0.0068621575 - KL loss: 0.17051993\n",
            "Epoch: 31 - Step: 111 - MSE loss: 0.007813388 - KL loss: 0.17645031\n",
            "Epoch: 31 - Step: 112 - MSE loss: 0.008522521 - KL loss: 0.18327446\n",
            "Epoch: 31 - Step: 113 - MSE loss: 0.008136215 - KL loss: 0.17390099\n",
            "Epoch: 31 - Step: 114 - MSE loss: 0.009276542 - KL loss: 0.19413638\n",
            "Epoch: 31 - Step: 115 - MSE loss: 0.008441887 - KL loss: 0.17678417\n",
            "Epoch: 31 - Step: 116 - MSE loss: 0.008665013 - KL loss: 0.18520889\n",
            "Epoch: 31 - Step: 117 - MSE loss: 0.00967826 - KL loss: 0.19112462\n",
            "Epoch: 31 - Step: 118 - MSE loss: 0.00861125 - KL loss: 0.18058312\n",
            "Epoch: 31 - Step: 119 - MSE loss: 0.008828207 - KL loss: 0.18048692\n",
            "Epoch: 31 - Step: 120 - MSE loss: 0.007987103 - KL loss: 0.18411824\n",
            "Epoch: 31 - Step: 121 - MSE loss: 0.008010316 - KL loss: 0.18470132\n",
            "Epoch: 31 - Step: 122 - MSE loss: 0.0081626335 - KL loss: 0.18657312\n",
            "Epoch: 31 - Step: 123 - MSE loss: 0.008307028 - KL loss: 0.17187184\n",
            "Epoch: 31 - Step: 124 - MSE loss: 0.009256047 - KL loss: 0.19143073\n",
            "Epoch: 31 - Step: 125 - MSE loss: 0.008641887 - KL loss: 0.1846276\n",
            "Epoch: 31 - Step: 126 - MSE loss: 0.008492143 - KL loss: 0.19169833\n",
            "Epoch: 31 - Step: 127 - MSE loss: 0.008883313 - KL loss: 0.1904153\n",
            "Epoch: 31 - Step: 128 - MSE loss: 0.008801678 - KL loss: 0.18673888\n",
            "Epoch: 31 - Step: 129 - MSE loss: 0.008300071 - KL loss: 0.18343642\n",
            "Epoch: 31 - Step: 130 - MSE loss: 0.007992934 - KL loss: 0.1988166\n",
            "Epoch: 31 - Step: 131 - MSE loss: 0.0088764755 - KL loss: 0.19150516\n",
            "Epoch: 31 - Step: 132 - MSE loss: 0.009266111 - KL loss: 0.19554162\n",
            "Epoch: 31 - Step: 133 - MSE loss: 0.009748481 - KL loss: 0.1915243\n",
            "Epoch: 31 - Step: 134 - MSE loss: 0.010927573 - KL loss: 0.19591577\n",
            "Epoch: 31 - Step: 135 - MSE loss: 0.011891328 - KL loss: 0.1795631\n",
            "Epoch: 31 - Step: 136 - MSE loss: 0.012440492 - KL loss: 0.20513414\n",
            "Epoch: 31 - Step: 137 - MSE loss: 0.011179886 - KL loss: 0.1774098\n",
            "Epoch: 31 - Step: 138 - MSE loss: 0.011569115 - KL loss: 0.18823686\n",
            "Epoch: 31 - Step: 139 - MSE loss: 0.0112816235 - KL loss: 0.17947084\n",
            "Epoch: 31 - Step: 140 - MSE loss: 0.01024685 - KL loss: 0.19395328\n",
            "Epoch: 31 - Step: 141 - MSE loss: 0.00954271 - KL loss: 0.18610936\n",
            "Epoch: 31 - Step: 142 - MSE loss: 0.010384921 - KL loss: 0.18755333\n",
            "Epoch: 31 - Step: 143 - MSE loss: 0.009370056 - KL loss: 0.18978408\n",
            "Epoch: 31 - Step: 144 - MSE loss: 0.010062814 - KL loss: 0.19713588\n",
            "Epoch:  32\n",
            "Epoch: 32 - Step: 0 - MSE loss: 0.0044718715 - KL loss: 0.13149932\n",
            "Epoch: 32 - Step: 1 - MSE loss: 0.0047229785 - KL loss: 0.13778901\n",
            "Epoch: 32 - Step: 2 - MSE loss: 0.004930623 - KL loss: 0.13574144\n",
            "Epoch: 32 - Step: 3 - MSE loss: 0.0043609114 - KL loss: 0.13113868\n",
            "Epoch: 32 - Step: 4 - MSE loss: 0.0044788937 - KL loss: 0.12794375\n",
            "Epoch: 32 - Step: 5 - MSE loss: 0.005099365 - KL loss: 0.13165505\n",
            "Epoch: 32 - Step: 6 - MSE loss: 0.0049359943 - KL loss: 0.1336486\n",
            "Epoch: 32 - Step: 7 - MSE loss: 0.005221896 - KL loss: 0.1282173\n",
            "Epoch: 32 - Step: 8 - MSE loss: 0.0050331317 - KL loss: 0.13455173\n",
            "Epoch: 32 - Step: 9 - MSE loss: 0.0056348094 - KL loss: 0.1304975\n",
            "Epoch: 32 - Step: 10 - MSE loss: 0.005169406 - KL loss: 0.1306442\n",
            "Epoch: 32 - Step: 11 - MSE loss: 0.0056438353 - KL loss: 0.13668448\n",
            "Epoch: 32 - Step: 12 - MSE loss: 0.0050891666 - KL loss: 0.13216907\n",
            "Epoch: 32 - Step: 13 - MSE loss: 0.0057728924 - KL loss: 0.13203293\n",
            "Epoch: 32 - Step: 14 - MSE loss: 0.005760813 - KL loss: 0.13895044\n",
            "Epoch: 32 - Step: 15 - MSE loss: 0.005212574 - KL loss: 0.13376406\n",
            "Epoch: 32 - Step: 16 - MSE loss: 0.0054804552 - KL loss: 0.12674394\n",
            "Epoch: 32 - Step: 17 - MSE loss: 0.005520697 - KL loss: 0.13235971\n",
            "Epoch: 32 - Step: 18 - MSE loss: 0.0050455113 - KL loss: 0.12036435\n",
            "Epoch: 32 - Step: 19 - MSE loss: 0.00504347 - KL loss: 0.12721871\n",
            "Epoch: 32 - Step: 20 - MSE loss: 0.0049341437 - KL loss: 0.11566119\n",
            "Epoch: 32 - Step: 21 - MSE loss: 0.0045979884 - KL loss: 0.11802861\n",
            "Epoch: 32 - Step: 22 - MSE loss: 0.005123259 - KL loss: 0.11800481\n",
            "Epoch: 32 - Step: 23 - MSE loss: 0.0053147674 - KL loss: 0.11948672\n",
            "Epoch: 32 - Step: 24 - MSE loss: 0.005156502 - KL loss: 0.122290984\n",
            "Epoch: 32 - Step: 25 - MSE loss: 0.004992215 - KL loss: 0.11693013\n",
            "Epoch: 32 - Step: 26 - MSE loss: 0.0050227414 - KL loss: 0.11313261\n",
            "Epoch: 32 - Step: 27 - MSE loss: 0.0050519863 - KL loss: 0.1189531\n",
            "Epoch: 32 - Step: 28 - MSE loss: 0.005125974 - KL loss: 0.11930291\n",
            "Epoch: 32 - Step: 29 - MSE loss: 0.004788553 - KL loss: 0.11154708\n",
            "Epoch: 32 - Step: 30 - MSE loss: 0.0046579544 - KL loss: 0.11092006\n",
            "Epoch: 32 - Step: 31 - MSE loss: 0.004724774 - KL loss: 0.11061559\n",
            "Epoch: 32 - Step: 32 - MSE loss: 0.0055550616 - KL loss: 0.121773675\n",
            "Epoch: 32 - Step: 33 - MSE loss: 0.0063194707 - KL loss: 0.13562533\n",
            "Epoch: 32 - Step: 34 - MSE loss: 0.0056291856 - KL loss: 0.13531047\n",
            "Epoch: 32 - Step: 35 - MSE loss: 0.0070499894 - KL loss: 0.15228409\n",
            "Epoch: 32 - Step: 36 - MSE loss: 0.0067008287 - KL loss: 0.15189475\n",
            "Epoch: 32 - Step: 37 - MSE loss: 0.0070045646 - KL loss: 0.15819837\n",
            "Epoch: 32 - Step: 38 - MSE loss: 0.007401869 - KL loss: 0.16143659\n",
            "Epoch: 32 - Step: 39 - MSE loss: 0.007269256 - KL loss: 0.16629031\n",
            "Epoch: 32 - Step: 40 - MSE loss: 0.008570018 - KL loss: 0.17605704\n",
            "Epoch: 32 - Step: 41 - MSE loss: 0.008571904 - KL loss: 0.17480859\n",
            "Epoch: 32 - Step: 42 - MSE loss: 0.007784989 - KL loss: 0.1646707\n",
            "Epoch: 32 - Step: 43 - MSE loss: 0.0073033436 - KL loss: 0.1757702\n",
            "Epoch: 32 - Step: 44 - MSE loss: 0.007866818 - KL loss: 0.1717133\n",
            "Epoch: 32 - Step: 45 - MSE loss: 0.0074539003 - KL loss: 0.17588471\n",
            "Epoch: 32 - Step: 46 - MSE loss: 0.0076324497 - KL loss: 0.17710514\n",
            "Epoch: 32 - Step: 47 - MSE loss: 0.008061371 - KL loss: 0.1899487\n",
            "Epoch: 32 - Step: 48 - MSE loss: 0.0082680965 - KL loss: 0.18281595\n",
            "Epoch: 32 - Step: 49 - MSE loss: 0.007655032 - KL loss: 0.18240789\n",
            "Epoch: 32 - Step: 50 - MSE loss: 0.0077485754 - KL loss: 0.17631672\n",
            "Epoch: 32 - Step: 51 - MSE loss: 0.008471435 - KL loss: 0.18645404\n",
            "Epoch: 32 - Step: 52 - MSE loss: 0.008910819 - KL loss: 0.19102739\n",
            "Epoch: 32 - Step: 53 - MSE loss: 0.009082658 - KL loss: 0.18286309\n",
            "Epoch: 32 - Step: 54 - MSE loss: 0.009088472 - KL loss: 0.18989849\n",
            "Epoch: 32 - Step: 55 - MSE loss: 0.009367161 - KL loss: 0.18340206\n",
            "Epoch: 32 - Step: 56 - MSE loss: 0.008330273 - KL loss: 0.18228549\n",
            "Epoch: 32 - Step: 57 - MSE loss: 0.008703413 - KL loss: 0.18029365\n",
            "Epoch: 32 - Step: 58 - MSE loss: 0.008918439 - KL loss: 0.1907452\n",
            "Epoch: 32 - Step: 59 - MSE loss: 0.009276466 - KL loss: 0.19193392\n",
            "Epoch: 32 - Step: 60 - MSE loss: 0.009751919 - KL loss: 0.19448745\n",
            "Epoch: 32 - Step: 61 - MSE loss: 0.008546816 - KL loss: 0.18534511\n",
            "Epoch: 32 - Step: 62 - MSE loss: 0.009180406 - KL loss: 0.19956313\n",
            "Epoch: 32 - Step: 63 - MSE loss: 0.009353082 - KL loss: 0.18924293\n",
            "Epoch: 32 - Step: 64 - MSE loss: 0.009407933 - KL loss: 0.20214915\n",
            "Epoch: 32 - Step: 65 - MSE loss: 0.010018581 - KL loss: 0.18853381\n",
            "Epoch: 32 - Step: 66 - MSE loss: 0.008543056 - KL loss: 0.16894221\n",
            "Epoch: 32 - Step: 67 - MSE loss: 0.008529669 - KL loss: 0.16645367\n",
            "Epoch: 32 - Step: 68 - MSE loss: 0.008710245 - KL loss: 0.1697388\n",
            "Epoch: 32 - Step: 69 - MSE loss: 0.008677282 - KL loss: 0.15589797\n",
            "Epoch: 32 - Step: 70 - MSE loss: 0.0076999585 - KL loss: 0.15723577\n",
            "Epoch: 32 - Step: 71 - MSE loss: 0.005950386 - KL loss: 0.14571936\n",
            "Epoch: 32 - Step: 72 - MSE loss: 0.0066210083 - KL loss: 0.13898349\n",
            "Epoch: 32 - Step: 73 - MSE loss: 0.0061532953 - KL loss: 0.1450919\n",
            "Epoch: 32 - Step: 74 - MSE loss: 0.0059763496 - KL loss: 0.14147834\n",
            "Epoch: 32 - Step: 75 - MSE loss: 0.005235214 - KL loss: 0.12801689\n",
            "Epoch: 32 - Step: 76 - MSE loss: 0.005289707 - KL loss: 0.12524995\n",
            "Epoch: 32 - Step: 77 - MSE loss: 0.005691426 - KL loss: 0.124835186\n",
            "Epoch: 32 - Step: 78 - MSE loss: 0.0054475586 - KL loss: 0.12915754\n",
            "Epoch: 32 - Step: 79 - MSE loss: 0.005490042 - KL loss: 0.12635182\n",
            "Epoch: 32 - Step: 80 - MSE loss: 0.005378746 - KL loss: 0.12386884\n",
            "Epoch: 32 - Step: 81 - MSE loss: 0.0052594785 - KL loss: 0.124965586\n",
            "Epoch: 32 - Step: 82 - MSE loss: 0.005382692 - KL loss: 0.123844706\n",
            "Epoch: 32 - Step: 83 - MSE loss: 0.005768984 - KL loss: 0.1309583\n",
            "Epoch: 32 - Step: 84 - MSE loss: 0.005689414 - KL loss: 0.12744668\n",
            "Epoch: 32 - Step: 85 - MSE loss: 0.0050165765 - KL loss: 0.1206687\n",
            "Epoch: 32 - Step: 86 - MSE loss: 0.0054773185 - KL loss: 0.12513098\n",
            "Epoch: 32 - Step: 87 - MSE loss: 0.0056869388 - KL loss: 0.12969047\n",
            "Epoch: 32 - Step: 88 - MSE loss: 0.0054225563 - KL loss: 0.13076895\n",
            "Epoch: 32 - Step: 89 - MSE loss: 0.00553925 - KL loss: 0.13900387\n",
            "Epoch: 32 - Step: 90 - MSE loss: 0.005439583 - KL loss: 0.13686858\n",
            "Epoch: 32 - Step: 91 - MSE loss: 0.0052549425 - KL loss: 0.1344678\n",
            "Epoch: 32 - Step: 92 - MSE loss: 0.0051338184 - KL loss: 0.13462332\n",
            "Epoch: 32 - Step: 93 - MSE loss: 0.0055101495 - KL loss: 0.1296711\n",
            "Epoch: 32 - Step: 94 - MSE loss: 0.005372143 - KL loss: 0.12801248\n",
            "Epoch: 32 - Step: 95 - MSE loss: 0.0056617446 - KL loss: 0.13636574\n",
            "Epoch: 32 - Step: 96 - MSE loss: 0.0052930247 - KL loss: 0.13389802\n",
            "Epoch: 32 - Step: 97 - MSE loss: 0.0058397776 - KL loss: 0.13337582\n",
            "Epoch: 32 - Step: 98 - MSE loss: 0.005700248 - KL loss: 0.13392633\n",
            "Epoch: 32 - Step: 99 - MSE loss: 0.0052545634 - KL loss: 0.13538621\n",
            "Epoch: 32 - Step: 100 - MSE loss: 0.0054978565 - KL loss: 0.13977914\n",
            "Epoch: 32 - Step: 101 - MSE loss: 0.005362271 - KL loss: 0.13382667\n",
            "Epoch: 32 - Step: 102 - MSE loss: 0.004734432 - KL loss: 0.12664889\n",
            "Epoch: 32 - Step: 103 - MSE loss: 0.004540182 - KL loss: 0.12629093\n",
            "Epoch: 32 - Step: 104 - MSE loss: 0.004853133 - KL loss: 0.12780903\n",
            "Epoch: 32 - Step: 105 - MSE loss: 0.005445192 - KL loss: 0.13974807\n",
            "Epoch: 32 - Step: 106 - MSE loss: 0.0062224553 - KL loss: 0.1472236\n",
            "Epoch: 32 - Step: 107 - MSE loss: 0.0076540783 - KL loss: 0.15989923\n",
            "Epoch: 32 - Step: 108 - MSE loss: 0.0069698286 - KL loss: 0.15883562\n",
            "Epoch: 32 - Step: 109 - MSE loss: 0.0068691554 - KL loss: 0.1752302\n",
            "Epoch: 32 - Step: 110 - MSE loss: 0.007393611 - KL loss: 0.17751187\n",
            "Epoch: 32 - Step: 111 - MSE loss: 0.007847187 - KL loss: 0.17792553\n",
            "Epoch: 32 - Step: 112 - MSE loss: 0.008146086 - KL loss: 0.17523701\n",
            "Epoch: 32 - Step: 113 - MSE loss: 0.0083028395 - KL loss: 0.17332777\n",
            "Epoch: 32 - Step: 114 - MSE loss: 0.008046586 - KL loss: 0.17810261\n",
            "Epoch: 32 - Step: 115 - MSE loss: 0.008899533 - KL loss: 0.18434802\n",
            "Epoch: 32 - Step: 116 - MSE loss: 0.008767641 - KL loss: 0.18315451\n",
            "Epoch: 32 - Step: 117 - MSE loss: 0.0084819775 - KL loss: 0.18441102\n",
            "Epoch: 32 - Step: 118 - MSE loss: 0.008224075 - KL loss: 0.17363185\n",
            "Epoch: 32 - Step: 119 - MSE loss: 0.008925618 - KL loss: 0.18833181\n",
            "Epoch: 32 - Step: 120 - MSE loss: 0.008786843 - KL loss: 0.18512097\n",
            "Epoch: 32 - Step: 121 - MSE loss: 0.008712483 - KL loss: 0.18514885\n",
            "Epoch: 32 - Step: 122 - MSE loss: 0.009151526 - KL loss: 0.17043513\n",
            "Epoch: 32 - Step: 123 - MSE loss: 0.010022272 - KL loss: 0.19105771\n",
            "Epoch: 32 - Step: 124 - MSE loss: 0.010786616 - KL loss: 0.17352049\n",
            "Epoch: 32 - Step: 125 - MSE loss: 0.009197993 - KL loss: 0.18534735\n",
            "Epoch: 32 - Step: 126 - MSE loss: 0.009056716 - KL loss: 0.18740818\n",
            "Epoch: 32 - Step: 127 - MSE loss: 0.00961545 - KL loss: 0.18525234\n",
            "Epoch: 32 - Step: 128 - MSE loss: 0.008744718 - KL loss: 0.18465188\n",
            "Epoch: 32 - Step: 129 - MSE loss: 0.008642679 - KL loss: 0.19570643\n",
            "Epoch: 32 - Step: 130 - MSE loss: 0.008585258 - KL loss: 0.18825595\n",
            "Epoch: 32 - Step: 131 - MSE loss: 0.008388636 - KL loss: 0.19021347\n",
            "Epoch: 32 - Step: 132 - MSE loss: 0.009147685 - KL loss: 0.19136396\n",
            "Epoch: 32 - Step: 133 - MSE loss: 0.009136577 - KL loss: 0.19807258\n",
            "Epoch: 32 - Step: 134 - MSE loss: 0.009192042 - KL loss: 0.18813743\n",
            "Epoch: 32 - Step: 135 - MSE loss: 0.009489471 - KL loss: 0.19372256\n",
            "Epoch: 32 - Step: 136 - MSE loss: 0.009546717 - KL loss: 0.18841794\n",
            "Epoch: 32 - Step: 137 - MSE loss: 0.009694998 - KL loss: 0.19411765\n",
            "Epoch: 32 - Step: 138 - MSE loss: 0.009972121 - KL loss: 0.19342159\n",
            "Epoch: 32 - Step: 139 - MSE loss: 0.009995236 - KL loss: 0.1923435\n",
            "Epoch: 32 - Step: 140 - MSE loss: 0.009822165 - KL loss: 0.18817747\n",
            "Epoch: 32 - Step: 141 - MSE loss: 0.009716949 - KL loss: 0.19220798\n",
            "Epoch: 32 - Step: 142 - MSE loss: 0.009441025 - KL loss: 0.18417215\n",
            "Epoch: 32 - Step: 143 - MSE loss: 0.00964159 - KL loss: 0.18776152\n",
            "Epoch: 32 - Step: 144 - MSE loss: 0.009596427 - KL loss: 0.18028592\n",
            "Epoch:  33\n",
            "Epoch: 33 - Step: 0 - MSE loss: 0.004669354 - KL loss: 0.12801737\n",
            "Epoch: 33 - Step: 1 - MSE loss: 0.004326886 - KL loss: 0.12758565\n",
            "Epoch: 33 - Step: 2 - MSE loss: 0.004454464 - KL loss: 0.13555378\n",
            "Epoch: 33 - Step: 3 - MSE loss: 0.0046323827 - KL loss: 0.12986854\n",
            "Epoch: 33 - Step: 4 - MSE loss: 0.0042754016 - KL loss: 0.13289425\n",
            "Epoch: 33 - Step: 5 - MSE loss: 0.0052623074 - KL loss: 0.12648775\n",
            "Epoch: 33 - Step: 6 - MSE loss: 0.0052832346 - KL loss: 0.13062324\n",
            "Epoch: 33 - Step: 7 - MSE loss: 0.0052713435 - KL loss: 0.12546052\n",
            "Epoch: 33 - Step: 8 - MSE loss: 0.0053416616 - KL loss: 0.13424547\n",
            "Epoch: 33 - Step: 9 - MSE loss: 0.0057751946 - KL loss: 0.1358228\n",
            "Epoch: 33 - Step: 10 - MSE loss: 0.0054858625 - KL loss: 0.13475093\n",
            "Epoch: 33 - Step: 11 - MSE loss: 0.005507404 - KL loss: 0.13161069\n",
            "Epoch: 33 - Step: 12 - MSE loss: 0.0054725087 - KL loss: 0.12806255\n",
            "Epoch: 33 - Step: 13 - MSE loss: 0.006334834 - KL loss: 0.13020585\n",
            "Epoch: 33 - Step: 14 - MSE loss: 0.006409297 - KL loss: 0.13236848\n",
            "Epoch: 33 - Step: 15 - MSE loss: 0.006707736 - KL loss: 0.13435337\n",
            "Epoch: 33 - Step: 16 - MSE loss: 0.005933816 - KL loss: 0.12956989\n",
            "Epoch: 33 - Step: 17 - MSE loss: 0.0056500826 - KL loss: 0.13197851\n",
            "Epoch: 33 - Step: 18 - MSE loss: 0.005249514 - KL loss: 0.12666626\n",
            "Epoch: 33 - Step: 19 - MSE loss: 0.004742865 - KL loss: 0.1262879\n",
            "Epoch: 33 - Step: 20 - MSE loss: 0.004827201 - KL loss: 0.118071556\n",
            "Epoch: 33 - Step: 21 - MSE loss: 0.0048922207 - KL loss: 0.11888753\n",
            "Epoch: 33 - Step: 22 - MSE loss: 0.0049288203 - KL loss: 0.11575741\n",
            "Epoch: 33 - Step: 23 - MSE loss: 0.0052084066 - KL loss: 0.12027201\n",
            "Epoch: 33 - Step: 24 - MSE loss: 0.0049984264 - KL loss: 0.116768345\n",
            "Epoch: 33 - Step: 25 - MSE loss: 0.004765789 - KL loss: 0.12053804\n",
            "Epoch: 33 - Step: 26 - MSE loss: 0.004918128 - KL loss: 0.117225796\n",
            "Epoch: 33 - Step: 27 - MSE loss: 0.0050903778 - KL loss: 0.12012884\n",
            "Epoch: 33 - Step: 28 - MSE loss: 0.0052203373 - KL loss: 0.12352734\n",
            "Epoch: 33 - Step: 29 - MSE loss: 0.0050391257 - KL loss: 0.12149371\n",
            "Epoch: 33 - Step: 30 - MSE loss: 0.004336665 - KL loss: 0.11225166\n",
            "Epoch: 33 - Step: 31 - MSE loss: 0.004887476 - KL loss: 0.11319147\n",
            "Epoch: 33 - Step: 32 - MSE loss: 0.0057852636 - KL loss: 0.1304403\n",
            "Epoch: 33 - Step: 33 - MSE loss: 0.0057445182 - KL loss: 0.13159683\n",
            "Epoch: 33 - Step: 34 - MSE loss: 0.0060266764 - KL loss: 0.13853717\n",
            "Epoch: 33 - Step: 35 - MSE loss: 0.005939413 - KL loss: 0.14301498\n",
            "Epoch: 33 - Step: 36 - MSE loss: 0.0060166493 - KL loss: 0.1468227\n",
            "Epoch: 33 - Step: 37 - MSE loss: 0.0074195233 - KL loss: 0.15676512\n",
            "Epoch: 33 - Step: 38 - MSE loss: 0.0075309016 - KL loss: 0.16460109\n",
            "Epoch: 33 - Step: 39 - MSE loss: 0.0077160993 - KL loss: 0.16905972\n",
            "Epoch: 33 - Step: 40 - MSE loss: 0.0078008063 - KL loss: 0.1661377\n",
            "Epoch: 33 - Step: 41 - MSE loss: 0.008311469 - KL loss: 0.16927074\n",
            "Epoch: 33 - Step: 42 - MSE loss: 0.007715082 - KL loss: 0.1741021\n",
            "Epoch: 33 - Step: 43 - MSE loss: 0.007226078 - KL loss: 0.16413584\n",
            "Epoch: 33 - Step: 44 - MSE loss: 0.0069055525 - KL loss: 0.17410271\n",
            "Epoch: 33 - Step: 45 - MSE loss: 0.0076816124 - KL loss: 0.1723817\n",
            "Epoch: 33 - Step: 46 - MSE loss: 0.007858475 - KL loss: 0.17325471\n",
            "Epoch: 33 - Step: 47 - MSE loss: 0.008063937 - KL loss: 0.17734955\n",
            "Epoch: 33 - Step: 48 - MSE loss: 0.008255887 - KL loss: 0.18916696\n",
            "Epoch: 33 - Step: 49 - MSE loss: 0.0073289014 - KL loss: 0.17428562\n",
            "Epoch: 33 - Step: 50 - MSE loss: 0.007923621 - KL loss: 0.18046618\n",
            "Epoch: 33 - Step: 51 - MSE loss: 0.007910544 - KL loss: 0.18400583\n",
            "Epoch: 33 - Step: 52 - MSE loss: 0.008752059 - KL loss: 0.19250467\n",
            "Epoch: 33 - Step: 53 - MSE loss: 0.009664018 - KL loss: 0.18706216\n",
            "Epoch: 33 - Step: 54 - MSE loss: 0.008728293 - KL loss: 0.17939661\n",
            "Epoch: 33 - Step: 55 - MSE loss: 0.008686645 - KL loss: 0.17506878\n",
            "Epoch: 33 - Step: 56 - MSE loss: 0.009397046 - KL loss: 0.18912141\n",
            "Epoch: 33 - Step: 57 - MSE loss: 0.009202552 - KL loss: 0.18424529\n",
            "Epoch: 33 - Step: 58 - MSE loss: 0.009334306 - KL loss: 0.18283841\n",
            "Epoch: 33 - Step: 59 - MSE loss: 0.009416384 - KL loss: 0.18556732\n",
            "Epoch: 33 - Step: 60 - MSE loss: 0.009469961 - KL loss: 0.19956088\n",
            "Epoch: 33 - Step: 61 - MSE loss: 0.009377536 - KL loss: 0.19336268\n",
            "Epoch: 33 - Step: 62 - MSE loss: 0.009129324 - KL loss: 0.19470458\n",
            "Epoch: 33 - Step: 63 - MSE loss: 0.010118549 - KL loss: 0.1836218\n",
            "Epoch: 33 - Step: 64 - MSE loss: 0.010185604 - KL loss: 0.2032005\n",
            "Epoch: 33 - Step: 65 - MSE loss: 0.0103774825 - KL loss: 0.17499903\n",
            "Epoch: 33 - Step: 66 - MSE loss: 0.009827394 - KL loss: 0.17950952\n",
            "Epoch: 33 - Step: 67 - MSE loss: 0.008116995 - KL loss: 0.15943399\n",
            "Epoch: 33 - Step: 68 - MSE loss: 0.007896856 - KL loss: 0.16696951\n",
            "Epoch: 33 - Step: 69 - MSE loss: 0.0074184984 - KL loss: 0.16346139\n",
            "Epoch: 33 - Step: 70 - MSE loss: 0.006977808 - KL loss: 0.16164845\n",
            "Epoch: 33 - Step: 71 - MSE loss: 0.0062390235 - KL loss: 0.14711577\n",
            "Epoch: 33 - Step: 72 - MSE loss: 0.006040674 - KL loss: 0.14158878\n",
            "Epoch: 33 - Step: 73 - MSE loss: 0.0057237656 - KL loss: 0.13380688\n",
            "Epoch: 33 - Step: 74 - MSE loss: 0.00535926 - KL loss: 0.137017\n",
            "Epoch: 33 - Step: 75 - MSE loss: 0.005250639 - KL loss: 0.12410192\n",
            "Epoch: 33 - Step: 76 - MSE loss: 0.005334969 - KL loss: 0.12807573\n",
            "Epoch: 33 - Step: 77 - MSE loss: 0.0052643567 - KL loss: 0.12526602\n",
            "Epoch: 33 - Step: 78 - MSE loss: 0.0056649265 - KL loss: 0.12145312\n",
            "Epoch: 33 - Step: 79 - MSE loss: 0.0051232507 - KL loss: 0.11751604\n",
            "Epoch: 33 - Step: 80 - MSE loss: 0.005189473 - KL loss: 0.124844655\n",
            "Epoch: 33 - Step: 81 - MSE loss: 0.0053585223 - KL loss: 0.12593572\n",
            "Epoch: 33 - Step: 82 - MSE loss: 0.0050461823 - KL loss: 0.12318033\n",
            "Epoch: 33 - Step: 83 - MSE loss: 0.0056423717 - KL loss: 0.12790132\n",
            "Epoch: 33 - Step: 84 - MSE loss: 0.0053764195 - KL loss: 0.12859556\n",
            "Epoch: 33 - Step: 85 - MSE loss: 0.005384888 - KL loss: 0.13418603\n",
            "Epoch: 33 - Step: 86 - MSE loss: 0.0051724142 - KL loss: 0.12995787\n",
            "Epoch: 33 - Step: 87 - MSE loss: 0.0053063934 - KL loss: 0.1312429\n",
            "Epoch: 33 - Step: 88 - MSE loss: 0.0052077738 - KL loss: 0.12717086\n",
            "Epoch: 33 - Step: 89 - MSE loss: 0.005608355 - KL loss: 0.13551675\n",
            "Epoch: 33 - Step: 90 - MSE loss: 0.004998535 - KL loss: 0.13012588\n",
            "Epoch: 33 - Step: 91 - MSE loss: 0.0053698267 - KL loss: 0.13928495\n",
            "Epoch: 33 - Step: 92 - MSE loss: 0.004904737 - KL loss: 0.13009338\n",
            "Epoch: 33 - Step: 93 - MSE loss: 0.0053085294 - KL loss: 0.13693906\n",
            "Epoch: 33 - Step: 94 - MSE loss: 0.0053449464 - KL loss: 0.13594265\n",
            "Epoch: 33 - Step: 95 - MSE loss: 0.005252557 - KL loss: 0.13126543\n",
            "Epoch: 33 - Step: 96 - MSE loss: 0.0056054355 - KL loss: 0.13442217\n",
            "Epoch: 33 - Step: 97 - MSE loss: 0.0052086064 - KL loss: 0.1308388\n",
            "Epoch: 33 - Step: 98 - MSE loss: 0.005338118 - KL loss: 0.13550074\n",
            "Epoch: 33 - Step: 99 - MSE loss: 0.0053840615 - KL loss: 0.13492087\n",
            "Epoch: 33 - Step: 100 - MSE loss: 0.0053853057 - KL loss: 0.13162538\n",
            "Epoch: 33 - Step: 101 - MSE loss: 0.005275223 - KL loss: 0.12984894\n",
            "Epoch: 33 - Step: 102 - MSE loss: 0.005138637 - KL loss: 0.13156182\n",
            "Epoch: 33 - Step: 103 - MSE loss: 0.005144189 - KL loss: 0.13260153\n",
            "Epoch: 33 - Step: 104 - MSE loss: 0.0047176257 - KL loss: 0.12711506\n",
            "Epoch: 33 - Step: 105 - MSE loss: 0.0057332423 - KL loss: 0.14128524\n",
            "Epoch: 33 - Step: 106 - MSE loss: 0.0063640275 - KL loss: 0.1414487\n",
            "Epoch: 33 - Step: 107 - MSE loss: 0.0066534765 - KL loss: 0.1594657\n",
            "Epoch: 33 - Step: 108 - MSE loss: 0.0061970246 - KL loss: 0.15733312\n",
            "Epoch: 33 - Step: 109 - MSE loss: 0.0070468527 - KL loss: 0.17170799\n",
            "Epoch: 33 - Step: 110 - MSE loss: 0.007273993 - KL loss: 0.16455165\n",
            "Epoch: 33 - Step: 111 - MSE loss: 0.0070848134 - KL loss: 0.16580495\n",
            "Epoch: 33 - Step: 112 - MSE loss: 0.007927144 - KL loss: 0.17853491\n",
            "Epoch: 33 - Step: 113 - MSE loss: 0.008249822 - KL loss: 0.18234392\n",
            "Epoch: 33 - Step: 114 - MSE loss: 0.0083397385 - KL loss: 0.17657244\n",
            "Epoch: 33 - Step: 115 - MSE loss: 0.008828045 - KL loss: 0.17820449\n",
            "Epoch: 33 - Step: 116 - MSE loss: 0.008419066 - KL loss: 0.17920177\n",
            "Epoch: 33 - Step: 117 - MSE loss: 0.009097967 - KL loss: 0.18674695\n",
            "Epoch: 33 - Step: 118 - MSE loss: 0.009398061 - KL loss: 0.18309653\n",
            "Epoch: 33 - Step: 119 - MSE loss: 0.008405966 - KL loss: 0.17423631\n",
            "Epoch: 33 - Step: 120 - MSE loss: 0.00883999 - KL loss: 0.17891333\n",
            "Epoch: 33 - Step: 121 - MSE loss: 0.007383524 - KL loss: 0.16992716\n",
            "Epoch: 33 - Step: 122 - MSE loss: 0.0074334815 - KL loss: 0.18088016\n",
            "Epoch: 33 - Step: 123 - MSE loss: 0.0073713805 - KL loss: 0.18074289\n",
            "Epoch: 33 - Step: 124 - MSE loss: 0.007780157 - KL loss: 0.18306018\n",
            "Epoch: 33 - Step: 125 - MSE loss: 0.007918068 - KL loss: 0.18511094\n",
            "Epoch: 33 - Step: 126 - MSE loss: 0.0077881855 - KL loss: 0.19036804\n",
            "Epoch: 33 - Step: 127 - MSE loss: 0.008208063 - KL loss: 0.17975363\n",
            "Epoch: 33 - Step: 128 - MSE loss: 0.007884619 - KL loss: 0.18327439\n",
            "Epoch: 33 - Step: 129 - MSE loss: 0.00790235 - KL loss: 0.18274745\n",
            "Epoch: 33 - Step: 130 - MSE loss: 0.008397123 - KL loss: 0.19239286\n",
            "Epoch: 33 - Step: 131 - MSE loss: 0.0084082605 - KL loss: 0.19019416\n",
            "Epoch: 33 - Step: 132 - MSE loss: 0.008635952 - KL loss: 0.19406047\n",
            "Epoch: 33 - Step: 133 - MSE loss: 0.009132787 - KL loss: 0.1816802\n",
            "Epoch: 33 - Step: 134 - MSE loss: 0.009363189 - KL loss: 0.19651228\n",
            "Epoch: 33 - Step: 135 - MSE loss: 0.0092562055 - KL loss: 0.18438971\n",
            "Epoch: 33 - Step: 136 - MSE loss: 0.009612226 - KL loss: 0.18159269\n",
            "Epoch: 33 - Step: 137 - MSE loss: 0.008985222 - KL loss: 0.18408526\n",
            "Epoch: 33 - Step: 138 - MSE loss: 0.009711551 - KL loss: 0.19357188\n",
            "Epoch: 33 - Step: 139 - MSE loss: 0.009613012 - KL loss: 0.1862238\n",
            "Epoch: 33 - Step: 140 - MSE loss: 0.00936234 - KL loss: 0.1845404\n",
            "Epoch: 33 - Step: 141 - MSE loss: 0.01028514 - KL loss: 0.1829567\n",
            "Epoch: 33 - Step: 142 - MSE loss: 0.009658606 - KL loss: 0.18641865\n",
            "Epoch: 33 - Step: 143 - MSE loss: 0.010369291 - KL loss: 0.17779791\n",
            "Epoch: 33 - Step: 144 - MSE loss: 0.0112116635 - KL loss: 0.1904777\n",
            "Epoch:  34\n",
            "Epoch: 34 - Step: 0 - MSE loss: 0.004988057 - KL loss: 0.11856608\n",
            "Epoch: 34 - Step: 1 - MSE loss: 0.0056936853 - KL loss: 0.13148586\n",
            "Epoch: 34 - Step: 2 - MSE loss: 0.005418045 - KL loss: 0.12597427\n",
            "Epoch: 34 - Step: 3 - MSE loss: 0.0054335073 - KL loss: 0.12962139\n",
            "Epoch: 34 - Step: 4 - MSE loss: 0.0057600434 - KL loss: 0.12649459\n",
            "Epoch: 34 - Step: 5 - MSE loss: 0.005078117 - KL loss: 0.12793072\n",
            "Epoch: 34 - Step: 6 - MSE loss: 0.004886991 - KL loss: 0.12577952\n",
            "Epoch: 34 - Step: 7 - MSE loss: 0.0048808022 - KL loss: 0.12919402\n",
            "Epoch: 34 - Step: 8 - MSE loss: 0.005519308 - KL loss: 0.13525552\n",
            "Epoch: 34 - Step: 9 - MSE loss: 0.004823894 - KL loss: 0.1251199\n",
            "Epoch: 34 - Step: 10 - MSE loss: 0.0055921283 - KL loss: 0.12882832\n",
            "Epoch: 34 - Step: 11 - MSE loss: 0.005456975 - KL loss: 0.13378756\n",
            "Epoch: 34 - Step: 12 - MSE loss: 0.0048364745 - KL loss: 0.12791288\n",
            "Epoch: 34 - Step: 13 - MSE loss: 0.005422993 - KL loss: 0.12963337\n",
            "Epoch: 34 - Step: 14 - MSE loss: 0.0052729785 - KL loss: 0.13425009\n",
            "Epoch: 34 - Step: 15 - MSE loss: 0.0053686914 - KL loss: 0.13473979\n",
            "Epoch: 34 - Step: 16 - MSE loss: 0.0052090394 - KL loss: 0.12934658\n",
            "Epoch: 34 - Step: 17 - MSE loss: 0.004861899 - KL loss: 0.12646288\n",
            "Epoch: 34 - Step: 18 - MSE loss: 0.004834859 - KL loss: 0.12213739\n",
            "Epoch: 34 - Step: 19 - MSE loss: 0.004917663 - KL loss: 0.12365328\n",
            "Epoch: 34 - Step: 20 - MSE loss: 0.0047520744 - KL loss: 0.116338655\n",
            "Epoch: 34 - Step: 21 - MSE loss: 0.004937444 - KL loss: 0.119553775\n",
            "Epoch: 34 - Step: 22 - MSE loss: 0.004925884 - KL loss: 0.115851425\n",
            "Epoch: 34 - Step: 23 - MSE loss: 0.004825304 - KL loss: 0.121123075\n",
            "Epoch: 34 - Step: 24 - MSE loss: 0.0046954714 - KL loss: 0.116586685\n",
            "Epoch: 34 - Step: 25 - MSE loss: 0.004801001 - KL loss: 0.121131696\n",
            "Epoch: 34 - Step: 26 - MSE loss: 0.0050567933 - KL loss: 0.112537086\n",
            "Epoch: 34 - Step: 27 - MSE loss: 0.0049473224 - KL loss: 0.11190194\n",
            "Epoch: 34 - Step: 28 - MSE loss: 0.0050987653 - KL loss: 0.11880341\n",
            "Epoch: 34 - Step: 29 - MSE loss: 0.004920692 - KL loss: 0.113856025\n",
            "Epoch: 34 - Step: 30 - MSE loss: 0.004152319 - KL loss: 0.11248278\n",
            "Epoch: 34 - Step: 31 - MSE loss: 0.0045402306 - KL loss: 0.11529051\n",
            "Epoch: 34 - Step: 32 - MSE loss: 0.0053537153 - KL loss: 0.11920854\n",
            "Epoch: 34 - Step: 33 - MSE loss: 0.0062691346 - KL loss: 0.13309236\n",
            "Epoch: 34 - Step: 34 - MSE loss: 0.006088877 - KL loss: 0.13787135\n",
            "Epoch: 34 - Step: 35 - MSE loss: 0.0059480406 - KL loss: 0.13151893\n",
            "Epoch: 34 - Step: 36 - MSE loss: 0.0067195133 - KL loss: 0.14925675\n",
            "Epoch: 34 - Step: 37 - MSE loss: 0.007093037 - KL loss: 0.16018432\n",
            "Epoch: 34 - Step: 38 - MSE loss: 0.0073750936 - KL loss: 0.16402277\n",
            "Epoch: 34 - Step: 39 - MSE loss: 0.007184785 - KL loss: 0.16497025\n",
            "Epoch: 34 - Step: 40 - MSE loss: 0.0073850383 - KL loss: 0.16512065\n",
            "Epoch: 34 - Step: 41 - MSE loss: 0.007938538 - KL loss: 0.17178127\n",
            "Epoch: 34 - Step: 42 - MSE loss: 0.008210865 - KL loss: 0.16460738\n",
            "Epoch: 34 - Step: 43 - MSE loss: 0.007220825 - KL loss: 0.17568897\n",
            "Epoch: 34 - Step: 44 - MSE loss: 0.007008955 - KL loss: 0.17453876\n",
            "Epoch: 34 - Step: 45 - MSE loss: 0.0071977493 - KL loss: 0.17296025\n",
            "Epoch: 34 - Step: 46 - MSE loss: 0.007269438 - KL loss: 0.17047721\n",
            "Epoch: 34 - Step: 47 - MSE loss: 0.0076303384 - KL loss: 0.18284225\n",
            "Epoch: 34 - Step: 48 - MSE loss: 0.007384289 - KL loss: 0.1800906\n",
            "Epoch: 34 - Step: 49 - MSE loss: 0.007608061 - KL loss: 0.17461151\n",
            "Epoch: 34 - Step: 50 - MSE loss: 0.008276254 - KL loss: 0.17829078\n",
            "Epoch: 34 - Step: 51 - MSE loss: 0.008229804 - KL loss: 0.18717179\n",
            "Epoch: 34 - Step: 52 - MSE loss: 0.008343785 - KL loss: 0.18896163\n",
            "Epoch: 34 - Step: 53 - MSE loss: 0.007983584 - KL loss: 0.17489658\n",
            "Epoch: 34 - Step: 54 - MSE loss: 0.007768323 - KL loss: 0.18010229\n",
            "Epoch: 34 - Step: 55 - MSE loss: 0.008389425 - KL loss: 0.185686\n",
            "Epoch: 34 - Step: 56 - MSE loss: 0.0082982825 - KL loss: 0.18541276\n",
            "Epoch: 34 - Step: 57 - MSE loss: 0.0083840415 - KL loss: 0.18018183\n",
            "Epoch: 34 - Step: 58 - MSE loss: 0.008508892 - KL loss: 0.17613736\n",
            "Epoch: 34 - Step: 59 - MSE loss: 0.008815717 - KL loss: 0.18330091\n",
            "Epoch: 34 - Step: 60 - MSE loss: 0.009478934 - KL loss: 0.18991297\n",
            "Epoch: 34 - Step: 61 - MSE loss: 0.010325653 - KL loss: 0.19963852\n",
            "Epoch: 34 - Step: 62 - MSE loss: 0.009964432 - KL loss: 0.1810577\n",
            "Epoch: 34 - Step: 63 - MSE loss: 0.011400677 - KL loss: 0.20155254\n",
            "Epoch: 34 - Step: 64 - MSE loss: 0.017036049 - KL loss: 0.18319273\n",
            "Epoch: 34 - Step: 65 - MSE loss: 0.017704172 - KL loss: 0.1977123\n",
            "Epoch: 34 - Step: 66 - MSE loss: 0.021359028 - KL loss: 0.1738807\n",
            "Epoch: 34 - Step: 67 - MSE loss: 0.013273227 - KL loss: 0.14111972\n",
            "Epoch: 34 - Step: 68 - MSE loss: 0.011011231 - KL loss: 0.15600088\n",
            "Epoch: 34 - Step: 69 - MSE loss: 0.009701119 - KL loss: 0.1657319\n",
            "Epoch: 34 - Step: 70 - MSE loss: 0.008097481 - KL loss: 0.1439004\n",
            "Epoch: 34 - Step: 71 - MSE loss: 0.009086474 - KL loss: 0.16547439\n",
            "Epoch: 34 - Step: 72 - MSE loss: 0.009966264 - KL loss: 0.15392557\n",
            "Epoch: 34 - Step: 73 - MSE loss: 0.008292978 - KL loss: 0.14058624\n",
            "Epoch: 34 - Step: 74 - MSE loss: 0.0067761745 - KL loss: 0.126831\n",
            "Epoch: 34 - Step: 75 - MSE loss: 0.0061341114 - KL loss: 0.13183427\n",
            "Epoch: 34 - Step: 76 - MSE loss: 0.0058105383 - KL loss: 0.13593112\n",
            "Epoch: 34 - Step: 77 - MSE loss: 0.006238435 - KL loss: 0.13126247\n",
            "Epoch: 34 - Step: 78 - MSE loss: 0.005559416 - KL loss: 0.12397785\n",
            "Epoch: 34 - Step: 79 - MSE loss: 0.005472878 - KL loss: 0.11948747\n",
            "Epoch: 34 - Step: 80 - MSE loss: 0.0056298175 - KL loss: 0.12362836\n",
            "Epoch: 34 - Step: 81 - MSE loss: 0.0056618345 - KL loss: 0.12559897\n",
            "Epoch: 34 - Step: 82 - MSE loss: 0.005778197 - KL loss: 0.12759024\n",
            "Epoch: 34 - Step: 83 - MSE loss: 0.0057948106 - KL loss: 0.12975273\n",
            "Epoch: 34 - Step: 84 - MSE loss: 0.0054101995 - KL loss: 0.12983985\n",
            "Epoch: 34 - Step: 85 - MSE loss: 0.0056457357 - KL loss: 0.13327992\n",
            "Epoch: 34 - Step: 86 - MSE loss: 0.0059287646 - KL loss: 0.13394234\n",
            "Epoch: 34 - Step: 87 - MSE loss: 0.005242226 - KL loss: 0.1342076\n",
            "Epoch: 34 - Step: 88 - MSE loss: 0.005382508 - KL loss: 0.13454434\n",
            "Epoch: 34 - Step: 89 - MSE loss: 0.0057503995 - KL loss: 0.14052393\n",
            "Epoch: 34 - Step: 90 - MSE loss: 0.0060479976 - KL loss: 0.13931885\n",
            "Epoch: 34 - Step: 91 - MSE loss: 0.0057810373 - KL loss: 0.1429014\n",
            "Epoch: 34 - Step: 92 - MSE loss: 0.0052381027 - KL loss: 0.13824517\n",
            "Epoch: 34 - Step: 93 - MSE loss: 0.0053720605 - KL loss: 0.12928621\n",
            "Epoch: 34 - Step: 94 - MSE loss: 0.0051654824 - KL loss: 0.1288723\n",
            "Epoch: 34 - Step: 95 - MSE loss: 0.0058445535 - KL loss: 0.13294873\n",
            "Epoch: 34 - Step: 96 - MSE loss: 0.0053531886 - KL loss: 0.1323233\n",
            "Epoch: 34 - Step: 97 - MSE loss: 0.005560164 - KL loss: 0.12834635\n",
            "Epoch: 34 - Step: 98 - MSE loss: 0.0054068267 - KL loss: 0.13647148\n",
            "Epoch: 34 - Step: 99 - MSE loss: 0.005608111 - KL loss: 0.13555795\n",
            "Epoch: 34 - Step: 100 - MSE loss: 0.005314657 - KL loss: 0.13630228\n",
            "Epoch: 34 - Step: 101 - MSE loss: 0.0056975223 - KL loss: 0.12766293\n",
            "Epoch: 34 - Step: 102 - MSE loss: 0.005217278 - KL loss: 0.12616017\n",
            "Epoch: 34 - Step: 103 - MSE loss: 0.005493393 - KL loss: 0.13356708\n",
            "Epoch: 34 - Step: 104 - MSE loss: 0.005630847 - KL loss: 0.13368854\n",
            "Epoch: 34 - Step: 105 - MSE loss: 0.0055921855 - KL loss: 0.14607461\n",
            "Epoch: 34 - Step: 106 - MSE loss: 0.006218288 - KL loss: 0.1538302\n",
            "Epoch: 34 - Step: 107 - MSE loss: 0.007087916 - KL loss: 0.15588976\n",
            "Epoch: 34 - Step: 108 - MSE loss: 0.006187759 - KL loss: 0.15522149\n",
            "Epoch: 34 - Step: 109 - MSE loss: 0.007025667 - KL loss: 0.16779858\n",
            "Epoch: 34 - Step: 110 - MSE loss: 0.0070120427 - KL loss: 0.15410843\n",
            "Epoch: 34 - Step: 111 - MSE loss: 0.008542136 - KL loss: 0.18908764\n",
            "Epoch: 34 - Step: 112 - MSE loss: 0.007976112 - KL loss: 0.16884266\n",
            "Epoch: 34 - Step: 113 - MSE loss: 0.008915377 - KL loss: 0.18494737\n",
            "Epoch: 34 - Step: 114 - MSE loss: 0.009222075 - KL loss: 0.18566352\n",
            "Epoch: 34 - Step: 115 - MSE loss: 0.008521159 - KL loss: 0.1847584\n",
            "Epoch: 34 - Step: 116 - MSE loss: 0.009740344 - KL loss: 0.18702579\n",
            "Epoch: 34 - Step: 117 - MSE loss: 0.008428018 - KL loss: 0.1784677\n",
            "Epoch: 34 - Step: 118 - MSE loss: 0.009003311 - KL loss: 0.19859141\n",
            "Epoch: 34 - Step: 119 - MSE loss: 0.008741745 - KL loss: 0.1866616\n",
            "Epoch: 34 - Step: 120 - MSE loss: 0.00854614 - KL loss: 0.17723349\n",
            "Epoch: 34 - Step: 121 - MSE loss: 0.008277389 - KL loss: 0.1787475\n",
            "Epoch: 34 - Step: 122 - MSE loss: 0.007820199 - KL loss: 0.18586048\n",
            "Epoch: 34 - Step: 123 - MSE loss: 0.0075492016 - KL loss: 0.17438473\n",
            "Epoch: 34 - Step: 124 - MSE loss: 0.0077361385 - KL loss: 0.18057504\n",
            "Epoch: 34 - Step: 125 - MSE loss: 0.0074140136 - KL loss: 0.18122596\n",
            "Epoch: 34 - Step: 126 - MSE loss: 0.00790476 - KL loss: 0.17824677\n",
            "Epoch: 34 - Step: 127 - MSE loss: 0.0077245417 - KL loss: 0.18471111\n",
            "Epoch: 34 - Step: 128 - MSE loss: 0.007393141 - KL loss: 0.18253215\n",
            "Epoch: 34 - Step: 129 - MSE loss: 0.008207696 - KL loss: 0.19166866\n",
            "Epoch: 34 - Step: 130 - MSE loss: 0.008236892 - KL loss: 0.18254414\n",
            "Epoch: 34 - Step: 131 - MSE loss: 0.008370765 - KL loss: 0.1892817\n",
            "Epoch: 34 - Step: 132 - MSE loss: 0.009200864 - KL loss: 0.19736418\n",
            "Epoch: 34 - Step: 133 - MSE loss: 0.008660252 - KL loss: 0.18458305\n",
            "Epoch: 34 - Step: 134 - MSE loss: 0.008119644 - KL loss: 0.18555051\n",
            "Epoch: 34 - Step: 135 - MSE loss: 0.009511046 - KL loss: 0.18693292\n",
            "Epoch: 34 - Step: 136 - MSE loss: 0.009232095 - KL loss: 0.1854069\n",
            "Epoch: 34 - Step: 137 - MSE loss: 0.009537526 - KL loss: 0.17817256\n",
            "Epoch: 34 - Step: 138 - MSE loss: 0.009027235 - KL loss: 0.1840516\n",
            "Epoch: 34 - Step: 139 - MSE loss: 0.0102390265 - KL loss: 0.18562812\n",
            "Epoch: 34 - Step: 140 - MSE loss: 0.009086519 - KL loss: 0.18035254\n",
            "Epoch: 34 - Step: 141 - MSE loss: 0.009946431 - KL loss: 0.19146052\n",
            "Epoch: 34 - Step: 142 - MSE loss: 0.009569443 - KL loss: 0.18248281\n",
            "Epoch: 34 - Step: 143 - MSE loss: 0.008581303 - KL loss: 0.18187003\n",
            "Epoch: 34 - Step: 144 - MSE loss: 0.009124565 - KL loss: 0.18081227\n",
            "Epoch:  35\n",
            "Epoch: 35 - Step: 0 - MSE loss: 0.0044711614 - KL loss: 0.12983152\n",
            "Epoch: 35 - Step: 1 - MSE loss: 0.0045295577 - KL loss: 0.12569407\n",
            "Epoch: 35 - Step: 2 - MSE loss: 0.0046448074 - KL loss: 0.13074137\n",
            "Epoch: 35 - Step: 3 - MSE loss: 0.0043444205 - KL loss: 0.12741351\n",
            "Epoch: 35 - Step: 4 - MSE loss: 0.004307126 - KL loss: 0.12410095\n",
            "Epoch: 35 - Step: 5 - MSE loss: 0.0045999014 - KL loss: 0.12558225\n",
            "Epoch: 35 - Step: 6 - MSE loss: 0.004851528 - KL loss: 0.12429732\n",
            "Epoch: 35 - Step: 7 - MSE loss: 0.0047458643 - KL loss: 0.12587735\n",
            "Epoch: 35 - Step: 8 - MSE loss: 0.0054257675 - KL loss: 0.13387957\n",
            "Epoch: 35 - Step: 9 - MSE loss: 0.0051388443 - KL loss: 0.13034213\n",
            "Epoch: 35 - Step: 10 - MSE loss: 0.005255539 - KL loss: 0.12713188\n",
            "Epoch: 35 - Step: 11 - MSE loss: 0.0056718737 - KL loss: 0.13007018\n",
            "Epoch: 35 - Step: 12 - MSE loss: 0.0048655146 - KL loss: 0.1250802\n",
            "Epoch: 35 - Step: 13 - MSE loss: 0.004995633 - KL loss: 0.13110748\n",
            "Epoch: 35 - Step: 14 - MSE loss: 0.0055963527 - KL loss: 0.12880586\n",
            "Epoch: 35 - Step: 15 - MSE loss: 0.0054688086 - KL loss: 0.12503594\n",
            "Epoch: 35 - Step: 16 - MSE loss: 0.005813696 - KL loss: 0.12922585\n",
            "Epoch: 35 - Step: 17 - MSE loss: 0.0052454546 - KL loss: 0.13668859\n",
            "Epoch: 35 - Step: 18 - MSE loss: 0.00506195 - KL loss: 0.12437202\n",
            "Epoch: 35 - Step: 19 - MSE loss: 0.004946523 - KL loss: 0.116894424\n",
            "Epoch: 35 - Step: 20 - MSE loss: 0.0045699845 - KL loss: 0.11588006\n",
            "Epoch: 35 - Step: 21 - MSE loss: 0.005134073 - KL loss: 0.12120524\n",
            "Epoch: 35 - Step: 22 - MSE loss: 0.004816421 - KL loss: 0.1189083\n",
            "Epoch: 35 - Step: 23 - MSE loss: 0.004979355 - KL loss: 0.11998389\n",
            "Epoch: 35 - Step: 24 - MSE loss: 0.0052680657 - KL loss: 0.11902699\n",
            "Epoch: 35 - Step: 25 - MSE loss: 0.0046753534 - KL loss: 0.11601022\n",
            "Epoch: 35 - Step: 26 - MSE loss: 0.004434451 - KL loss: 0.11367759\n",
            "Epoch: 35 - Step: 27 - MSE loss: 0.0049306382 - KL loss: 0.11526838\n",
            "Epoch: 35 - Step: 28 - MSE loss: 0.005467447 - KL loss: 0.11616284\n",
            "Epoch: 35 - Step: 29 - MSE loss: 0.0049852687 - KL loss: 0.11659457\n",
            "Epoch: 35 - Step: 30 - MSE loss: 0.005126435 - KL loss: 0.115241274\n",
            "Epoch: 35 - Step: 31 - MSE loss: 0.005590386 - KL loss: 0.11413946\n",
            "Epoch: 35 - Step: 32 - MSE loss: 0.0056322874 - KL loss: 0.11760241\n",
            "Epoch: 35 - Step: 33 - MSE loss: 0.006546564 - KL loss: 0.13411415\n",
            "Epoch: 35 - Step: 34 - MSE loss: 0.006153001 - KL loss: 0.1401908\n",
            "Epoch: 35 - Step: 35 - MSE loss: 0.0064678066 - KL loss: 0.14062923\n",
            "Epoch: 35 - Step: 36 - MSE loss: 0.00676431 - KL loss: 0.15645649\n",
            "Epoch: 35 - Step: 37 - MSE loss: 0.0069564935 - KL loss: 0.15002577\n",
            "Epoch: 35 - Step: 38 - MSE loss: 0.007437995 - KL loss: 0.16313033\n",
            "Epoch: 35 - Step: 39 - MSE loss: 0.007583817 - KL loss: 0.17627588\n",
            "Epoch: 35 - Step: 40 - MSE loss: 0.0077141426 - KL loss: 0.16598698\n",
            "Epoch: 35 - Step: 41 - MSE loss: 0.007829222 - KL loss: 0.1604547\n",
            "Epoch: 35 - Step: 42 - MSE loss: 0.006964737 - KL loss: 0.16415386\n",
            "Epoch: 35 - Step: 43 - MSE loss: 0.007386634 - KL loss: 0.16669607\n",
            "Epoch: 35 - Step: 44 - MSE loss: 0.0069707795 - KL loss: 0.17339678\n",
            "Epoch: 35 - Step: 45 - MSE loss: 0.0072014015 - KL loss: 0.17163692\n",
            "Epoch: 35 - Step: 46 - MSE loss: 0.0077617206 - KL loss: 0.16743203\n",
            "Epoch: 35 - Step: 47 - MSE loss: 0.0076376093 - KL loss: 0.17757328\n",
            "Epoch: 35 - Step: 48 - MSE loss: 0.0073845065 - KL loss: 0.17843324\n",
            "Epoch: 35 - Step: 49 - MSE loss: 0.007754207 - KL loss: 0.17667022\n",
            "Epoch: 35 - Step: 50 - MSE loss: 0.00801578 - KL loss: 0.17923853\n",
            "Epoch: 35 - Step: 51 - MSE loss: 0.0074786693 - KL loss: 0.17845437\n",
            "Epoch: 35 - Step: 52 - MSE loss: 0.008716277 - KL loss: 0.18000534\n",
            "Epoch: 35 - Step: 53 - MSE loss: 0.009098884 - KL loss: 0.1787514\n",
            "Epoch: 35 - Step: 54 - MSE loss: 0.008636176 - KL loss: 0.1877597\n",
            "Epoch: 35 - Step: 55 - MSE loss: 0.009530268 - KL loss: 0.1747567\n",
            "Epoch: 35 - Step: 56 - MSE loss: 0.010049555 - KL loss: 0.19244814\n",
            "Epoch: 35 - Step: 57 - MSE loss: 0.008182998 - KL loss: 0.17489041\n",
            "Epoch: 35 - Step: 58 - MSE loss: 0.00870489 - KL loss: 0.18852381\n",
            "Epoch: 35 - Step: 59 - MSE loss: 0.009077885 - KL loss: 0.1824099\n",
            "Epoch: 35 - Step: 60 - MSE loss: 0.009284676 - KL loss: 0.17891338\n",
            "Epoch: 35 - Step: 61 - MSE loss: 0.008794151 - KL loss: 0.18438488\n",
            "Epoch: 35 - Step: 62 - MSE loss: 0.009251614 - KL loss: 0.18731344\n",
            "Epoch: 35 - Step: 63 - MSE loss: 0.008510736 - KL loss: 0.18225242\n",
            "Epoch: 35 - Step: 64 - MSE loss: 0.008956335 - KL loss: 0.18968847\n",
            "Epoch: 35 - Step: 65 - MSE loss: 0.00919956 - KL loss: 0.19238198\n",
            "Epoch: 35 - Step: 66 - MSE loss: 0.0076245205 - KL loss: 0.17772484\n",
            "Epoch: 35 - Step: 67 - MSE loss: 0.0072407336 - KL loss: 0.15935655\n",
            "Epoch: 35 - Step: 68 - MSE loss: 0.007180871 - KL loss: 0.1580489\n",
            "Epoch: 35 - Step: 69 - MSE loss: 0.006945245 - KL loss: 0.15405767\n",
            "Epoch: 35 - Step: 70 - MSE loss: 0.0067018704 - KL loss: 0.15203124\n",
            "Epoch: 35 - Step: 71 - MSE loss: 0.0060010217 - KL loss: 0.14503548\n",
            "Epoch: 35 - Step: 72 - MSE loss: 0.0055311644 - KL loss: 0.13016593\n",
            "Epoch: 35 - Step: 73 - MSE loss: 0.0058478485 - KL loss: 0.13554035\n",
            "Epoch: 35 - Step: 74 - MSE loss: 0.005359872 - KL loss: 0.12979597\n",
            "Epoch: 35 - Step: 75 - MSE loss: 0.0049869576 - KL loss: 0.123385675\n",
            "Epoch: 35 - Step: 76 - MSE loss: 0.005583543 - KL loss: 0.12945068\n",
            "Epoch: 35 - Step: 77 - MSE loss: 0.005296986 - KL loss: 0.12575163\n",
            "Epoch: 35 - Step: 78 - MSE loss: 0.005385689 - KL loss: 0.12568887\n",
            "Epoch: 35 - Step: 79 - MSE loss: 0.004846729 - KL loss: 0.11589491\n",
            "Epoch: 35 - Step: 80 - MSE loss: 0.0045987642 - KL loss: 0.11101873\n",
            "Epoch: 35 - Step: 81 - MSE loss: 0.00459965 - KL loss: 0.11375183\n",
            "Epoch: 35 - Step: 82 - MSE loss: 0.0051190173 - KL loss: 0.11924489\n",
            "Epoch: 35 - Step: 83 - MSE loss: 0.005192493 - KL loss: 0.12609771\n",
            "Epoch: 35 - Step: 84 - MSE loss: 0.005050052 - KL loss: 0.12902942\n",
            "Epoch: 35 - Step: 85 - MSE loss: 0.005138677 - KL loss: 0.12447078\n",
            "Epoch: 35 - Step: 86 - MSE loss: 0.0052246097 - KL loss: 0.1294094\n",
            "Epoch: 35 - Step: 87 - MSE loss: 0.005293329 - KL loss: 0.1317823\n",
            "Epoch: 35 - Step: 88 - MSE loss: 0.0053084767 - KL loss: 0.13074586\n",
            "Epoch: 35 - Step: 89 - MSE loss: 0.005255506 - KL loss: 0.1297437\n",
            "Epoch: 35 - Step: 90 - MSE loss: 0.0053618685 - KL loss: 0.13451089\n",
            "Epoch: 35 - Step: 91 - MSE loss: 0.0051133432 - KL loss: 0.12876981\n",
            "Epoch: 35 - Step: 92 - MSE loss: 0.0048049632 - KL loss: 0.12722345\n",
            "Epoch: 35 - Step: 93 - MSE loss: 0.0051019336 - KL loss: 0.12750027\n",
            "Epoch: 35 - Step: 94 - MSE loss: 0.005294098 - KL loss: 0.13264889\n",
            "Epoch: 35 - Step: 95 - MSE loss: 0.005012801 - KL loss: 0.12872665\n",
            "Epoch: 35 - Step: 96 - MSE loss: 0.0051780515 - KL loss: 0.12988639\n",
            "Epoch: 35 - Step: 97 - MSE loss: 0.0048297653 - KL loss: 0.12376441\n",
            "Epoch: 35 - Step: 98 - MSE loss: 0.0052667186 - KL loss: 0.1311835\n",
            "Epoch: 35 - Step: 99 - MSE loss: 0.004924687 - KL loss: 0.13404356\n",
            "Epoch: 35 - Step: 100 - MSE loss: 0.0052703093 - KL loss: 0.13208394\n",
            "Epoch: 35 - Step: 101 - MSE loss: 0.0053285384 - KL loss: 0.13076627\n",
            "Epoch: 35 - Step: 102 - MSE loss: 0.004861289 - KL loss: 0.13027894\n",
            "Epoch: 35 - Step: 103 - MSE loss: 0.004636035 - KL loss: 0.1257017\n",
            "Epoch: 35 - Step: 104 - MSE loss: 0.004850853 - KL loss: 0.12953694\n",
            "Epoch: 35 - Step: 105 - MSE loss: 0.005684946 - KL loss: 0.14125311\n",
            "Epoch: 35 - Step: 106 - MSE loss: 0.006127003 - KL loss: 0.14608654\n",
            "Epoch: 35 - Step: 107 - MSE loss: 0.0068350825 - KL loss: 0.15288687\n",
            "Epoch: 35 - Step: 108 - MSE loss: 0.005926164 - KL loss: 0.15220183\n",
            "Epoch: 35 - Step: 109 - MSE loss: 0.00654985 - KL loss: 0.16320959\n",
            "Epoch: 35 - Step: 110 - MSE loss: 0.006665341 - KL loss: 0.16004772\n",
            "Epoch: 35 - Step: 111 - MSE loss: 0.007487245 - KL loss: 0.16572593\n",
            "Epoch: 35 - Step: 112 - MSE loss: 0.0076855845 - KL loss: 0.17001691\n",
            "Epoch: 35 - Step: 113 - MSE loss: 0.007801077 - KL loss: 0.1799881\n",
            "Epoch: 35 - Step: 114 - MSE loss: 0.0076548406 - KL loss: 0.16812243\n",
            "Epoch: 35 - Step: 115 - MSE loss: 0.008220212 - KL loss: 0.17683434\n",
            "Epoch: 35 - Step: 116 - MSE loss: 0.008791778 - KL loss: 0.18000752\n",
            "Epoch: 35 - Step: 117 - MSE loss: 0.008672283 - KL loss: 0.19047497\n",
            "Epoch: 35 - Step: 118 - MSE loss: 0.009250234 - KL loss: 0.1783163\n",
            "Epoch: 35 - Step: 119 - MSE loss: 0.007964269 - KL loss: 0.17794457\n",
            "Epoch: 35 - Step: 120 - MSE loss: 0.007542852 - KL loss: 0.16925892\n",
            "Epoch: 35 - Step: 121 - MSE loss: 0.0068905544 - KL loss: 0.16984618\n",
            "Epoch: 35 - Step: 122 - MSE loss: 0.007767899 - KL loss: 0.1625448\n",
            "Epoch: 35 - Step: 123 - MSE loss: 0.0070601315 - KL loss: 0.17247704\n",
            "Epoch: 35 - Step: 124 - MSE loss: 0.007761968 - KL loss: 0.18290561\n",
            "Epoch: 35 - Step: 125 - MSE loss: 0.007753261 - KL loss: 0.17907417\n",
            "Epoch: 35 - Step: 126 - MSE loss: 0.0075483676 - KL loss: 0.18563151\n",
            "Epoch: 35 - Step: 127 - MSE loss: 0.00694993 - KL loss: 0.17339692\n",
            "Epoch: 35 - Step: 128 - MSE loss: 0.0072775683 - KL loss: 0.17505711\n",
            "Epoch: 35 - Step: 129 - MSE loss: 0.0072168945 - KL loss: 0.17334166\n",
            "Epoch: 35 - Step: 130 - MSE loss: 0.0077841436 - KL loss: 0.18531895\n",
            "Epoch: 35 - Step: 131 - MSE loss: 0.008361669 - KL loss: 0.18928897\n",
            "Epoch: 35 - Step: 132 - MSE loss: 0.008008829 - KL loss: 0.18092482\n",
            "Epoch: 35 - Step: 133 - MSE loss: 0.00897121 - KL loss: 0.19199984\n",
            "Epoch: 35 - Step: 134 - MSE loss: 0.0104221525 - KL loss: 0.1734509\n",
            "Epoch: 35 - Step: 135 - MSE loss: 0.01169091 - KL loss: 0.18524706\n",
            "Epoch: 35 - Step: 136 - MSE loss: 0.011114781 - KL loss: 0.16799964\n",
            "Epoch: 35 - Step: 137 - MSE loss: 0.009720861 - KL loss: 0.17964408\n",
            "Epoch: 35 - Step: 138 - MSE loss: 0.009344891 - KL loss: 0.17730916\n",
            "Epoch: 35 - Step: 139 - MSE loss: 0.009527033 - KL loss: 0.18418014\n",
            "Epoch: 35 - Step: 140 - MSE loss: 0.008726082 - KL loss: 0.17808136\n",
            "Epoch: 35 - Step: 141 - MSE loss: 0.009021799 - KL loss: 0.18514767\n",
            "Epoch: 35 - Step: 142 - MSE loss: 0.008805866 - KL loss: 0.18705672\n",
            "Epoch: 35 - Step: 143 - MSE loss: 0.009617397 - KL loss: 0.18186249\n",
            "Epoch: 35 - Step: 144 - MSE loss: 0.009350076 - KL loss: 0.18687914\n",
            "Epoch:  36\n",
            "Epoch: 36 - Step: 0 - MSE loss: 0.0045993347 - KL loss: 0.13036624\n",
            "Epoch: 36 - Step: 1 - MSE loss: 0.0040550106 - KL loss: 0.122667804\n",
            "Epoch: 36 - Step: 2 - MSE loss: 0.004244474 - KL loss: 0.12869292\n",
            "Epoch: 36 - Step: 3 - MSE loss: 0.0044967285 - KL loss: 0.12751693\n",
            "Epoch: 36 - Step: 4 - MSE loss: 0.0038172894 - KL loss: 0.124267414\n",
            "Epoch: 36 - Step: 5 - MSE loss: 0.0042174044 - KL loss: 0.1267599\n",
            "Epoch: 36 - Step: 6 - MSE loss: 0.00450961 - KL loss: 0.12515557\n",
            "Epoch: 36 - Step: 7 - MSE loss: 0.005146655 - KL loss: 0.13210571\n",
            "Epoch: 36 - Step: 8 - MSE loss: 0.0046875956 - KL loss: 0.12814674\n",
            "Epoch: 36 - Step: 9 - MSE loss: 0.004967095 - KL loss: 0.13138017\n",
            "Epoch: 36 - Step: 10 - MSE loss: 0.005260762 - KL loss: 0.12678519\n",
            "Epoch: 36 - Step: 11 - MSE loss: 0.0047193556 - KL loss: 0.12744999\n",
            "Epoch: 36 - Step: 12 - MSE loss: 0.004969434 - KL loss: 0.12555733\n",
            "Epoch: 36 - Step: 13 - MSE loss: 0.005228644 - KL loss: 0.1293787\n",
            "Epoch: 36 - Step: 14 - MSE loss: 0.005558685 - KL loss: 0.1330964\n",
            "Epoch: 36 - Step: 15 - MSE loss: 0.005096455 - KL loss: 0.13297352\n",
            "Epoch: 36 - Step: 16 - MSE loss: 0.005304672 - KL loss: 0.1333293\n",
            "Epoch: 36 - Step: 17 - MSE loss: 0.005166671 - KL loss: 0.1308882\n",
            "Epoch: 36 - Step: 18 - MSE loss: 0.005078642 - KL loss: 0.124873936\n",
            "Epoch: 36 - Step: 19 - MSE loss: 0.0048185443 - KL loss: 0.12372845\n",
            "Epoch: 36 - Step: 20 - MSE loss: 0.0048776246 - KL loss: 0.118512884\n",
            "Epoch: 36 - Step: 21 - MSE loss: 0.004910212 - KL loss: 0.1128063\n",
            "Epoch: 36 - Step: 22 - MSE loss: 0.0046921065 - KL loss: 0.11600757\n",
            "Epoch: 36 - Step: 23 - MSE loss: 0.0044762683 - KL loss: 0.114819095\n",
            "Epoch: 36 - Step: 24 - MSE loss: 0.0049305796 - KL loss: 0.117182195\n",
            "Epoch: 36 - Step: 25 - MSE loss: 0.0044662883 - KL loss: 0.113979094\n",
            "Epoch: 36 - Step: 26 - MSE loss: 0.0044891723 - KL loss: 0.1106513\n",
            "Epoch: 36 - Step: 27 - MSE loss: 0.004950065 - KL loss: 0.11212771\n",
            "Epoch: 36 - Step: 28 - MSE loss: 0.004496433 - KL loss: 0.110025495\n",
            "Epoch: 36 - Step: 29 - MSE loss: 0.004393481 - KL loss: 0.11298548\n",
            "Epoch: 36 - Step: 30 - MSE loss: 0.0045843613 - KL loss: 0.112144664\n",
            "Epoch: 36 - Step: 31 - MSE loss: 0.004502224 - KL loss: 0.115619704\n",
            "Epoch: 36 - Step: 32 - MSE loss: 0.0052604093 - KL loss: 0.123085335\n",
            "Epoch: 36 - Step: 33 - MSE loss: 0.0059758653 - KL loss: 0.13691753\n",
            "Epoch: 36 - Step: 34 - MSE loss: 0.005677732 - KL loss: 0.13185948\n",
            "Epoch: 36 - Step: 35 - MSE loss: 0.005359559 - KL loss: 0.13684015\n",
            "Epoch: 36 - Step: 36 - MSE loss: 0.0064343982 - KL loss: 0.14574717\n",
            "Epoch: 36 - Step: 37 - MSE loss: 0.006887231 - KL loss: 0.15419978\n",
            "Epoch: 36 - Step: 38 - MSE loss: 0.0070724227 - KL loss: 0.15823168\n",
            "Epoch: 36 - Step: 39 - MSE loss: 0.007772386 - KL loss: 0.15849036\n",
            "Epoch: 36 - Step: 40 - MSE loss: 0.007961278 - KL loss: 0.16119738\n",
            "Epoch: 36 - Step: 41 - MSE loss: 0.0070067197 - KL loss: 0.15291649\n",
            "Epoch: 36 - Step: 42 - MSE loss: 0.0066874395 - KL loss: 0.1635674\n",
            "Epoch: 36 - Step: 43 - MSE loss: 0.007916983 - KL loss: 0.16494565\n",
            "Epoch: 36 - Step: 44 - MSE loss: 0.0071630483 - KL loss: 0.1692626\n",
            "Epoch: 36 - Step: 45 - MSE loss: 0.007667529 - KL loss: 0.17029506\n",
            "Epoch: 36 - Step: 46 - MSE loss: 0.007013617 - KL loss: 0.17560656\n",
            "Epoch: 36 - Step: 47 - MSE loss: 0.006571891 - KL loss: 0.17341429\n",
            "Epoch: 36 - Step: 48 - MSE loss: 0.008034215 - KL loss: 0.18040809\n",
            "Epoch: 36 - Step: 49 - MSE loss: 0.0072964276 - KL loss: 0.17241448\n",
            "Epoch: 36 - Step: 50 - MSE loss: 0.008009892 - KL loss: 0.17863563\n",
            "Epoch: 36 - Step: 51 - MSE loss: 0.008433623 - KL loss: 0.1754567\n",
            "Epoch: 36 - Step: 52 - MSE loss: 0.008570195 - KL loss: 0.18143153\n",
            "Epoch: 36 - Step: 53 - MSE loss: 0.008332622 - KL loss: 0.1708642\n",
            "Epoch: 36 - Step: 54 - MSE loss: 0.008321617 - KL loss: 0.17895785\n",
            "Epoch: 36 - Step: 55 - MSE loss: 0.008044088 - KL loss: 0.17298271\n",
            "Epoch: 36 - Step: 56 - MSE loss: 0.007727917 - KL loss: 0.17788053\n",
            "Epoch: 36 - Step: 57 - MSE loss: 0.007809987 - KL loss: 0.17287868\n",
            "Epoch: 36 - Step: 58 - MSE loss: 0.008313046 - KL loss: 0.17279078\n",
            "Epoch: 36 - Step: 59 - MSE loss: 0.008568276 - KL loss: 0.18198764\n",
            "Epoch: 36 - Step: 60 - MSE loss: 0.009101418 - KL loss: 0.1782074\n",
            "Epoch: 36 - Step: 61 - MSE loss: 0.0085273525 - KL loss: 0.19051082\n",
            "Epoch: 36 - Step: 62 - MSE loss: 0.008923358 - KL loss: 0.18869412\n",
            "Epoch: 36 - Step: 63 - MSE loss: 0.008787984 - KL loss: 0.19148058\n",
            "Epoch: 36 - Step: 64 - MSE loss: 0.0093049565 - KL loss: 0.17910375\n",
            "Epoch: 36 - Step: 65 - MSE loss: 0.0093784025 - KL loss: 0.18776456\n",
            "Epoch: 36 - Step: 66 - MSE loss: 0.009262958 - KL loss: 0.16792716\n",
            "Epoch: 36 - Step: 67 - MSE loss: 0.008159335 - KL loss: 0.17661352\n",
            "Epoch: 36 - Step: 68 - MSE loss: 0.007874227 - KL loss: 0.16073377\n",
            "Epoch: 36 - Step: 69 - MSE loss: 0.007106032 - KL loss: 0.15727353\n",
            "Epoch: 36 - Step: 70 - MSE loss: 0.0066423547 - KL loss: 0.15827242\n",
            "Epoch: 36 - Step: 71 - MSE loss: 0.005496783 - KL loss: 0.13614301\n",
            "Epoch: 36 - Step: 72 - MSE loss: 0.0050307144 - KL loss: 0.1253044\n",
            "Epoch: 36 - Step: 73 - MSE loss: 0.005465464 - KL loss: 0.1319569\n",
            "Epoch: 36 - Step: 74 - MSE loss: 0.0054836185 - KL loss: 0.12997144\n",
            "Epoch: 36 - Step: 75 - MSE loss: 0.0047858036 - KL loss: 0.12358171\n",
            "Epoch: 36 - Step: 76 - MSE loss: 0.0053968416 - KL loss: 0.12611818\n",
            "Epoch: 36 - Step: 77 - MSE loss: 0.0052617714 - KL loss: 0.12453934\n",
            "Epoch: 36 - Step: 78 - MSE loss: 0.004613852 - KL loss: 0.11604808\n",
            "Epoch: 36 - Step: 79 - MSE loss: 0.0048518362 - KL loss: 0.11732034\n",
            "Epoch: 36 - Step: 80 - MSE loss: 0.0048567005 - KL loss: 0.12348903\n",
            "Epoch: 36 - Step: 81 - MSE loss: 0.0048434353 - KL loss: 0.120416865\n",
            "Epoch: 36 - Step: 82 - MSE loss: 0.0055862903 - KL loss: 0.1249937\n",
            "Epoch: 36 - Step: 83 - MSE loss: 0.0052061477 - KL loss: 0.11945282\n",
            "Epoch: 36 - Step: 84 - MSE loss: 0.005267045 - KL loss: 0.1279302\n",
            "Epoch: 36 - Step: 85 - MSE loss: 0.005225442 - KL loss: 0.12366411\n",
            "Epoch: 36 - Step: 86 - MSE loss: 0.005021314 - KL loss: 0.12641105\n",
            "Epoch: 36 - Step: 87 - MSE loss: 0.005244784 - KL loss: 0.12532535\n",
            "Epoch: 36 - Step: 88 - MSE loss: 0.0049183834 - KL loss: 0.12607118\n",
            "Epoch: 36 - Step: 89 - MSE loss: 0.004986844 - KL loss: 0.12920418\n",
            "Epoch: 36 - Step: 90 - MSE loss: 0.005156636 - KL loss: 0.1321488\n",
            "Epoch: 36 - Step: 91 - MSE loss: 0.0049876324 - KL loss: 0.13241747\n",
            "Epoch: 36 - Step: 92 - MSE loss: 0.0047622584 - KL loss: 0.13396935\n",
            "Epoch: 36 - Step: 93 - MSE loss: 0.005137266 - KL loss: 0.13175058\n",
            "Epoch: 36 - Step: 94 - MSE loss: 0.005031585 - KL loss: 0.12797889\n",
            "Epoch: 36 - Step: 95 - MSE loss: 0.0046309577 - KL loss: 0.12824276\n",
            "Epoch: 36 - Step: 96 - MSE loss: 0.005184337 - KL loss: 0.12838924\n",
            "Epoch: 36 - Step: 97 - MSE loss: 0.00475009 - KL loss: 0.127904\n",
            "Epoch: 36 - Step: 98 - MSE loss: 0.0047184206 - KL loss: 0.12327435\n",
            "Epoch: 36 - Step: 99 - MSE loss: 0.0052474192 - KL loss: 0.1327391\n",
            "Epoch: 36 - Step: 100 - MSE loss: 0.004934942 - KL loss: 0.12943605\n",
            "Epoch: 36 - Step: 101 - MSE loss: 0.0051242397 - KL loss: 0.13148472\n",
            "Epoch: 36 - Step: 102 - MSE loss: 0.004610908 - KL loss: 0.123633675\n",
            "Epoch: 36 - Step: 103 - MSE loss: 0.004211075 - KL loss: 0.123166606\n",
            "Epoch: 36 - Step: 104 - MSE loss: 0.004673613 - KL loss: 0.12791657\n",
            "Epoch: 36 - Step: 105 - MSE loss: 0.0050270916 - KL loss: 0.1328457\n",
            "Epoch: 36 - Step: 106 - MSE loss: 0.006493252 - KL loss: 0.14859393\n",
            "Epoch: 36 - Step: 107 - MSE loss: 0.006259423 - KL loss: 0.1459875\n",
            "Epoch: 36 - Step: 108 - MSE loss: 0.0058759563 - KL loss: 0.14731051\n",
            "Epoch: 36 - Step: 109 - MSE loss: 0.0065670046 - KL loss: 0.16219646\n",
            "Epoch: 36 - Step: 110 - MSE loss: 0.006158249 - KL loss: 0.1636309\n",
            "Epoch: 36 - Step: 111 - MSE loss: 0.0070286538 - KL loss: 0.17158306\n",
            "Epoch: 36 - Step: 112 - MSE loss: 0.008084014 - KL loss: 0.17340644\n",
            "Epoch: 36 - Step: 113 - MSE loss: 0.008659444 - KL loss: 0.17667851\n",
            "Epoch: 36 - Step: 114 - MSE loss: 0.0077710524 - KL loss: 0.17915338\n",
            "Epoch: 36 - Step: 115 - MSE loss: 0.0076500834 - KL loss: 0.17463465\n",
            "Epoch: 36 - Step: 116 - MSE loss: 0.008192723 - KL loss: 0.17768723\n",
            "Epoch: 36 - Step: 117 - MSE loss: 0.0081739 - KL loss: 0.16220543\n",
            "Epoch: 36 - Step: 118 - MSE loss: 0.0073224995 - KL loss: 0.16956165\n",
            "Epoch: 36 - Step: 119 - MSE loss: 0.00754156 - KL loss: 0.16571823\n",
            "Epoch: 36 - Step: 120 - MSE loss: 0.007969239 - KL loss: 0.17318618\n",
            "Epoch: 36 - Step: 121 - MSE loss: 0.0072352854 - KL loss: 0.16692688\n",
            "Epoch: 36 - Step: 122 - MSE loss: 0.0073995874 - KL loss: 0.17822932\n",
            "Epoch: 36 - Step: 123 - MSE loss: 0.007398291 - KL loss: 0.17836353\n",
            "Epoch: 36 - Step: 124 - MSE loss: 0.0074626897 - KL loss: 0.17079782\n",
            "Epoch: 36 - Step: 125 - MSE loss: 0.0070320605 - KL loss: 0.17325294\n",
            "Epoch: 36 - Step: 126 - MSE loss: 0.007894422 - KL loss: 0.18432844\n",
            "Epoch: 36 - Step: 127 - MSE loss: 0.007557836 - KL loss: 0.17721\n",
            "Epoch: 36 - Step: 128 - MSE loss: 0.0074792947 - KL loss: 0.17147496\n",
            "Epoch: 36 - Step: 129 - MSE loss: 0.007493978 - KL loss: 0.18145113\n",
            "Epoch: 36 - Step: 130 - MSE loss: 0.007949125 - KL loss: 0.18616086\n",
            "Epoch: 36 - Step: 131 - MSE loss: 0.007327864 - KL loss: 0.18282145\n",
            "Epoch: 36 - Step: 132 - MSE loss: 0.007908967 - KL loss: 0.18388052\n",
            "Epoch: 36 - Step: 133 - MSE loss: 0.008866657 - KL loss: 0.18889156\n",
            "Epoch: 36 - Step: 134 - MSE loss: 0.009009893 - KL loss: 0.17285717\n",
            "Epoch: 36 - Step: 135 - MSE loss: 0.0095077185 - KL loss: 0.19411197\n",
            "Epoch: 36 - Step: 136 - MSE loss: 0.010276566 - KL loss: 0.17682195\n",
            "Epoch: 36 - Step: 137 - MSE loss: 0.010159505 - KL loss: 0.18241444\n",
            "Epoch: 36 - Step: 138 - MSE loss: 0.009803538 - KL loss: 0.17231941\n",
            "Epoch: 36 - Step: 139 - MSE loss: 0.009503295 - KL loss: 0.18192998\n",
            "Epoch: 36 - Step: 140 - MSE loss: 0.011039022 - KL loss: 0.1783129\n",
            "Epoch: 36 - Step: 141 - MSE loss: 0.011056126 - KL loss: 0.19036886\n",
            "Epoch: 36 - Step: 142 - MSE loss: 0.010589644 - KL loss: 0.17044789\n",
            "Epoch: 36 - Step: 143 - MSE loss: 0.009091798 - KL loss: 0.17697397\n",
            "Epoch: 36 - Step: 144 - MSE loss: 0.009724087 - KL loss: 0.18584007\n",
            "Epoch:  37\n",
            "Epoch: 37 - Step: 0 - MSE loss: 0.0045025 - KL loss: 0.12368638\n",
            "Epoch: 37 - Step: 1 - MSE loss: 0.0046510645 - KL loss: 0.123716086\n",
            "Epoch: 37 - Step: 2 - MSE loss: 0.0046150135 - KL loss: 0.12905365\n",
            "Epoch: 37 - Step: 3 - MSE loss: 0.0044697393 - KL loss: 0.12929109\n",
            "Epoch: 37 - Step: 4 - MSE loss: 0.004394705 - KL loss: 0.12757716\n",
            "Epoch: 37 - Step: 5 - MSE loss: 0.00440851 - KL loss: 0.12193914\n",
            "Epoch: 37 - Step: 6 - MSE loss: 0.004062426 - KL loss: 0.121688224\n",
            "Epoch: 37 - Step: 7 - MSE loss: 0.0045520184 - KL loss: 0.12506798\n",
            "Epoch: 37 - Step: 8 - MSE loss: 0.004914081 - KL loss: 0.13056964\n",
            "Epoch: 37 - Step: 9 - MSE loss: 0.005177163 - KL loss: 0.12976521\n",
            "Epoch: 37 - Step: 10 - MSE loss: 0.004856633 - KL loss: 0.12383978\n",
            "Epoch: 37 - Step: 11 - MSE loss: 0.0053376793 - KL loss: 0.13287564\n",
            "Epoch: 37 - Step: 12 - MSE loss: 0.0054961233 - KL loss: 0.12894146\n",
            "Epoch: 37 - Step: 13 - MSE loss: 0.005051106 - KL loss: 0.12475839\n",
            "Epoch: 37 - Step: 14 - MSE loss: 0.0052394103 - KL loss: 0.12862149\n",
            "Epoch: 37 - Step: 15 - MSE loss: 0.005122921 - KL loss: 0.13090514\n",
            "Epoch: 37 - Step: 16 - MSE loss: 0.0052418318 - KL loss: 0.12961766\n",
            "Epoch: 37 - Step: 17 - MSE loss: 0.0049926047 - KL loss: 0.12958768\n",
            "Epoch: 37 - Step: 18 - MSE loss: 0.0046150777 - KL loss: 0.120902106\n",
            "Epoch: 37 - Step: 19 - MSE loss: 0.0047405604 - KL loss: 0.11602311\n",
            "Epoch: 37 - Step: 20 - MSE loss: 0.004523284 - KL loss: 0.114222966\n",
            "Epoch: 37 - Step: 21 - MSE loss: 0.004500178 - KL loss: 0.11285745\n",
            "Epoch: 37 - Step: 22 - MSE loss: 0.004923564 - KL loss: 0.11260283\n",
            "Epoch: 37 - Step: 23 - MSE loss: 0.0047963993 - KL loss: 0.12093985\n",
            "Epoch: 37 - Step: 24 - MSE loss: 0.005017312 - KL loss: 0.12070254\n",
            "Epoch: 37 - Step: 25 - MSE loss: 0.004619426 - KL loss: 0.11892315\n",
            "Epoch: 37 - Step: 26 - MSE loss: 0.004852494 - KL loss: 0.11389418\n",
            "Epoch: 37 - Step: 27 - MSE loss: 0.004186763 - KL loss: 0.11081924\n",
            "Epoch: 37 - Step: 28 - MSE loss: 0.0049599726 - KL loss: 0.11851798\n",
            "Epoch: 37 - Step: 29 - MSE loss: 0.0048124944 - KL loss: 0.112440504\n",
            "Epoch: 37 - Step: 30 - MSE loss: 0.00462803 - KL loss: 0.1129357\n",
            "Epoch: 37 - Step: 31 - MSE loss: 0.0046130507 - KL loss: 0.12059574\n",
            "Epoch: 37 - Step: 32 - MSE loss: 0.0051893047 - KL loss: 0.11846481\n",
            "Epoch: 37 - Step: 33 - MSE loss: 0.0053744535 - KL loss: 0.13032234\n",
            "Epoch: 37 - Step: 34 - MSE loss: 0.00559989 - KL loss: 0.13281624\n",
            "Epoch: 37 - Step: 35 - MSE loss: 0.0052950676 - KL loss: 0.13219352\n",
            "Epoch: 37 - Step: 36 - MSE loss: 0.006603285 - KL loss: 0.15435922\n",
            "Epoch: 37 - Step: 37 - MSE loss: 0.0066282614 - KL loss: 0.1584729\n",
            "Epoch: 37 - Step: 38 - MSE loss: 0.006595192 - KL loss: 0.15276048\n",
            "Epoch: 37 - Step: 39 - MSE loss: 0.00692964 - KL loss: 0.15857041\n",
            "Epoch: 37 - Step: 40 - MSE loss: 0.008041452 - KL loss: 0.16489807\n",
            "Epoch: 37 - Step: 41 - MSE loss: 0.0071819928 - KL loss: 0.15987976\n",
            "Epoch: 37 - Step: 42 - MSE loss: 0.006788878 - KL loss: 0.15348604\n",
            "Epoch: 37 - Step: 43 - MSE loss: 0.0069389357 - KL loss: 0.17328298\n",
            "Epoch: 37 - Step: 44 - MSE loss: 0.0067753964 - KL loss: 0.16820739\n",
            "Epoch: 37 - Step: 45 - MSE loss: 0.0068220072 - KL loss: 0.1652937\n",
            "Epoch: 37 - Step: 46 - MSE loss: 0.007695476 - KL loss: 0.17696145\n",
            "Epoch: 37 - Step: 47 - MSE loss: 0.0072205127 - KL loss: 0.16788927\n",
            "Epoch: 37 - Step: 48 - MSE loss: 0.0070711393 - KL loss: 0.17279387\n",
            "Epoch: 37 - Step: 49 - MSE loss: 0.007437702 - KL loss: 0.1720447\n",
            "Epoch: 37 - Step: 50 - MSE loss: 0.0068557034 - KL loss: 0.17250426\n",
            "Epoch: 37 - Step: 51 - MSE loss: 0.0075928043 - KL loss: 0.17114112\n",
            "Epoch: 37 - Step: 52 - MSE loss: 0.007653315 - KL loss: 0.17947245\n",
            "Epoch: 37 - Step: 53 - MSE loss: 0.008256028 - KL loss: 0.17091727\n",
            "Epoch: 37 - Step: 54 - MSE loss: 0.008012638 - KL loss: 0.17433268\n",
            "Epoch: 37 - Step: 55 - MSE loss: 0.0082085235 - KL loss: 0.17208138\n",
            "Epoch: 37 - Step: 56 - MSE loss: 0.007956196 - KL loss: 0.17378092\n",
            "Epoch: 37 - Step: 57 - MSE loss: 0.007503111 - KL loss: 0.1761606\n",
            "Epoch: 37 - Step: 58 - MSE loss: 0.008139779 - KL loss: 0.18316981\n",
            "Epoch: 37 - Step: 59 - MSE loss: 0.008614688 - KL loss: 0.18341981\n",
            "Epoch: 37 - Step: 60 - MSE loss: 0.009566291 - KL loss: 0.18365017\n",
            "Epoch: 37 - Step: 61 - MSE loss: 0.008844785 - KL loss: 0.18118474\n",
            "Epoch: 37 - Step: 62 - MSE loss: 0.009258901 - KL loss: 0.17265321\n",
            "Epoch: 37 - Step: 63 - MSE loss: 0.009180783 - KL loss: 0.1804353\n",
            "Epoch: 37 - Step: 64 - MSE loss: 0.009568998 - KL loss: 0.18674067\n",
            "Epoch: 37 - Step: 65 - MSE loss: 0.00872841 - KL loss: 0.19247475\n",
            "Epoch: 37 - Step: 66 - MSE loss: 0.0071485904 - KL loss: 0.16946706\n",
            "Epoch: 37 - Step: 67 - MSE loss: 0.0070615374 - KL loss: 0.16103345\n",
            "Epoch: 37 - Step: 68 - MSE loss: 0.0063885762 - KL loss: 0.14535561\n",
            "Epoch: 37 - Step: 69 - MSE loss: 0.0069430848 - KL loss: 0.16247727\n",
            "Epoch: 37 - Step: 70 - MSE loss: 0.006565232 - KL loss: 0.15070806\n",
            "Epoch: 37 - Step: 71 - MSE loss: 0.006406013 - KL loss: 0.1438261\n",
            "Epoch: 37 - Step: 72 - MSE loss: 0.005508199 - KL loss: 0.12620409\n",
            "Epoch: 37 - Step: 73 - MSE loss: 0.005347879 - KL loss: 0.13602886\n",
            "Epoch: 37 - Step: 74 - MSE loss: 0.005799532 - KL loss: 0.1330865\n",
            "Epoch: 37 - Step: 75 - MSE loss: 0.0046218 - KL loss: 0.12397748\n",
            "Epoch: 37 - Step: 76 - MSE loss: 0.004629306 - KL loss: 0.11742154\n",
            "Epoch: 37 - Step: 77 - MSE loss: 0.00506081 - KL loss: 0.120812796\n",
            "Epoch: 37 - Step: 78 - MSE loss: 0.004772199 - KL loss: 0.117916524\n",
            "Epoch: 37 - Step: 79 - MSE loss: 0.004683676 - KL loss: 0.11384232\n",
            "Epoch: 37 - Step: 80 - MSE loss: 0.0045608394 - KL loss: 0.114063725\n",
            "Epoch: 37 - Step: 81 - MSE loss: 0.0051790155 - KL loss: 0.12495709\n",
            "Epoch: 37 - Step: 82 - MSE loss: 0.0050601903 - KL loss: 0.11880495\n",
            "Epoch: 37 - Step: 83 - MSE loss: 0.00519391 - KL loss: 0.12212612\n",
            "Epoch: 37 - Step: 84 - MSE loss: 0.0049085324 - KL loss: 0.11912276\n",
            "Epoch: 37 - Step: 85 - MSE loss: 0.0044717845 - KL loss: 0.12025186\n",
            "Epoch: 37 - Step: 86 - MSE loss: 0.005340054 - KL loss: 0.12788674\n",
            "Epoch: 37 - Step: 87 - MSE loss: 0.0051487894 - KL loss: 0.1242371\n",
            "Epoch: 37 - Step: 88 - MSE loss: 0.005100591 - KL loss: 0.13146551\n",
            "Epoch: 37 - Step: 89 - MSE loss: 0.005165373 - KL loss: 0.12936598\n",
            "Epoch: 37 - Step: 90 - MSE loss: 0.005070967 - KL loss: 0.13517952\n",
            "Epoch: 37 - Step: 91 - MSE loss: 0.0048974776 - KL loss: 0.12800829\n",
            "Epoch: 37 - Step: 92 - MSE loss: 0.0045246794 - KL loss: 0.12332265\n",
            "Epoch: 37 - Step: 93 - MSE loss: 0.004371698 - KL loss: 0.12555599\n",
            "Epoch: 37 - Step: 94 - MSE loss: 0.005050288 - KL loss: 0.13246611\n",
            "Epoch: 37 - Step: 95 - MSE loss: 0.005392438 - KL loss: 0.13006943\n",
            "Epoch: 37 - Step: 96 - MSE loss: 0.004853236 - KL loss: 0.12724063\n",
            "Epoch: 37 - Step: 97 - MSE loss: 0.0049617495 - KL loss: 0.13053125\n",
            "Epoch: 37 - Step: 98 - MSE loss: 0.004678631 - KL loss: 0.12895438\n",
            "Epoch: 37 - Step: 99 - MSE loss: 0.004720629 - KL loss: 0.12922516\n",
            "Epoch: 37 - Step: 100 - MSE loss: 0.004842281 - KL loss: 0.13250673\n",
            "Epoch: 37 - Step: 101 - MSE loss: 0.004841765 - KL loss: 0.12474944\n",
            "Epoch: 37 - Step: 102 - MSE loss: 0.004877228 - KL loss: 0.1282165\n",
            "Epoch: 37 - Step: 103 - MSE loss: 0.004104494 - KL loss: 0.12251298\n",
            "Epoch: 37 - Step: 104 - MSE loss: 0.0045613116 - KL loss: 0.13200593\n",
            "Epoch: 37 - Step: 105 - MSE loss: 0.0047660028 - KL loss: 0.12965085\n",
            "Epoch: 37 - Step: 106 - MSE loss: 0.005879525 - KL loss: 0.14090534\n",
            "Epoch: 37 - Step: 107 - MSE loss: 0.006041862 - KL loss: 0.14252263\n",
            "Epoch: 37 - Step: 108 - MSE loss: 0.0061375587 - KL loss: 0.15322761\n",
            "Epoch: 37 - Step: 109 - MSE loss: 0.0059729056 - KL loss: 0.15764047\n",
            "Epoch: 37 - Step: 110 - MSE loss: 0.006693596 - KL loss: 0.16418427\n",
            "Epoch: 37 - Step: 111 - MSE loss: 0.00675871 - KL loss: 0.1644871\n",
            "Epoch: 37 - Step: 112 - MSE loss: 0.0074849655 - KL loss: 0.17066993\n",
            "Epoch: 37 - Step: 113 - MSE loss: 0.007025437 - KL loss: 0.16710559\n",
            "Epoch: 37 - Step: 114 - MSE loss: 0.008272197 - KL loss: 0.17940682\n",
            "Epoch: 37 - Step: 115 - MSE loss: 0.008551816 - KL loss: 0.19090742\n",
            "Epoch: 37 - Step: 116 - MSE loss: 0.008499562 - KL loss: 0.17750758\n",
            "Epoch: 37 - Step: 117 - MSE loss: 0.007794768 - KL loss: 0.16913563\n",
            "Epoch: 37 - Step: 118 - MSE loss: 0.00746952 - KL loss: 0.17107433\n",
            "Epoch: 37 - Step: 119 - MSE loss: 0.007419443 - KL loss: 0.17450011\n",
            "Epoch: 37 - Step: 120 - MSE loss: 0.007219896 - KL loss: 0.16785574\n",
            "Epoch: 37 - Step: 121 - MSE loss: 0.007114366 - KL loss: 0.17166586\n",
            "Epoch: 37 - Step: 122 - MSE loss: 0.0071320753 - KL loss: 0.17107736\n",
            "Epoch: 37 - Step: 123 - MSE loss: 0.007257433 - KL loss: 0.1713523\n",
            "Epoch: 37 - Step: 124 - MSE loss: 0.007140661 - KL loss: 0.17185262\n",
            "Epoch: 37 - Step: 125 - MSE loss: 0.0071407217 - KL loss: 0.17390224\n",
            "Epoch: 37 - Step: 126 - MSE loss: 0.0070200176 - KL loss: 0.17783736\n",
            "Epoch: 37 - Step: 127 - MSE loss: 0.0068529644 - KL loss: 0.17535542\n",
            "Epoch: 37 - Step: 128 - MSE loss: 0.006779799 - KL loss: 0.16968527\n",
            "Epoch: 37 - Step: 129 - MSE loss: 0.0076209255 - KL loss: 0.17243156\n",
            "Epoch: 37 - Step: 130 - MSE loss: 0.007528324 - KL loss: 0.17407891\n",
            "Epoch: 37 - Step: 131 - MSE loss: 0.007965043 - KL loss: 0.18259665\n",
            "Epoch: 37 - Step: 132 - MSE loss: 0.008520316 - KL loss: 0.18331754\n",
            "Epoch: 37 - Step: 133 - MSE loss: 0.009145242 - KL loss: 0.19125965\n",
            "Epoch: 37 - Step: 134 - MSE loss: 0.0115245655 - KL loss: 0.16956773\n",
            "Epoch: 37 - Step: 135 - MSE loss: 0.011680865 - KL loss: 0.18090571\n",
            "Epoch: 37 - Step: 136 - MSE loss: 0.011824458 - KL loss: 0.16721043\n",
            "Epoch: 37 - Step: 137 - MSE loss: 0.011777162 - KL loss: 0.17168297\n",
            "Epoch: 37 - Step: 138 - MSE loss: 0.01157976 - KL loss: 0.1698713\n",
            "Epoch: 37 - Step: 139 - MSE loss: 0.010128018 - KL loss: 0.19163764\n",
            "Epoch: 37 - Step: 140 - MSE loss: 0.009198253 - KL loss: 0.17788836\n",
            "Epoch: 37 - Step: 141 - MSE loss: 0.009015862 - KL loss: 0.1781492\n",
            "Epoch: 37 - Step: 142 - MSE loss: 0.008902937 - KL loss: 0.17996955\n",
            "Epoch: 37 - Step: 143 - MSE loss: 0.008824782 - KL loss: 0.1824735\n",
            "Epoch: 37 - Step: 144 - MSE loss: 0.008218046 - KL loss: 0.17882173\n",
            "Epoch:  38\n",
            "Epoch: 38 - Step: 0 - MSE loss: 0.0041635726 - KL loss: 0.12403235\n",
            "Epoch: 38 - Step: 1 - MSE loss: 0.004181499 - KL loss: 0.121535845\n",
            "Epoch: 38 - Step: 2 - MSE loss: 0.004144301 - KL loss: 0.1236646\n",
            "Epoch: 38 - Step: 3 - MSE loss: 0.004126187 - KL loss: 0.12420547\n",
            "Epoch: 38 - Step: 4 - MSE loss: 0.004226785 - KL loss: 0.12517115\n",
            "Epoch: 38 - Step: 5 - MSE loss: 0.0041511124 - KL loss: 0.12793379\n",
            "Epoch: 38 - Step: 6 - MSE loss: 0.0044895024 - KL loss: 0.12550324\n",
            "Epoch: 38 - Step: 7 - MSE loss: 0.00455546 - KL loss: 0.13192576\n",
            "Epoch: 38 - Step: 8 - MSE loss: 0.004496216 - KL loss: 0.12795058\n",
            "Epoch: 38 - Step: 9 - MSE loss: 0.005107528 - KL loss: 0.12989235\n",
            "Epoch: 38 - Step: 10 - MSE loss: 0.0047719087 - KL loss: 0.13094959\n",
            "Epoch: 38 - Step: 11 - MSE loss: 0.004840437 - KL loss: 0.12821756\n",
            "Epoch: 38 - Step: 12 - MSE loss: 0.00511964 - KL loss: 0.1270486\n",
            "Epoch: 38 - Step: 13 - MSE loss: 0.004937639 - KL loss: 0.12905477\n",
            "Epoch: 38 - Step: 14 - MSE loss: 0.005405487 - KL loss: 0.130637\n",
            "Epoch: 38 - Step: 15 - MSE loss: 0.004848597 - KL loss: 0.124573484\n",
            "Epoch: 38 - Step: 16 - MSE loss: 0.005004222 - KL loss: 0.12844862\n",
            "Epoch: 38 - Step: 17 - MSE loss: 0.0047412766 - KL loss: 0.12503196\n",
            "Epoch: 38 - Step: 18 - MSE loss: 0.004542301 - KL loss: 0.119323194\n",
            "Epoch: 38 - Step: 19 - MSE loss: 0.004436688 - KL loss: 0.11512515\n",
            "Epoch: 38 - Step: 20 - MSE loss: 0.0044001234 - KL loss: 0.11529319\n",
            "Epoch: 38 - Step: 21 - MSE loss: 0.0048313434 - KL loss: 0.1134766\n",
            "Epoch: 38 - Step: 22 - MSE loss: 0.004899806 - KL loss: 0.11539993\n",
            "Epoch: 38 - Step: 23 - MSE loss: 0.0046398626 - KL loss: 0.11346412\n",
            "Epoch: 38 - Step: 24 - MSE loss: 0.0046513113 - KL loss: 0.113593176\n",
            "Epoch: 38 - Step: 25 - MSE loss: 0.0046712845 - KL loss: 0.12127593\n",
            "Epoch: 38 - Step: 26 - MSE loss: 0.0044781617 - KL loss: 0.11387018\n",
            "Epoch: 38 - Step: 27 - MSE loss: 0.004644695 - KL loss: 0.11376017\n",
            "Epoch: 38 - Step: 28 - MSE loss: 0.0046904706 - KL loss: 0.11489195\n",
            "Epoch: 38 - Step: 29 - MSE loss: 0.0044641574 - KL loss: 0.11286603\n",
            "Epoch: 38 - Step: 30 - MSE loss: 0.00437953 - KL loss: 0.111242145\n",
            "Epoch: 38 - Step: 31 - MSE loss: 0.004376318 - KL loss: 0.11339463\n",
            "Epoch: 38 - Step: 32 - MSE loss: 0.005385404 - KL loss: 0.12735406\n",
            "Epoch: 38 - Step: 33 - MSE loss: 0.005405454 - KL loss: 0.13094708\n",
            "Epoch: 38 - Step: 34 - MSE loss: 0.005734216 - KL loss: 0.13179243\n",
            "Epoch: 38 - Step: 35 - MSE loss: 0.005710166 - KL loss: 0.13844687\n",
            "Epoch: 38 - Step: 36 - MSE loss: 0.0056153485 - KL loss: 0.13991627\n",
            "Epoch: 38 - Step: 37 - MSE loss: 0.0060448702 - KL loss: 0.1489402\n",
            "Epoch: 38 - Step: 38 - MSE loss: 0.0072390023 - KL loss: 0.1639755\n",
            "Epoch: 38 - Step: 39 - MSE loss: 0.006485389 - KL loss: 0.16223928\n",
            "Epoch: 38 - Step: 40 - MSE loss: 0.0075289756 - KL loss: 0.16374813\n",
            "Epoch: 38 - Step: 41 - MSE loss: 0.0075382986 - KL loss: 0.16742148\n",
            "Epoch: 38 - Step: 42 - MSE loss: 0.0067087538 - KL loss: 0.15934268\n",
            "Epoch: 38 - Step: 43 - MSE loss: 0.006597504 - KL loss: 0.15711886\n",
            "Epoch: 38 - Step: 44 - MSE loss: 0.0066816458 - KL loss: 0.15301397\n",
            "Epoch: 38 - Step: 45 - MSE loss: 0.0060625877 - KL loss: 0.14895914\n",
            "Epoch: 38 - Step: 46 - MSE loss: 0.0066425074 - KL loss: 0.1663829\n",
            "Epoch: 38 - Step: 47 - MSE loss: 0.006950405 - KL loss: 0.17288674\n",
            "Epoch: 38 - Step: 48 - MSE loss: 0.006875454 - KL loss: 0.17083333\n",
            "Epoch: 38 - Step: 49 - MSE loss: 0.0076699653 - KL loss: 0.17384881\n",
            "Epoch: 38 - Step: 50 - MSE loss: 0.0072133304 - KL loss: 0.17556104\n",
            "Epoch: 38 - Step: 51 - MSE loss: 0.0078053884 - KL loss: 0.17413564\n",
            "Epoch: 38 - Step: 52 - MSE loss: 0.007764477 - KL loss: 0.1772874\n",
            "Epoch: 38 - Step: 53 - MSE loss: 0.0081408825 - KL loss: 0.17643707\n",
            "Epoch: 38 - Step: 54 - MSE loss: 0.0076484196 - KL loss: 0.17645244\n",
            "Epoch: 38 - Step: 55 - MSE loss: 0.008311357 - KL loss: 0.17952994\n",
            "Epoch: 38 - Step: 56 - MSE loss: 0.00756727 - KL loss: 0.17456877\n",
            "Epoch: 38 - Step: 57 - MSE loss: 0.007778588 - KL loss: 0.17507306\n",
            "Epoch: 38 - Step: 58 - MSE loss: 0.007544216 - KL loss: 0.166795\n",
            "Epoch: 38 - Step: 59 - MSE loss: 0.007817346 - KL loss: 0.17373532\n",
            "Epoch: 38 - Step: 60 - MSE loss: 0.008675328 - KL loss: 0.17225474\n",
            "Epoch: 38 - Step: 61 - MSE loss: 0.008902208 - KL loss: 0.1888864\n",
            "Epoch: 38 - Step: 62 - MSE loss: 0.008213157 - KL loss: 0.18347943\n",
            "Epoch: 38 - Step: 63 - MSE loss: 0.007769318 - KL loss: 0.18386823\n",
            "Epoch: 38 - Step: 64 - MSE loss: 0.008359469 - KL loss: 0.18653944\n",
            "Epoch: 38 - Step: 65 - MSE loss: 0.008261348 - KL loss: 0.17848603\n",
            "Epoch: 38 - Step: 66 - MSE loss: 0.0074788756 - KL loss: 0.1633461\n",
            "Epoch: 38 - Step: 67 - MSE loss: 0.0073215193 - KL loss: 0.1690985\n",
            "Epoch: 38 - Step: 68 - MSE loss: 0.00664811 - KL loss: 0.16051382\n",
            "Epoch: 38 - Step: 69 - MSE loss: 0.006732259 - KL loss: 0.14810629\n",
            "Epoch: 38 - Step: 70 - MSE loss: 0.00684567 - KL loss: 0.15921272\n",
            "Epoch: 38 - Step: 71 - MSE loss: 0.0054581575 - KL loss: 0.13443798\n",
            "Epoch: 38 - Step: 72 - MSE loss: 0.0050751506 - KL loss: 0.13538167\n",
            "Epoch: 38 - Step: 73 - MSE loss: 0.004874781 - KL loss: 0.12613282\n",
            "Epoch: 38 - Step: 74 - MSE loss: 0.0049176565 - KL loss: 0.1258717\n",
            "Epoch: 38 - Step: 75 - MSE loss: 0.0049528596 - KL loss: 0.12754452\n",
            "Epoch: 38 - Step: 76 - MSE loss: 0.0045411824 - KL loss: 0.1159586\n",
            "Epoch: 38 - Step: 77 - MSE loss: 0.0047377055 - KL loss: 0.12171845\n",
            "Epoch: 38 - Step: 78 - MSE loss: 0.004507329 - KL loss: 0.11125764\n",
            "Epoch: 38 - Step: 79 - MSE loss: 0.0048726797 - KL loss: 0.120041266\n",
            "Epoch: 38 - Step: 80 - MSE loss: 0.0046666856 - KL loss: 0.116512746\n",
            "Epoch: 38 - Step: 81 - MSE loss: 0.0049548494 - KL loss: 0.11659423\n",
            "Epoch: 38 - Step: 82 - MSE loss: 0.0053210133 - KL loss: 0.11755732\n",
            "Epoch: 38 - Step: 83 - MSE loss: 0.004981754 - KL loss: 0.12588009\n",
            "Epoch: 38 - Step: 84 - MSE loss: 0.0050458997 - KL loss: 0.124528304\n",
            "Epoch: 38 - Step: 85 - MSE loss: 0.0047921413 - KL loss: 0.12255834\n",
            "Epoch: 38 - Step: 86 - MSE loss: 0.0053169145 - KL loss: 0.12072219\n",
            "Epoch: 38 - Step: 87 - MSE loss: 0.0058717406 - KL loss: 0.124973625\n",
            "Epoch: 38 - Step: 88 - MSE loss: 0.005631748 - KL loss: 0.12166359\n",
            "Epoch: 38 - Step: 89 - MSE loss: 0.005962761 - KL loss: 0.13367563\n",
            "Epoch: 38 - Step: 90 - MSE loss: 0.00514343 - KL loss: 0.13091528\n",
            "Epoch: 38 - Step: 91 - MSE loss: 0.0048950976 - KL loss: 0.1275371\n",
            "Epoch: 38 - Step: 92 - MSE loss: 0.004378025 - KL loss: 0.11973837\n",
            "Epoch: 38 - Step: 93 - MSE loss: 0.0047398657 - KL loss: 0.12993312\n",
            "Epoch: 38 - Step: 94 - MSE loss: 0.0048577418 - KL loss: 0.12962353\n",
            "Epoch: 38 - Step: 95 - MSE loss: 0.004962362 - KL loss: 0.1301345\n",
            "Epoch: 38 - Step: 96 - MSE loss: 0.004591059 - KL loss: 0.1271466\n",
            "Epoch: 38 - Step: 97 - MSE loss: 0.004944039 - KL loss: 0.12384784\n",
            "Epoch: 38 - Step: 98 - MSE loss: 0.0050009787 - KL loss: 0.1293712\n",
            "Epoch: 38 - Step: 99 - MSE loss: 0.005066449 - KL loss: 0.1326095\n",
            "Epoch: 38 - Step: 100 - MSE loss: 0.00502671 - KL loss: 0.1248561\n",
            "Epoch: 38 - Step: 101 - MSE loss: 0.0050079697 - KL loss: 0.12665394\n",
            "Epoch: 38 - Step: 102 - MSE loss: 0.0050421283 - KL loss: 0.12432628\n",
            "Epoch: 38 - Step: 103 - MSE loss: 0.00446917 - KL loss: 0.12367888\n",
            "Epoch: 38 - Step: 104 - MSE loss: 0.005055016 - KL loss: 0.12706786\n",
            "Epoch: 38 - Step: 105 - MSE loss: 0.004752488 - KL loss: 0.12709975\n",
            "Epoch: 38 - Step: 106 - MSE loss: 0.0052701696 - KL loss: 0.14161685\n",
            "Epoch: 38 - Step: 107 - MSE loss: 0.006401036 - KL loss: 0.14816445\n",
            "Epoch: 38 - Step: 108 - MSE loss: 0.005953564 - KL loss: 0.15397528\n",
            "Epoch: 38 - Step: 109 - MSE loss: 0.006078522 - KL loss: 0.1514549\n",
            "Epoch: 38 - Step: 110 - MSE loss: 0.0064702225 - KL loss: 0.16097616\n",
            "Epoch: 38 - Step: 111 - MSE loss: 0.0070527196 - KL loss: 0.1705217\n",
            "Epoch: 38 - Step: 112 - MSE loss: 0.0073541254 - KL loss: 0.1632918\n",
            "Epoch: 38 - Step: 113 - MSE loss: 0.007625229 - KL loss: 0.17204328\n",
            "Epoch: 38 - Step: 114 - MSE loss: 0.0073866467 - KL loss: 0.17127898\n",
            "Epoch: 38 - Step: 115 - MSE loss: 0.0073252902 - KL loss: 0.1649301\n",
            "Epoch: 38 - Step: 116 - MSE loss: 0.0074708904 - KL loss: 0.1760093\n",
            "Epoch: 38 - Step: 117 - MSE loss: 0.00751693 - KL loss: 0.16977283\n",
            "Epoch: 38 - Step: 118 - MSE loss: 0.007859746 - KL loss: 0.17308804\n",
            "Epoch: 38 - Step: 119 - MSE loss: 0.007574175 - KL loss: 0.17255938\n",
            "Epoch: 38 - Step: 120 - MSE loss: 0.006820094 - KL loss: 0.16747041\n",
            "Epoch: 38 - Step: 121 - MSE loss: 0.0066808662 - KL loss: 0.1670267\n",
            "Epoch: 38 - Step: 122 - MSE loss: 0.0065461886 - KL loss: 0.1667867\n",
            "Epoch: 38 - Step: 123 - MSE loss: 0.0069727064 - KL loss: 0.16832697\n",
            "Epoch: 38 - Step: 124 - MSE loss: 0.0064029675 - KL loss: 0.17017476\n",
            "Epoch: 38 - Step: 125 - MSE loss: 0.007161493 - KL loss: 0.16905044\n",
            "Epoch: 38 - Step: 126 - MSE loss: 0.0076048463 - KL loss: 0.1823837\n",
            "Epoch: 38 - Step: 127 - MSE loss: 0.0067721303 - KL loss: 0.17564178\n",
            "Epoch: 38 - Step: 128 - MSE loss: 0.0071549 - KL loss: 0.17323023\n",
            "Epoch: 38 - Step: 129 - MSE loss: 0.0070277355 - KL loss: 0.16901305\n",
            "Epoch: 38 - Step: 130 - MSE loss: 0.007138261 - KL loss: 0.17544499\n",
            "Epoch: 38 - Step: 131 - MSE loss: 0.007358894 - KL loss: 0.17317884\n",
            "Epoch: 38 - Step: 132 - MSE loss: 0.008350781 - KL loss: 0.18630868\n",
            "Epoch: 38 - Step: 133 - MSE loss: 0.0078054373 - KL loss: 0.1727508\n",
            "Epoch: 38 - Step: 134 - MSE loss: 0.0077094096 - KL loss: 0.17899455\n",
            "Epoch: 38 - Step: 135 - MSE loss: 0.0081584 - KL loss: 0.16904818\n",
            "Epoch: 38 - Step: 136 - MSE loss: 0.008839789 - KL loss: 0.17679448\n",
            "Epoch: 38 - Step: 137 - MSE loss: 0.009188695 - KL loss: 0.16828829\n",
            "Epoch: 38 - Step: 138 - MSE loss: 0.009097402 - KL loss: 0.18061855\n",
            "Epoch: 38 - Step: 139 - MSE loss: 0.009728489 - KL loss: 0.17056844\n",
            "Epoch: 38 - Step: 140 - MSE loss: 0.008993681 - KL loss: 0.18660037\n",
            "Epoch: 38 - Step: 141 - MSE loss: 0.009073329 - KL loss: 0.17523336\n",
            "Epoch: 38 - Step: 142 - MSE loss: 0.008846305 - KL loss: 0.1751445\n",
            "Epoch: 38 - Step: 143 - MSE loss: 0.008898414 - KL loss: 0.17840683\n",
            "Epoch: 38 - Step: 144 - MSE loss: 0.009139804 - KL loss: 0.1857925\n",
            "Epoch:  39\n",
            "Epoch: 39 - Step: 0 - MSE loss: 0.003788786 - KL loss: 0.11976373\n",
            "Epoch: 39 - Step: 1 - MSE loss: 0.0044834027 - KL loss: 0.12279717\n",
            "Epoch: 39 - Step: 2 - MSE loss: 0.004075322 - KL loss: 0.12420266\n",
            "Epoch: 39 - Step: 3 - MSE loss: 0.004483988 - KL loss: 0.12653492\n",
            "Epoch: 39 - Step: 4 - MSE loss: 0.0045635086 - KL loss: 0.12361089\n",
            "Epoch: 39 - Step: 5 - MSE loss: 0.0049105417 - KL loss: 0.11986343\n",
            "Epoch: 39 - Step: 6 - MSE loss: 0.0049741385 - KL loss: 0.120995834\n",
            "Epoch: 39 - Step: 7 - MSE loss: 0.0047832737 - KL loss: 0.12749034\n",
            "Epoch: 39 - Step: 8 - MSE loss: 0.004431921 - KL loss: 0.12700877\n",
            "Epoch: 39 - Step: 9 - MSE loss: 0.0046663 - KL loss: 0.12205313\n",
            "Epoch: 39 - Step: 10 - MSE loss: 0.0049693654 - KL loss: 0.12238158\n",
            "Epoch: 39 - Step: 11 - MSE loss: 0.004876403 - KL loss: 0.123278655\n",
            "Epoch: 39 - Step: 12 - MSE loss: 0.0047119944 - KL loss: 0.1255572\n",
            "Epoch: 39 - Step: 13 - MSE loss: 0.00469445 - KL loss: 0.12572551\n",
            "Epoch: 39 - Step: 14 - MSE loss: 0.004549056 - KL loss: 0.12624803\n",
            "Epoch: 39 - Step: 15 - MSE loss: 0.0049063116 - KL loss: 0.12996203\n",
            "Epoch: 39 - Step: 16 - MSE loss: 0.0047040703 - KL loss: 0.12659924\n",
            "Epoch: 39 - Step: 17 - MSE loss: 0.004722768 - KL loss: 0.11846092\n",
            "Epoch: 39 - Step: 18 - MSE loss: 0.0044292496 - KL loss: 0.1134534\n",
            "Epoch: 39 - Step: 19 - MSE loss: 0.004413805 - KL loss: 0.1147601\n",
            "Epoch: 39 - Step: 20 - MSE loss: 0.0046821367 - KL loss: 0.119014084\n",
            "Epoch: 39 - Step: 21 - MSE loss: 0.0043613873 - KL loss: 0.113906235\n",
            "Epoch: 39 - Step: 22 - MSE loss: 0.004448375 - KL loss: 0.11294386\n",
            "Epoch: 39 - Step: 23 - MSE loss: 0.0046576243 - KL loss: 0.11687687\n",
            "Epoch: 39 - Step: 24 - MSE loss: 0.004610646 - KL loss: 0.120711386\n",
            "Epoch: 39 - Step: 25 - MSE loss: 0.004420231 - KL loss: 0.11410089\n",
            "Epoch: 39 - Step: 26 - MSE loss: 0.0045010494 - KL loss: 0.116766416\n",
            "Epoch: 39 - Step: 27 - MSE loss: 0.004721891 - KL loss: 0.11446062\n",
            "Epoch: 39 - Step: 28 - MSE loss: 0.0046004723 - KL loss: 0.115420654\n",
            "Epoch: 39 - Step: 29 - MSE loss: 0.0044240323 - KL loss: 0.107591584\n",
            "Epoch: 39 - Step: 30 - MSE loss: 0.0037835913 - KL loss: 0.10345554\n",
            "Epoch: 39 - Step: 31 - MSE loss: 0.004415134 - KL loss: 0.11304706\n",
            "Epoch: 39 - Step: 32 - MSE loss: 0.005306121 - KL loss: 0.12131923\n",
            "Epoch: 39 - Step: 33 - MSE loss: 0.0053761774 - KL loss: 0.13124473\n",
            "Epoch: 39 - Step: 34 - MSE loss: 0.0055383425 - KL loss: 0.1273423\n",
            "Epoch: 39 - Step: 35 - MSE loss: 0.005389845 - KL loss: 0.1321155\n",
            "Epoch: 39 - Step: 36 - MSE loss: 0.0054705534 - KL loss: 0.14451228\n",
            "Epoch: 39 - Step: 37 - MSE loss: 0.00638385 - KL loss: 0.14794989\n",
            "Epoch: 39 - Step: 38 - MSE loss: 0.0065744724 - KL loss: 0.16232316\n",
            "Epoch: 39 - Step: 39 - MSE loss: 0.0070809447 - KL loss: 0.16202457\n",
            "Epoch: 39 - Step: 40 - MSE loss: 0.007325504 - KL loss: 0.15510672\n",
            "Epoch: 39 - Step: 41 - MSE loss: 0.0071086586 - KL loss: 0.1594208\n",
            "Epoch: 39 - Step: 42 - MSE loss: 0.0067796484 - KL loss: 0.16639818\n",
            "Epoch: 39 - Step: 43 - MSE loss: 0.0065721665 - KL loss: 0.15326837\n",
            "Epoch: 39 - Step: 44 - MSE loss: 0.006644245 - KL loss: 0.16611049\n",
            "Epoch: 39 - Step: 45 - MSE loss: 0.006099762 - KL loss: 0.15634063\n",
            "Epoch: 39 - Step: 46 - MSE loss: 0.0067279744 - KL loss: 0.1611068\n",
            "Epoch: 39 - Step: 47 - MSE loss: 0.006653892 - KL loss: 0.16497736\n",
            "Epoch: 39 - Step: 48 - MSE loss: 0.006492485 - KL loss: 0.16718298\n",
            "Epoch: 39 - Step: 49 - MSE loss: 0.007790191 - KL loss: 0.16853556\n",
            "Epoch: 39 - Step: 50 - MSE loss: 0.007276565 - KL loss: 0.17660195\n",
            "Epoch: 39 - Step: 51 - MSE loss: 0.0069870073 - KL loss: 0.17172623\n",
            "Epoch: 39 - Step: 52 - MSE loss: 0.0071119186 - KL loss: 0.16774856\n",
            "Epoch: 39 - Step: 53 - MSE loss: 0.0071829446 - KL loss: 0.17625937\n",
            "Epoch: 39 - Step: 54 - MSE loss: 0.008120236 - KL loss: 0.18275872\n",
            "Epoch: 39 - Step: 55 - MSE loss: 0.007743379 - KL loss: 0.16937128\n",
            "Epoch: 39 - Step: 56 - MSE loss: 0.007616472 - KL loss: 0.16751057\n",
            "Epoch: 39 - Step: 57 - MSE loss: 0.007285163 - KL loss: 0.1716437\n",
            "Epoch: 39 - Step: 58 - MSE loss: 0.0076609044 - KL loss: 0.16702394\n",
            "Epoch: 39 - Step: 59 - MSE loss: 0.0077080093 - KL loss: 0.1793415\n",
            "Epoch: 39 - Step: 60 - MSE loss: 0.008434431 - KL loss: 0.17611437\n",
            "Epoch: 39 - Step: 61 - MSE loss: 0.007783349 - KL loss: 0.17586198\n",
            "Epoch: 39 - Step: 62 - MSE loss: 0.0080128005 - KL loss: 0.18446866\n",
            "Epoch: 39 - Step: 63 - MSE loss: 0.008693356 - KL loss: 0.1756591\n",
            "Epoch: 39 - Step: 64 - MSE loss: 0.0086577 - KL loss: 0.17702156\n",
            "Epoch: 39 - Step: 65 - MSE loss: 0.008324542 - KL loss: 0.17414106\n",
            "Epoch: 39 - Step: 66 - MSE loss: 0.0070584645 - KL loss: 0.15560415\n",
            "Epoch: 39 - Step: 67 - MSE loss: 0.0067127645 - KL loss: 0.15602815\n",
            "Epoch: 39 - Step: 68 - MSE loss: 0.006655024 - KL loss: 0.15936038\n",
            "Epoch: 39 - Step: 69 - MSE loss: 0.007050839 - KL loss: 0.15752077\n",
            "Epoch: 39 - Step: 70 - MSE loss: 0.0061102672 - KL loss: 0.14495312\n",
            "Epoch: 39 - Step: 71 - MSE loss: 0.006161731 - KL loss: 0.14220884\n",
            "Epoch: 39 - Step: 72 - MSE loss: 0.0049688183 - KL loss: 0.12598418\n",
            "Epoch: 39 - Step: 73 - MSE loss: 0.0049229446 - KL loss: 0.13151032\n",
            "Epoch: 39 - Step: 74 - MSE loss: 0.004804528 - KL loss: 0.12499874\n",
            "Epoch: 39 - Step: 75 - MSE loss: 0.005069476 - KL loss: 0.12642437\n",
            "Epoch: 39 - Step: 76 - MSE loss: 0.004302353 - KL loss: 0.1154535\n",
            "Epoch: 39 - Step: 77 - MSE loss: 0.0048334394 - KL loss: 0.118442684\n",
            "Epoch: 39 - Step: 78 - MSE loss: 0.0046161963 - KL loss: 0.117084846\n",
            "Epoch: 39 - Step: 79 - MSE loss: 0.004707603 - KL loss: 0.11203303\n",
            "Epoch: 39 - Step: 80 - MSE loss: 0.0048323474 - KL loss: 0.11630131\n",
            "Epoch: 39 - Step: 81 - MSE loss: 0.004646935 - KL loss: 0.11732212\n",
            "Epoch: 39 - Step: 82 - MSE loss: 0.0054580215 - KL loss: 0.12660915\n",
            "Epoch: 39 - Step: 83 - MSE loss: 0.0051747262 - KL loss: 0.12204608\n",
            "Epoch: 39 - Step: 84 - MSE loss: 0.0048738667 - KL loss: 0.121803656\n",
            "Epoch: 39 - Step: 85 - MSE loss: 0.005078497 - KL loss: 0.11885038\n",
            "Epoch: 39 - Step: 86 - MSE loss: 0.005194874 - KL loss: 0.12459835\n",
            "Epoch: 39 - Step: 87 - MSE loss: 0.0052164025 - KL loss: 0.12593395\n",
            "Epoch: 39 - Step: 88 - MSE loss: 0.0057082097 - KL loss: 0.12709227\n",
            "Epoch: 39 - Step: 89 - MSE loss: 0.005426787 - KL loss: 0.12726435\n",
            "Epoch: 39 - Step: 90 - MSE loss: 0.00544686 - KL loss: 0.12779948\n",
            "Epoch: 39 - Step: 91 - MSE loss: 0.0046714833 - KL loss: 0.12654161\n",
            "Epoch: 39 - Step: 92 - MSE loss: 0.0048041204 - KL loss: 0.12462356\n",
            "Epoch: 39 - Step: 93 - MSE loss: 0.0050195735 - KL loss: 0.12898633\n",
            "Epoch: 39 - Step: 94 - MSE loss: 0.0044986615 - KL loss: 0.12125714\n",
            "Epoch: 39 - Step: 95 - MSE loss: 0.004673963 - KL loss: 0.123995684\n",
            "Epoch: 39 - Step: 96 - MSE loss: 0.0047684032 - KL loss: 0.12622303\n",
            "Epoch: 39 - Step: 97 - MSE loss: 0.004510069 - KL loss: 0.12034712\n",
            "Epoch: 39 - Step: 98 - MSE loss: 0.004950861 - KL loss: 0.122948855\n",
            "Epoch: 39 - Step: 99 - MSE loss: 0.0046302737 - KL loss: 0.12697163\n",
            "Epoch: 39 - Step: 100 - MSE loss: 0.0048925136 - KL loss: 0.12721896\n",
            "Epoch: 39 - Step: 101 - MSE loss: 0.0048266207 - KL loss: 0.12918803\n",
            "Epoch: 39 - Step: 102 - MSE loss: 0.0049888417 - KL loss: 0.12764132\n",
            "Epoch: 39 - Step: 103 - MSE loss: 0.0045570154 - KL loss: 0.12353361\n",
            "Epoch: 39 - Step: 104 - MSE loss: 0.0042055915 - KL loss: 0.11927681\n",
            "Epoch: 39 - Step: 105 - MSE loss: 0.004815782 - KL loss: 0.1302673\n",
            "Epoch: 39 - Step: 106 - MSE loss: 0.005997499 - KL loss: 0.14153352\n",
            "Epoch: 39 - Step: 107 - MSE loss: 0.0059952666 - KL loss: 0.13967133\n",
            "Epoch: 39 - Step: 108 - MSE loss: 0.0059645097 - KL loss: 0.15038612\n",
            "Epoch: 39 - Step: 109 - MSE loss: 0.0064870543 - KL loss: 0.15912694\n",
            "Epoch: 39 - Step: 110 - MSE loss: 0.006708659 - KL loss: 0.16198295\n",
            "Epoch: 39 - Step: 111 - MSE loss: 0.0068127424 - KL loss: 0.15460056\n",
            "Epoch: 39 - Step: 112 - MSE loss: 0.0067302324 - KL loss: 0.16893193\n",
            "Epoch: 39 - Step: 113 - MSE loss: 0.006950415 - KL loss: 0.1657804\n",
            "Epoch: 39 - Step: 114 - MSE loss: 0.0077077574 - KL loss: 0.1693919\n",
            "Epoch: 39 - Step: 115 - MSE loss: 0.007760864 - KL loss: 0.16964655\n",
            "Epoch: 39 - Step: 116 - MSE loss: 0.0070137098 - KL loss: 0.17351721\n",
            "Epoch: 39 - Step: 117 - MSE loss: 0.007872024 - KL loss: 0.17411643\n",
            "Epoch: 39 - Step: 118 - MSE loss: 0.0070952023 - KL loss: 0.16803288\n",
            "Epoch: 39 - Step: 119 - MSE loss: 0.0073268334 - KL loss: 0.16642912\n",
            "Epoch: 39 - Step: 120 - MSE loss: 0.0069899787 - KL loss: 0.16240613\n",
            "Epoch: 39 - Step: 121 - MSE loss: 0.006019616 - KL loss: 0.16413529\n",
            "Epoch: 39 - Step: 122 - MSE loss: 0.0067953616 - KL loss: 0.1662671\n",
            "Epoch: 39 - Step: 123 - MSE loss: 0.006448151 - KL loss: 0.16604951\n",
            "Epoch: 39 - Step: 124 - MSE loss: 0.007078022 - KL loss: 0.16965617\n",
            "Epoch: 39 - Step: 125 - MSE loss: 0.006791392 - KL loss: 0.17738818\n",
            "Epoch: 39 - Step: 126 - MSE loss: 0.0067633153 - KL loss: 0.16623652\n",
            "Epoch: 39 - Step: 127 - MSE loss: 0.006913575 - KL loss: 0.17514016\n",
            "Epoch: 39 - Step: 128 - MSE loss: 0.0068681724 - KL loss: 0.1687431\n",
            "Epoch: 39 - Step: 129 - MSE loss: 0.0063237394 - KL loss: 0.16596703\n",
            "Epoch: 39 - Step: 130 - MSE loss: 0.0068429834 - KL loss: 0.16887963\n",
            "Epoch: 39 - Step: 131 - MSE loss: 0.007420569 - KL loss: 0.16946565\n",
            "Epoch: 39 - Step: 132 - MSE loss: 0.007828657 - KL loss: 0.18068948\n",
            "Epoch: 39 - Step: 133 - MSE loss: 0.0077168806 - KL loss: 0.17904335\n",
            "Epoch: 39 - Step: 134 - MSE loss: 0.008099241 - KL loss: 0.1811148\n",
            "Epoch: 39 - Step: 135 - MSE loss: 0.008245959 - KL loss: 0.16375493\n",
            "Epoch: 39 - Step: 136 - MSE loss: 0.009528682 - KL loss: 0.18067494\n",
            "Epoch: 39 - Step: 137 - MSE loss: 0.0114850225 - KL loss: 0.16628262\n",
            "Epoch: 39 - Step: 138 - MSE loss: 0.012500928 - KL loss: 0.18973947\n",
            "Epoch: 39 - Step: 139 - MSE loss: 0.013398524 - KL loss: 0.16939957\n",
            "Epoch: 39 - Step: 140 - MSE loss: 0.011348132 - KL loss: 0.16280463\n",
            "Epoch: 39 - Step: 141 - MSE loss: 0.010811365 - KL loss: 0.17608023\n",
            "Epoch: 39 - Step: 142 - MSE loss: 0.010885525 - KL loss: 0.19028595\n",
            "Epoch: 39 - Step: 143 - MSE loss: 0.010625453 - KL loss: 0.17755477\n",
            "Epoch: 39 - Step: 144 - MSE loss: 0.00872094 - KL loss: 0.1746582\n",
            "Epoch:  40\n",
            "Epoch: 40 - Step: 0 - MSE loss: 0.0038669317 - KL loss: 0.1188878\n",
            "Epoch: 40 - Step: 1 - MSE loss: 0.0045922804 - KL loss: 0.13411513\n",
            "Epoch: 40 - Step: 2 - MSE loss: 0.0042861598 - KL loss: 0.13111213\n",
            "Epoch: 40 - Step: 3 - MSE loss: 0.004072343 - KL loss: 0.123937406\n",
            "Epoch: 40 - Step: 4 - MSE loss: 0.004397217 - KL loss: 0.12167715\n",
            "Epoch: 40 - Step: 5 - MSE loss: 0.00431162 - KL loss: 0.11938631\n",
            "Epoch: 40 - Step: 6 - MSE loss: 0.0044853077 - KL loss: 0.12337424\n",
            "Epoch: 40 - Step: 7 - MSE loss: 0.0044573587 - KL loss: 0.12638554\n",
            "Epoch: 40 - Step: 8 - MSE loss: 0.0047330684 - KL loss: 0.12512834\n",
            "Epoch: 40 - Step: 9 - MSE loss: 0.0045666294 - KL loss: 0.1267911\n",
            "Epoch: 40 - Step: 10 - MSE loss: 0.004813061 - KL loss: 0.12600783\n",
            "Epoch: 40 - Step: 11 - MSE loss: 0.0048084324 - KL loss: 0.12855808\n",
            "Epoch: 40 - Step: 12 - MSE loss: 0.0048419475 - KL loss: 0.12724313\n",
            "Epoch: 40 - Step: 13 - MSE loss: 0.0049544103 - KL loss: 0.12629797\n",
            "Epoch: 40 - Step: 14 - MSE loss: 0.0050178957 - KL loss: 0.12527207\n",
            "Epoch: 40 - Step: 15 - MSE loss: 0.005004737 - KL loss: 0.12598403\n",
            "Epoch: 40 - Step: 16 - MSE loss: 0.004861282 - KL loss: 0.12693104\n",
            "Epoch: 40 - Step: 17 - MSE loss: 0.004791665 - KL loss: 0.12042931\n",
            "Epoch: 40 - Step: 18 - MSE loss: 0.0045514028 - KL loss: 0.11794\n",
            "Epoch: 40 - Step: 19 - MSE loss: 0.0040266993 - KL loss: 0.11271806\n",
            "Epoch: 40 - Step: 20 - MSE loss: 0.0042110174 - KL loss: 0.12121168\n",
            "Epoch: 40 - Step: 21 - MSE loss: 0.004556246 - KL loss: 0.11164166\n",
            "Epoch: 40 - Step: 22 - MSE loss: 0.004698269 - KL loss: 0.11243352\n",
            "Epoch: 40 - Step: 23 - MSE loss: 0.0045721973 - KL loss: 0.116243534\n",
            "Epoch: 40 - Step: 24 - MSE loss: 0.004497647 - KL loss: 0.11486143\n",
            "Epoch: 40 - Step: 25 - MSE loss: 0.00461618 - KL loss: 0.117982715\n",
            "Epoch: 40 - Step: 26 - MSE loss: 0.0045042164 - KL loss: 0.11326817\n",
            "Epoch: 40 - Step: 27 - MSE loss: 0.00447516 - KL loss: 0.10933716\n",
            "Epoch: 40 - Step: 28 - MSE loss: 0.004457788 - KL loss: 0.116130576\n",
            "Epoch: 40 - Step: 29 - MSE loss: 0.004129155 - KL loss: 0.111107044\n",
            "Epoch: 40 - Step: 30 - MSE loss: 0.0041847765 - KL loss: 0.109945156\n",
            "Epoch: 40 - Step: 31 - MSE loss: 0.0042134067 - KL loss: 0.10934153\n",
            "Epoch: 40 - Step: 32 - MSE loss: 0.005168925 - KL loss: 0.12253662\n",
            "Epoch: 40 - Step: 33 - MSE loss: 0.005128771 - KL loss: 0.124985985\n",
            "Epoch: 40 - Step: 34 - MSE loss: 0.005408484 - KL loss: 0.13260283\n",
            "Epoch: 40 - Step: 35 - MSE loss: 0.00535481 - KL loss: 0.13562678\n",
            "Epoch: 40 - Step: 36 - MSE loss: 0.0064768866 - KL loss: 0.15339151\n",
            "Epoch: 40 - Step: 37 - MSE loss: 0.0061350004 - KL loss: 0.14849144\n",
            "Epoch: 40 - Step: 38 - MSE loss: 0.0062563824 - KL loss: 0.14842054\n",
            "Epoch: 40 - Step: 39 - MSE loss: 0.007020954 - KL loss: 0.15914062\n",
            "Epoch: 40 - Step: 40 - MSE loss: 0.0072100083 - KL loss: 0.15096784\n",
            "Epoch: 40 - Step: 41 - MSE loss: 0.0072113927 - KL loss: 0.16192138\n",
            "Epoch: 40 - Step: 42 - MSE loss: 0.0066556293 - KL loss: 0.15285426\n",
            "Epoch: 40 - Step: 43 - MSE loss: 0.0061258595 - KL loss: 0.15700927\n",
            "Epoch: 40 - Step: 44 - MSE loss: 0.006398808 - KL loss: 0.15883519\n",
            "Epoch: 40 - Step: 45 - MSE loss: 0.006445859 - KL loss: 0.16159786\n",
            "Epoch: 40 - Step: 46 - MSE loss: 0.0065546636 - KL loss: 0.16453736\n",
            "Epoch: 40 - Step: 47 - MSE loss: 0.006573534 - KL loss: 0.16138001\n",
            "Epoch: 40 - Step: 48 - MSE loss: 0.0070430986 - KL loss: 0.17441322\n",
            "Epoch: 40 - Step: 49 - MSE loss: 0.0062388047 - KL loss: 0.16389763\n",
            "Epoch: 40 - Step: 50 - MSE loss: 0.006838724 - KL loss: 0.16229445\n",
            "Epoch: 40 - Step: 51 - MSE loss: 0.00745602 - KL loss: 0.17044276\n",
            "Epoch: 40 - Step: 52 - MSE loss: 0.007928406 - KL loss: 0.16850421\n",
            "Epoch: 40 - Step: 53 - MSE loss: 0.007594649 - KL loss: 0.17971769\n",
            "Epoch: 40 - Step: 54 - MSE loss: 0.007852447 - KL loss: 0.17523926\n",
            "Epoch: 40 - Step: 55 - MSE loss: 0.007164462 - KL loss: 0.16416466\n",
            "Epoch: 40 - Step: 56 - MSE loss: 0.0070752674 - KL loss: 0.16860437\n",
            "Epoch: 40 - Step: 57 - MSE loss: 0.007837254 - KL loss: 0.17443433\n",
            "Epoch: 40 - Step: 58 - MSE loss: 0.0075975056 - KL loss: 0.1718021\n",
            "Epoch: 40 - Step: 59 - MSE loss: 0.007794779 - KL loss: 0.18112914\n",
            "Epoch: 40 - Step: 60 - MSE loss: 0.008097545 - KL loss: 0.16943428\n",
            "Epoch: 40 - Step: 61 - MSE loss: 0.007869611 - KL loss: 0.17526597\n",
            "Epoch: 40 - Step: 62 - MSE loss: 0.0075158603 - KL loss: 0.17585884\n",
            "Epoch: 40 - Step: 63 - MSE loss: 0.008337109 - KL loss: 0.17998445\n",
            "Epoch: 40 - Step: 64 - MSE loss: 0.008787458 - KL loss: 0.17575234\n",
            "Epoch: 40 - Step: 65 - MSE loss: 0.008435753 - KL loss: 0.17792797\n",
            "Epoch: 40 - Step: 66 - MSE loss: 0.007830641 - KL loss: 0.16167298\n",
            "Epoch: 40 - Step: 67 - MSE loss: 0.006923908 - KL loss: 0.15725085\n",
            "Epoch: 40 - Step: 68 - MSE loss: 0.0073138676 - KL loss: 0.15889218\n",
            "Epoch: 40 - Step: 69 - MSE loss: 0.0068773497 - KL loss: 0.1558375\n",
            "Epoch: 40 - Step: 70 - MSE loss: 0.0060803234 - KL loss: 0.13767302\n",
            "Epoch: 40 - Step: 71 - MSE loss: 0.0054745064 - KL loss: 0.13675416\n",
            "Epoch: 40 - Step: 72 - MSE loss: 0.005129574 - KL loss: 0.12621567\n",
            "Epoch: 40 - Step: 73 - MSE loss: 0.0049621076 - KL loss: 0.12625332\n",
            "Epoch: 40 - Step: 74 - MSE loss: 0.004730799 - KL loss: 0.12495589\n",
            "Epoch: 40 - Step: 75 - MSE loss: 0.0046946346 - KL loss: 0.11674362\n",
            "Epoch: 40 - Step: 76 - MSE loss: 0.0045952424 - KL loss: 0.12045887\n",
            "Epoch: 40 - Step: 77 - MSE loss: 0.0048775957 - KL loss: 0.124106646\n",
            "Epoch: 40 - Step: 78 - MSE loss: 0.0046432507 - KL loss: 0.12037738\n",
            "Epoch: 40 - Step: 79 - MSE loss: 0.004601669 - KL loss: 0.11538037\n",
            "Epoch: 40 - Step: 80 - MSE loss: 0.004479036 - KL loss: 0.111909166\n",
            "Epoch: 40 - Step: 81 - MSE loss: 0.004739477 - KL loss: 0.122172326\n",
            "Epoch: 40 - Step: 82 - MSE loss: 0.0050008935 - KL loss: 0.12426308\n",
            "Epoch: 40 - Step: 83 - MSE loss: 0.004854395 - KL loss: 0.11758591\n",
            "Epoch: 40 - Step: 84 - MSE loss: 0.004785854 - KL loss: 0.11908024\n",
            "Epoch: 40 - Step: 85 - MSE loss: 0.004574251 - KL loss: 0.12215699\n",
            "Epoch: 40 - Step: 86 - MSE loss: 0.0048337425 - KL loss: 0.12545922\n",
            "Epoch: 40 - Step: 87 - MSE loss: 0.0046704593 - KL loss: 0.11657346\n",
            "Epoch: 40 - Step: 88 - MSE loss: 0.004850662 - KL loss: 0.12392339\n",
            "Epoch: 40 - Step: 89 - MSE loss: 0.0048771123 - KL loss: 0.12291223\n",
            "Epoch: 40 - Step: 90 - MSE loss: 0.0048026 - KL loss: 0.1265503\n",
            "Epoch: 40 - Step: 91 - MSE loss: 0.004608196 - KL loss: 0.12928978\n",
            "Epoch: 40 - Step: 92 - MSE loss: 0.0043789702 - KL loss: 0.12521036\n",
            "Epoch: 40 - Step: 93 - MSE loss: 0.0048032687 - KL loss: 0.13043885\n",
            "Epoch: 40 - Step: 94 - MSE loss: 0.00449321 - KL loss: 0.123828106\n",
            "Epoch: 40 - Step: 95 - MSE loss: 0.0047606593 - KL loss: 0.12909093\n",
            "Epoch: 40 - Step: 96 - MSE loss: 0.0047654896 - KL loss: 0.1241654\n",
            "Epoch: 40 - Step: 97 - MSE loss: 0.004774162 - KL loss: 0.12471078\n",
            "Epoch: 40 - Step: 98 - MSE loss: 0.004853143 - KL loss: 0.12566078\n",
            "Epoch: 40 - Step: 99 - MSE loss: 0.0051098443 - KL loss: 0.12972975\n",
            "Epoch: 40 - Step: 100 - MSE loss: 0.0044331397 - KL loss: 0.1264295\n",
            "Epoch: 40 - Step: 101 - MSE loss: 0.0044285185 - KL loss: 0.12201146\n",
            "Epoch: 40 - Step: 102 - MSE loss: 0.004246875 - KL loss: 0.1226856\n",
            "Epoch: 40 - Step: 103 - MSE loss: 0.004095271 - KL loss: 0.11915331\n",
            "Epoch: 40 - Step: 104 - MSE loss: 0.004411613 - KL loss: 0.12356877\n",
            "Epoch: 40 - Step: 105 - MSE loss: 0.004711803 - KL loss: 0.12870787\n",
            "Epoch: 40 - Step: 106 - MSE loss: 0.005122552 - KL loss: 0.13239193\n",
            "Epoch: 40 - Step: 107 - MSE loss: 0.005694386 - KL loss: 0.14257497\n",
            "Epoch: 40 - Step: 108 - MSE loss: 0.0054275654 - KL loss: 0.15092088\n",
            "Epoch: 40 - Step: 109 - MSE loss: 0.00574108 - KL loss: 0.15200087\n",
            "Epoch: 40 - Step: 110 - MSE loss: 0.0060951007 - KL loss: 0.14775676\n",
            "Epoch: 40 - Step: 111 - MSE loss: 0.00633187 - KL loss: 0.15688413\n",
            "Epoch: 40 - Step: 112 - MSE loss: 0.007573712 - KL loss: 0.16668713\n",
            "Epoch: 40 - Step: 113 - MSE loss: 0.0070563597 - KL loss: 0.16694558\n",
            "Epoch: 40 - Step: 114 - MSE loss: 0.0070030466 - KL loss: 0.16975263\n",
            "Epoch: 40 - Step: 115 - MSE loss: 0.0073194653 - KL loss: 0.16166788\n",
            "Epoch: 40 - Step: 116 - MSE loss: 0.0077569894 - KL loss: 0.17742673\n",
            "Epoch: 40 - Step: 117 - MSE loss: 0.0073650726 - KL loss: 0.16466317\n",
            "Epoch: 40 - Step: 118 - MSE loss: 0.008309578 - KL loss: 0.16734472\n",
            "Epoch: 40 - Step: 119 - MSE loss: 0.007588214 - KL loss: 0.162731\n",
            "Epoch: 40 - Step: 120 - MSE loss: 0.00718581 - KL loss: 0.17282403\n",
            "Epoch: 40 - Step: 121 - MSE loss: 0.006889717 - KL loss: 0.16884005\n",
            "Epoch: 40 - Step: 122 - MSE loss: 0.0069162697 - KL loss: 0.16762319\n",
            "Epoch: 40 - Step: 123 - MSE loss: 0.0064468547 - KL loss: 0.16733265\n",
            "Epoch: 40 - Step: 124 - MSE loss: 0.0069029466 - KL loss: 0.16389649\n",
            "Epoch: 40 - Step: 125 - MSE loss: 0.007211829 - KL loss: 0.17612013\n",
            "Epoch: 40 - Step: 126 - MSE loss: 0.006444823 - KL loss: 0.1662058\n",
            "Epoch: 40 - Step: 127 - MSE loss: 0.0063036936 - KL loss: 0.17153227\n",
            "Epoch: 40 - Step: 128 - MSE loss: 0.006857278 - KL loss: 0.17016427\n",
            "Epoch: 40 - Step: 129 - MSE loss: 0.0066205203 - KL loss: 0.1701598\n",
            "Epoch: 40 - Step: 130 - MSE loss: 0.0074206702 - KL loss: 0.17580074\n",
            "Epoch: 40 - Step: 131 - MSE loss: 0.0072867083 - KL loss: 0.17050973\n",
            "Epoch: 40 - Step: 132 - MSE loss: 0.007168926 - KL loss: 0.17240733\n",
            "Epoch: 40 - Step: 133 - MSE loss: 0.007901068 - KL loss: 0.17431292\n",
            "Epoch: 40 - Step: 134 - MSE loss: 0.0081341965 - KL loss: 0.17894801\n",
            "Epoch: 40 - Step: 135 - MSE loss: 0.009351668 - KL loss: 0.17131226\n",
            "Epoch: 40 - Step: 136 - MSE loss: 0.009273726 - KL loss: 0.17011061\n",
            "Epoch: 40 - Step: 137 - MSE loss: 0.009292656 - KL loss: 0.1702994\n",
            "Epoch: 40 - Step: 138 - MSE loss: 0.008287838 - KL loss: 0.17490332\n",
            "Epoch: 40 - Step: 139 - MSE loss: 0.008209881 - KL loss: 0.16918609\n",
            "Epoch: 40 - Step: 140 - MSE loss: 0.008192056 - KL loss: 0.17454422\n",
            "Epoch: 40 - Step: 141 - MSE loss: 0.008159243 - KL loss: 0.17721602\n",
            "Epoch: 40 - Step: 142 - MSE loss: 0.008454756 - KL loss: 0.17228052\n",
            "Epoch: 40 - Step: 143 - MSE loss: 0.008200977 - KL loss: 0.17461807\n",
            "Epoch: 40 - Step: 144 - MSE loss: 0.008372676 - KL loss: 0.1807773\n",
            "Epoch:  41\n",
            "Epoch: 41 - Step: 0 - MSE loss: 0.0036457088 - KL loss: 0.117853716\n",
            "Epoch: 41 - Step: 1 - MSE loss: 0.0040509445 - KL loss: 0.11920591\n",
            "Epoch: 41 - Step: 2 - MSE loss: 0.0039822673 - KL loss: 0.123952344\n",
            "Epoch: 41 - Step: 3 - MSE loss: 0.004098536 - KL loss: 0.1200382\n",
            "Epoch: 41 - Step: 4 - MSE loss: 0.0041840575 - KL loss: 0.116916716\n",
            "Epoch: 41 - Step: 5 - MSE loss: 0.004080838 - KL loss: 0.121114716\n",
            "Epoch: 41 - Step: 6 - MSE loss: 0.0042354516 - KL loss: 0.124506615\n",
            "Epoch: 41 - Step: 7 - MSE loss: 0.00485061 - KL loss: 0.1270451\n",
            "Epoch: 41 - Step: 8 - MSE loss: 0.004696624 - KL loss: 0.12318446\n",
            "Epoch: 41 - Step: 9 - MSE loss: 0.0046124966 - KL loss: 0.12489637\n",
            "Epoch: 41 - Step: 10 - MSE loss: 0.0048295646 - KL loss: 0.124445595\n",
            "Epoch: 41 - Step: 11 - MSE loss: 0.004446928 - KL loss: 0.121329136\n",
            "Epoch: 41 - Step: 12 - MSE loss: 0.004342895 - KL loss: 0.121225014\n",
            "Epoch: 41 - Step: 13 - MSE loss: 0.0046821996 - KL loss: 0.12407623\n",
            "Epoch: 41 - Step: 14 - MSE loss: 0.005170542 - KL loss: 0.123988934\n",
            "Epoch: 41 - Step: 15 - MSE loss: 0.0048402078 - KL loss: 0.12430486\n",
            "Epoch: 41 - Step: 16 - MSE loss: 0.004895296 - KL loss: 0.1225043\n",
            "Epoch: 41 - Step: 17 - MSE loss: 0.0047681415 - KL loss: 0.12505183\n",
            "Epoch: 41 - Step: 18 - MSE loss: 0.0045317416 - KL loss: 0.111062326\n",
            "Epoch: 41 - Step: 19 - MSE loss: 0.00463954 - KL loss: 0.11595549\n",
            "Epoch: 41 - Step: 20 - MSE loss: 0.004696934 - KL loss: 0.11519905\n",
            "Epoch: 41 - Step: 21 - MSE loss: 0.0043869033 - KL loss: 0.111917734\n",
            "Epoch: 41 - Step: 22 - MSE loss: 0.0046731946 - KL loss: 0.118700266\n",
            "Epoch: 41 - Step: 23 - MSE loss: 0.0046768878 - KL loss: 0.11158726\n",
            "Epoch: 41 - Step: 24 - MSE loss: 0.004499996 - KL loss: 0.12036007\n",
            "Epoch: 41 - Step: 25 - MSE loss: 0.004491374 - KL loss: 0.117946595\n",
            "Epoch: 41 - Step: 26 - MSE loss: 0.0042113303 - KL loss: 0.11446023\n",
            "Epoch: 41 - Step: 27 - MSE loss: 0.0045720045 - KL loss: 0.11168569\n",
            "Epoch: 41 - Step: 28 - MSE loss: 0.0044641285 - KL loss: 0.11192624\n",
            "Epoch: 41 - Step: 29 - MSE loss: 0.004452813 - KL loss: 0.11214628\n",
            "Epoch: 41 - Step: 30 - MSE loss: 0.004149912 - KL loss: 0.10762024\n",
            "Epoch: 41 - Step: 31 - MSE loss: 0.004336273 - KL loss: 0.109232605\n",
            "Epoch: 41 - Step: 32 - MSE loss: 0.0046709497 - KL loss: 0.115108795\n",
            "Epoch: 41 - Step: 33 - MSE loss: 0.0051632035 - KL loss: 0.11980572\n",
            "Epoch: 41 - Step: 34 - MSE loss: 0.004929649 - KL loss: 0.12317985\n",
            "Epoch: 41 - Step: 35 - MSE loss: 0.0054114168 - KL loss: 0.14000875\n",
            "Epoch: 41 - Step: 36 - MSE loss: 0.00530497 - KL loss: 0.13617957\n",
            "Epoch: 41 - Step: 37 - MSE loss: 0.005994961 - KL loss: 0.14680639\n",
            "Epoch: 41 - Step: 38 - MSE loss: 0.006922627 - KL loss: 0.15513429\n",
            "Epoch: 41 - Step: 39 - MSE loss: 0.006484509 - KL loss: 0.15754215\n",
            "Epoch: 41 - Step: 40 - MSE loss: 0.0073720063 - KL loss: 0.157635\n",
            "Epoch: 41 - Step: 41 - MSE loss: 0.007181583 - KL loss: 0.15525925\n",
            "Epoch: 41 - Step: 42 - MSE loss: 0.006703835 - KL loss: 0.16658288\n",
            "Epoch: 41 - Step: 43 - MSE loss: 0.0064167045 - KL loss: 0.15096837\n",
            "Epoch: 41 - Step: 44 - MSE loss: 0.0057423753 - KL loss: 0.15343767\n",
            "Epoch: 41 - Step: 45 - MSE loss: 0.0063594053 - KL loss: 0.16262469\n",
            "Epoch: 41 - Step: 46 - MSE loss: 0.007049391 - KL loss: 0.16116992\n",
            "Epoch: 41 - Step: 47 - MSE loss: 0.0064635123 - KL loss: 0.16503462\n",
            "Epoch: 41 - Step: 48 - MSE loss: 0.00704802 - KL loss: 0.16562009\n",
            "Epoch: 41 - Step: 49 - MSE loss: 0.006263342 - KL loss: 0.1651968\n",
            "Epoch: 41 - Step: 50 - MSE loss: 0.0063347644 - KL loss: 0.16111979\n",
            "Epoch: 41 - Step: 51 - MSE loss: 0.007083718 - KL loss: 0.17504245\n",
            "Epoch: 41 - Step: 52 - MSE loss: 0.007256527 - KL loss: 0.16183858\n",
            "Epoch: 41 - Step: 53 - MSE loss: 0.0073798 - KL loss: 0.1690472\n",
            "Epoch: 41 - Step: 54 - MSE loss: 0.0070091845 - KL loss: 0.16926283\n",
            "Epoch: 41 - Step: 55 - MSE loss: 0.007680714 - KL loss: 0.16434255\n",
            "Epoch: 41 - Step: 56 - MSE loss: 0.006948002 - KL loss: 0.17079067\n",
            "Epoch: 41 - Step: 57 - MSE loss: 0.007023556 - KL loss: 0.16940182\n",
            "Epoch: 41 - Step: 58 - MSE loss: 0.007493165 - KL loss: 0.16534072\n",
            "Epoch: 41 - Step: 59 - MSE loss: 0.0068685464 - KL loss: 0.16787504\n",
            "Epoch: 41 - Step: 60 - MSE loss: 0.007912492 - KL loss: 0.17684047\n",
            "Epoch: 41 - Step: 61 - MSE loss: 0.0074476893 - KL loss: 0.1742364\n",
            "Epoch: 41 - Step: 62 - MSE loss: 0.00783318 - KL loss: 0.18018234\n",
            "Epoch: 41 - Step: 63 - MSE loss: 0.007793362 - KL loss: 0.17468943\n",
            "Epoch: 41 - Step: 64 - MSE loss: 0.008472493 - KL loss: 0.17851266\n",
            "Epoch: 41 - Step: 65 - MSE loss: 0.007924783 - KL loss: 0.18342066\n",
            "Epoch: 41 - Step: 66 - MSE loss: 0.006952531 - KL loss: 0.16836\n",
            "Epoch: 41 - Step: 67 - MSE loss: 0.006936059 - KL loss: 0.15449584\n",
            "Epoch: 41 - Step: 68 - MSE loss: 0.006474903 - KL loss: 0.14486751\n",
            "Epoch: 41 - Step: 69 - MSE loss: 0.0065120067 - KL loss: 0.14547332\n",
            "Epoch: 41 - Step: 70 - MSE loss: 0.0059123575 - KL loss: 0.15005134\n",
            "Epoch: 41 - Step: 71 - MSE loss: 0.005594928 - KL loss: 0.13552125\n",
            "Epoch: 41 - Step: 72 - MSE loss: 0.005011703 - KL loss: 0.12521252\n",
            "Epoch: 41 - Step: 73 - MSE loss: 0.005029162 - KL loss: 0.1294569\n",
            "Epoch: 41 - Step: 74 - MSE loss: 0.005064888 - KL loss: 0.12608695\n",
            "Epoch: 41 - Step: 75 - MSE loss: 0.005080558 - KL loss: 0.12584206\n",
            "Epoch: 41 - Step: 76 - MSE loss: 0.0045735054 - KL loss: 0.11506492\n",
            "Epoch: 41 - Step: 77 - MSE loss: 0.004728027 - KL loss: 0.11891681\n",
            "Epoch: 41 - Step: 78 - MSE loss: 0.0045044073 - KL loss: 0.10911502\n",
            "Epoch: 41 - Step: 79 - MSE loss: 0.004308533 - KL loss: 0.11175741\n",
            "Epoch: 41 - Step: 80 - MSE loss: 0.0043488746 - KL loss: 0.11563988\n",
            "Epoch: 41 - Step: 81 - MSE loss: 0.004345925 - KL loss: 0.11451311\n",
            "Epoch: 41 - Step: 82 - MSE loss: 0.0049878582 - KL loss: 0.11772008\n",
            "Epoch: 41 - Step: 83 - MSE loss: 0.004618718 - KL loss: 0.12091953\n",
            "Epoch: 41 - Step: 84 - MSE loss: 0.0045201653 - KL loss: 0.120782346\n",
            "Epoch: 41 - Step: 85 - MSE loss: 0.0046395934 - KL loss: 0.11957663\n",
            "Epoch: 41 - Step: 86 - MSE loss: 0.0050486233 - KL loss: 0.119264506\n",
            "Epoch: 41 - Step: 87 - MSE loss: 0.0046841525 - KL loss: 0.12012417\n",
            "Epoch: 41 - Step: 88 - MSE loss: 0.0047740596 - KL loss: 0.123298876\n",
            "Epoch: 41 - Step: 89 - MSE loss: 0.004675579 - KL loss: 0.11617871\n",
            "Epoch: 41 - Step: 90 - MSE loss: 0.005317205 - KL loss: 0.12996344\n",
            "Epoch: 41 - Step: 91 - MSE loss: 0.0046882657 - KL loss: 0.12569126\n",
            "Epoch: 41 - Step: 92 - MSE loss: 0.0047036195 - KL loss: 0.12750636\n",
            "Epoch: 41 - Step: 93 - MSE loss: 0.004696265 - KL loss: 0.12858671\n",
            "Epoch: 41 - Step: 94 - MSE loss: 0.004553872 - KL loss: 0.12594864\n",
            "Epoch: 41 - Step: 95 - MSE loss: 0.004752731 - KL loss: 0.1208932\n",
            "Epoch: 41 - Step: 96 - MSE loss: 0.004556355 - KL loss: 0.1185763\n",
            "Epoch: 41 - Step: 97 - MSE loss: 0.0041161715 - KL loss: 0.119896725\n",
            "Epoch: 41 - Step: 98 - MSE loss: 0.0044795135 - KL loss: 0.12605679\n",
            "Epoch: 41 - Step: 99 - MSE loss: 0.0047540884 - KL loss: 0.122373566\n",
            "Epoch: 41 - Step: 100 - MSE loss: 0.0043108715 - KL loss: 0.12867388\n",
            "Epoch: 41 - Step: 101 - MSE loss: 0.0047011753 - KL loss: 0.124674335\n",
            "Epoch: 41 - Step: 102 - MSE loss: 0.0045631053 - KL loss: 0.124740705\n",
            "Epoch: 41 - Step: 103 - MSE loss: 0.00379631 - KL loss: 0.11505691\n",
            "Epoch: 41 - Step: 104 - MSE loss: 0.004010362 - KL loss: 0.117357746\n",
            "Epoch: 41 - Step: 105 - MSE loss: 0.0045060003 - KL loss: 0.12456481\n",
            "Epoch: 41 - Step: 106 - MSE loss: 0.005414142 - KL loss: 0.13836631\n",
            "Epoch: 41 - Step: 107 - MSE loss: 0.0053127385 - KL loss: 0.13805091\n",
            "Epoch: 41 - Step: 108 - MSE loss: 0.0056469813 - KL loss: 0.14794576\n",
            "Epoch: 41 - Step: 109 - MSE loss: 0.0057512224 - KL loss: 0.14937225\n",
            "Epoch: 41 - Step: 110 - MSE loss: 0.0058933417 - KL loss: 0.15062836\n",
            "Epoch: 41 - Step: 111 - MSE loss: 0.0062979795 - KL loss: 0.14767432\n",
            "Epoch: 41 - Step: 112 - MSE loss: 0.007385442 - KL loss: 0.1781916\n",
            "Epoch: 41 - Step: 113 - MSE loss: 0.0061958157 - KL loss: 0.15862106\n",
            "Epoch: 41 - Step: 114 - MSE loss: 0.0069508837 - KL loss: 0.16509011\n",
            "Epoch: 41 - Step: 115 - MSE loss: 0.007531204 - KL loss: 0.16431743\n",
            "Epoch: 41 - Step: 116 - MSE loss: 0.00829193 - KL loss: 0.1771818\n",
            "Epoch: 41 - Step: 117 - MSE loss: 0.009046998 - KL loss: 0.15510252\n",
            "Epoch: 41 - Step: 118 - MSE loss: 0.011199201 - KL loss: 0.18140532\n",
            "Epoch: 41 - Step: 119 - MSE loss: 0.013169363 - KL loss: 0.15556121\n",
            "Epoch: 41 - Step: 120 - MSE loss: 0.0115160905 - KL loss: 0.14763512\n",
            "Epoch: 41 - Step: 121 - MSE loss: 0.008441619 - KL loss: 0.15739676\n",
            "Epoch: 41 - Step: 122 - MSE loss: 0.007047523 - KL loss: 0.17054427\n",
            "Epoch: 41 - Step: 123 - MSE loss: 0.0076862015 - KL loss: 0.18146133\n",
            "Epoch: 41 - Step: 124 - MSE loss: 0.0075533823 - KL loss: 0.16805689\n",
            "Epoch: 41 - Step: 125 - MSE loss: 0.0073832623 - KL loss: 0.17774612\n",
            "Epoch: 41 - Step: 126 - MSE loss: 0.0061660265 - KL loss: 0.17133561\n",
            "Epoch: 41 - Step: 127 - MSE loss: 0.0065684184 - KL loss: 0.16931719\n",
            "Epoch: 41 - Step: 128 - MSE loss: 0.0064672823 - KL loss: 0.1666426\n",
            "Epoch: 41 - Step: 129 - MSE loss: 0.006882215 - KL loss: 0.17007533\n",
            "Epoch: 41 - Step: 130 - MSE loss: 0.006864626 - KL loss: 0.17078239\n",
            "Epoch: 41 - Step: 131 - MSE loss: 0.0071312436 - KL loss: 0.17517868\n",
            "Epoch: 41 - Step: 132 - MSE loss: 0.007543955 - KL loss: 0.17747898\n",
            "Epoch: 41 - Step: 133 - MSE loss: 0.0075062946 - KL loss: 0.17648506\n",
            "Epoch: 41 - Step: 134 - MSE loss: 0.007984548 - KL loss: 0.17500743\n",
            "Epoch: 41 - Step: 135 - MSE loss: 0.007673263 - KL loss: 0.16891935\n",
            "Epoch: 41 - Step: 136 - MSE loss: 0.00767733 - KL loss: 0.17647776\n",
            "Epoch: 41 - Step: 137 - MSE loss: 0.008820864 - KL loss: 0.17643219\n",
            "Epoch: 41 - Step: 138 - MSE loss: 0.008129646 - KL loss: 0.17014585\n",
            "Epoch: 41 - Step: 139 - MSE loss: 0.007927764 - KL loss: 0.17823161\n",
            "Epoch: 41 - Step: 140 - MSE loss: 0.008237154 - KL loss: 0.17317691\n",
            "Epoch: 41 - Step: 141 - MSE loss: 0.008072529 - KL loss: 0.17142974\n",
            "Epoch: 41 - Step: 142 - MSE loss: 0.008225543 - KL loss: 0.17487961\n",
            "Epoch: 41 - Step: 143 - MSE loss: 0.007785318 - KL loss: 0.16591063\n",
            "Epoch: 41 - Step: 144 - MSE loss: 0.008382656 - KL loss: 0.177701\n",
            "Epoch:  42\n",
            "Epoch: 42 - Step: 0 - MSE loss: 0.0038917467 - KL loss: 0.12009017\n",
            "Epoch: 42 - Step: 1 - MSE loss: 0.0039681033 - KL loss: 0.11981452\n",
            "Epoch: 42 - Step: 2 - MSE loss: 0.0041150153 - KL loss: 0.12296934\n",
            "Epoch: 42 - Step: 3 - MSE loss: 0.0043594143 - KL loss: 0.11783377\n",
            "Epoch: 42 - Step: 4 - MSE loss: 0.0044480474 - KL loss: 0.122940764\n",
            "Epoch: 42 - Step: 5 - MSE loss: 0.004412726 - KL loss: 0.11858934\n",
            "Epoch: 42 - Step: 6 - MSE loss: 0.0043400875 - KL loss: 0.11587471\n",
            "Epoch: 42 - Step: 7 - MSE loss: 0.0047113597 - KL loss: 0.123492345\n",
            "Epoch: 42 - Step: 8 - MSE loss: 0.004775806 - KL loss: 0.12591642\n",
            "Epoch: 42 - Step: 9 - MSE loss: 0.0051199202 - KL loss: 0.12635176\n",
            "Epoch: 42 - Step: 10 - MSE loss: 0.004832398 - KL loss: 0.12419014\n",
            "Epoch: 42 - Step: 11 - MSE loss: 0.0046361783 - KL loss: 0.12063952\n",
            "Epoch: 42 - Step: 12 - MSE loss: 0.0047841654 - KL loss: 0.12117317\n",
            "Epoch: 42 - Step: 13 - MSE loss: 0.0044805417 - KL loss: 0.123577446\n",
            "Epoch: 42 - Step: 14 - MSE loss: 0.0048606456 - KL loss: 0.12796791\n",
            "Epoch: 42 - Step: 15 - MSE loss: 0.004686432 - KL loss: 0.1190552\n",
            "Epoch: 42 - Step: 16 - MSE loss: 0.0051179053 - KL loss: 0.12519355\n",
            "Epoch: 42 - Step: 17 - MSE loss: 0.0042325766 - KL loss: 0.11994906\n",
            "Epoch: 42 - Step: 18 - MSE loss: 0.0041606943 - KL loss: 0.11388187\n",
            "Epoch: 42 - Step: 19 - MSE loss: 0.0039406773 - KL loss: 0.11250469\n",
            "Epoch: 42 - Step: 20 - MSE loss: 0.00403109 - KL loss: 0.10828694\n",
            "Epoch: 42 - Step: 21 - MSE loss: 0.004361086 - KL loss: 0.113202885\n",
            "Epoch: 42 - Step: 22 - MSE loss: 0.004054148 - KL loss: 0.11278749\n",
            "Epoch: 42 - Step: 23 - MSE loss: 0.004644983 - KL loss: 0.112189665\n",
            "Epoch: 42 - Step: 24 - MSE loss: 0.004157443 - KL loss: 0.11053382\n",
            "Epoch: 42 - Step: 25 - MSE loss: 0.0042532147 - KL loss: 0.11429627\n",
            "Epoch: 42 - Step: 26 - MSE loss: 0.00411969 - KL loss: 0.11116102\n",
            "Epoch: 42 - Step: 27 - MSE loss: 0.004380667 - KL loss: 0.11254601\n",
            "Epoch: 42 - Step: 28 - MSE loss: 0.004453457 - KL loss: 0.11292667\n",
            "Epoch: 42 - Step: 29 - MSE loss: 0.0042810226 - KL loss: 0.110717624\n",
            "Epoch: 42 - Step: 30 - MSE loss: 0.003704537 - KL loss: 0.10428986\n",
            "Epoch: 42 - Step: 31 - MSE loss: 0.004181926 - KL loss: 0.11440114\n",
            "Epoch: 42 - Step: 32 - MSE loss: 0.0047652484 - KL loss: 0.11593742\n",
            "Epoch: 42 - Step: 33 - MSE loss: 0.0054910486 - KL loss: 0.12762666\n",
            "Epoch: 42 - Step: 34 - MSE loss: 0.005482271 - KL loss: 0.12994826\n",
            "Epoch: 42 - Step: 35 - MSE loss: 0.0053823297 - KL loss: 0.13505211\n",
            "Epoch: 42 - Step: 36 - MSE loss: 0.0053792726 - KL loss: 0.13704933\n",
            "Epoch: 42 - Step: 37 - MSE loss: 0.0057768724 - KL loss: 0.14935869\n",
            "Epoch: 42 - Step: 38 - MSE loss: 0.006501284 - KL loss: 0.1551851\n",
            "Epoch: 42 - Step: 39 - MSE loss: 0.0072386093 - KL loss: 0.15337875\n",
            "Epoch: 42 - Step: 40 - MSE loss: 0.006529389 - KL loss: 0.15937918\n",
            "Epoch: 42 - Step: 41 - MSE loss: 0.0074966345 - KL loss: 0.16455188\n",
            "Epoch: 42 - Step: 42 - MSE loss: 0.0059745666 - KL loss: 0.15347394\n",
            "Epoch: 42 - Step: 43 - MSE loss: 0.0065394877 - KL loss: 0.15195417\n",
            "Epoch: 42 - Step: 44 - MSE loss: 0.0061000525 - KL loss: 0.15219699\n",
            "Epoch: 42 - Step: 45 - MSE loss: 0.0062644393 - KL loss: 0.16088943\n",
            "Epoch: 42 - Step: 46 - MSE loss: 0.0069596767 - KL loss: 0.16389805\n",
            "Epoch: 42 - Step: 47 - MSE loss: 0.006685281 - KL loss: 0.16748002\n",
            "Epoch: 42 - Step: 48 - MSE loss: 0.006369633 - KL loss: 0.16302937\n",
            "Epoch: 42 - Step: 49 - MSE loss: 0.00621517 - KL loss: 0.16496375\n",
            "Epoch: 42 - Step: 50 - MSE loss: 0.0072092735 - KL loss: 0.1670411\n",
            "Epoch: 42 - Step: 51 - MSE loss: 0.006367153 - KL loss: 0.16787419\n",
            "Epoch: 42 - Step: 52 - MSE loss: 0.0074706823 - KL loss: 0.17258602\n",
            "Epoch: 42 - Step: 53 - MSE loss: 0.007171056 - KL loss: 0.16241145\n",
            "Epoch: 42 - Step: 54 - MSE loss: 0.007588314 - KL loss: 0.16191469\n",
            "Epoch: 42 - Step: 55 - MSE loss: 0.0067195874 - KL loss: 0.16313192\n",
            "Epoch: 42 - Step: 56 - MSE loss: 0.007234869 - KL loss: 0.16527975\n",
            "Epoch: 42 - Step: 57 - MSE loss: 0.0070047514 - KL loss: 0.1652075\n",
            "Epoch: 42 - Step: 58 - MSE loss: 0.0072661303 - KL loss: 0.1598223\n",
            "Epoch: 42 - Step: 59 - MSE loss: 0.007624008 - KL loss: 0.16650823\n",
            "Epoch: 42 - Step: 60 - MSE loss: 0.007795151 - KL loss: 0.17244032\n",
            "Epoch: 42 - Step: 61 - MSE loss: 0.0074514295 - KL loss: 0.1661585\n",
            "Epoch: 42 - Step: 62 - MSE loss: 0.0071752444 - KL loss: 0.1658432\n",
            "Epoch: 42 - Step: 63 - MSE loss: 0.0075076222 - KL loss: 0.16401637\n",
            "Epoch: 42 - Step: 64 - MSE loss: 0.008262194 - KL loss: 0.18871057\n",
            "Epoch: 42 - Step: 65 - MSE loss: 0.008291666 - KL loss: 0.16415572\n",
            "Epoch: 42 - Step: 66 - MSE loss: 0.0074252733 - KL loss: 0.17069049\n",
            "Epoch: 42 - Step: 67 - MSE loss: 0.007293405 - KL loss: 0.15575668\n",
            "Epoch: 42 - Step: 68 - MSE loss: 0.006971463 - KL loss: 0.16280492\n",
            "Epoch: 42 - Step: 69 - MSE loss: 0.0065239235 - KL loss: 0.15368362\n",
            "Epoch: 42 - Step: 70 - MSE loss: 0.005531643 - KL loss: 0.13735217\n",
            "Epoch: 42 - Step: 71 - MSE loss: 0.0053891498 - KL loss: 0.1367375\n",
            "Epoch: 42 - Step: 72 - MSE loss: 0.004774567 - KL loss: 0.13045219\n",
            "Epoch: 42 - Step: 73 - MSE loss: 0.004645089 - KL loss: 0.12536484\n",
            "Epoch: 42 - Step: 74 - MSE loss: 0.0052535986 - KL loss: 0.12882438\n",
            "Epoch: 42 - Step: 75 - MSE loss: 0.0041860943 - KL loss: 0.11388478\n",
            "Epoch: 42 - Step: 76 - MSE loss: 0.004521847 - KL loss: 0.11740656\n",
            "Epoch: 42 - Step: 77 - MSE loss: 0.0043002306 - KL loss: 0.11345439\n",
            "Epoch: 42 - Step: 78 - MSE loss: 0.004797719 - KL loss: 0.1178415\n",
            "Epoch: 42 - Step: 79 - MSE loss: 0.004540699 - KL loss: 0.114195906\n",
            "Epoch: 42 - Step: 80 - MSE loss: 0.0046087517 - KL loss: 0.11714901\n",
            "Epoch: 42 - Step: 81 - MSE loss: 0.0043358817 - KL loss: 0.118898556\n",
            "Epoch: 42 - Step: 82 - MSE loss: 0.0048299045 - KL loss: 0.11966739\n",
            "Epoch: 42 - Step: 83 - MSE loss: 0.004374132 - KL loss: 0.108889356\n",
            "Epoch: 42 - Step: 84 - MSE loss: 0.004707499 - KL loss: 0.11887886\n",
            "Epoch: 42 - Step: 85 - MSE loss: 0.004645169 - KL loss: 0.124068126\n",
            "Epoch: 42 - Step: 86 - MSE loss: 0.0051601124 - KL loss: 0.12287402\n",
            "Epoch: 42 - Step: 87 - MSE loss: 0.005141288 - KL loss: 0.12595493\n",
            "Epoch: 42 - Step: 88 - MSE loss: 0.0047475384 - KL loss: 0.124092646\n",
            "Epoch: 42 - Step: 89 - MSE loss: 0.004986563 - KL loss: 0.12539491\n",
            "Epoch: 42 - Step: 90 - MSE loss: 0.004367894 - KL loss: 0.12265651\n",
            "Epoch: 42 - Step: 91 - MSE loss: 0.004352414 - KL loss: 0.12504742\n",
            "Epoch: 42 - Step: 92 - MSE loss: 0.0041973446 - KL loss: 0.11822337\n",
            "Epoch: 42 - Step: 93 - MSE loss: 0.003978173 - KL loss: 0.124353126\n",
            "Epoch: 42 - Step: 94 - MSE loss: 0.0046097874 - KL loss: 0.1261172\n",
            "Epoch: 42 - Step: 95 - MSE loss: 0.004540405 - KL loss: 0.12553036\n",
            "Epoch: 42 - Step: 96 - MSE loss: 0.004481496 - KL loss: 0.1221958\n",
            "Epoch: 42 - Step: 97 - MSE loss: 0.00450657 - KL loss: 0.1207721\n",
            "Epoch: 42 - Step: 98 - MSE loss: 0.004773022 - KL loss: 0.123795085\n",
            "Epoch: 42 - Step: 99 - MSE loss: 0.004869921 - KL loss: 0.125487\n",
            "Epoch: 42 - Step: 100 - MSE loss: 0.0048255366 - KL loss: 0.12798065\n",
            "Epoch: 42 - Step: 101 - MSE loss: 0.004386593 - KL loss: 0.12039747\n",
            "Epoch: 42 - Step: 102 - MSE loss: 0.0040793098 - KL loss: 0.120483294\n",
            "Epoch: 42 - Step: 103 - MSE loss: 0.0040247156 - KL loss: 0.118270576\n",
            "Epoch: 42 - Step: 104 - MSE loss: 0.0042084814 - KL loss: 0.12555742\n",
            "Epoch: 42 - Step: 105 - MSE loss: 0.0045276233 - KL loss: 0.1238906\n",
            "Epoch: 42 - Step: 106 - MSE loss: 0.005740957 - KL loss: 0.13683319\n",
            "Epoch: 42 - Step: 107 - MSE loss: 0.00507509 - KL loss: 0.13918045\n",
            "Epoch: 42 - Step: 108 - MSE loss: 0.005047208 - KL loss: 0.14090967\n",
            "Epoch: 42 - Step: 109 - MSE loss: 0.005861459 - KL loss: 0.15299395\n",
            "Epoch: 42 - Step: 110 - MSE loss: 0.0059239133 - KL loss: 0.14952892\n",
            "Epoch: 42 - Step: 111 - MSE loss: 0.006632397 - KL loss: 0.16352126\n",
            "Epoch: 42 - Step: 112 - MSE loss: 0.007200613 - KL loss: 0.17205629\n",
            "Epoch: 42 - Step: 113 - MSE loss: 0.0070114373 - KL loss: 0.16152403\n",
            "Epoch: 42 - Step: 114 - MSE loss: 0.0067259013 - KL loss: 0.15559778\n",
            "Epoch: 42 - Step: 115 - MSE loss: 0.007358965 - KL loss: 0.17537278\n",
            "Epoch: 42 - Step: 116 - MSE loss: 0.0075592864 - KL loss: 0.16642132\n",
            "Epoch: 42 - Step: 117 - MSE loss: 0.0071675405 - KL loss: 0.15794425\n",
            "Epoch: 42 - Step: 118 - MSE loss: 0.0069296653 - KL loss: 0.15847893\n",
            "Epoch: 42 - Step: 119 - MSE loss: 0.0073613618 - KL loss: 0.15791014\n",
            "Epoch: 42 - Step: 120 - MSE loss: 0.006432802 - KL loss: 0.16066983\n",
            "Epoch: 42 - Step: 121 - MSE loss: 0.006642131 - KL loss: 0.16055526\n",
            "Epoch: 42 - Step: 122 - MSE loss: 0.0059989784 - KL loss: 0.15479499\n",
            "Epoch: 42 - Step: 123 - MSE loss: 0.006663874 - KL loss: 0.16630363\n",
            "Epoch: 42 - Step: 124 - MSE loss: 0.006166251 - KL loss: 0.16651843\n",
            "Epoch: 42 - Step: 125 - MSE loss: 0.0067841467 - KL loss: 0.16955933\n",
            "Epoch: 42 - Step: 126 - MSE loss: 0.0062233363 - KL loss: 0.16132182\n",
            "Epoch: 42 - Step: 127 - MSE loss: 0.0064469003 - KL loss: 0.159448\n",
            "Epoch: 42 - Step: 128 - MSE loss: 0.006497094 - KL loss: 0.17068133\n",
            "Epoch: 42 - Step: 129 - MSE loss: 0.006779971 - KL loss: 0.1620954\n",
            "Epoch: 42 - Step: 130 - MSE loss: 0.0066033737 - KL loss: 0.1732862\n",
            "Epoch: 42 - Step: 131 - MSE loss: 0.006317192 - KL loss: 0.1672148\n",
            "Epoch: 42 - Step: 132 - MSE loss: 0.0072803753 - KL loss: 0.17351168\n",
            "Epoch: 42 - Step: 133 - MSE loss: 0.0077675935 - KL loss: 0.16553396\n",
            "Epoch: 42 - Step: 134 - MSE loss: 0.0072079054 - KL loss: 0.16755952\n",
            "Epoch: 42 - Step: 135 - MSE loss: 0.007947026 - KL loss: 0.16761228\n",
            "Epoch: 42 - Step: 136 - MSE loss: 0.0077023827 - KL loss: 0.16772765\n",
            "Epoch: 42 - Step: 137 - MSE loss: 0.008679123 - KL loss: 0.16942602\n",
            "Epoch: 42 - Step: 138 - MSE loss: 0.008465173 - KL loss: 0.18516132\n",
            "Epoch: 42 - Step: 139 - MSE loss: 0.008328472 - KL loss: 0.16753307\n",
            "Epoch: 42 - Step: 140 - MSE loss: 0.008111842 - KL loss: 0.1743441\n",
            "Epoch: 42 - Step: 141 - MSE loss: 0.009309495 - KL loss: 0.16620636\n",
            "Epoch: 42 - Step: 142 - MSE loss: 0.009248953 - KL loss: 0.1711353\n",
            "Epoch: 42 - Step: 143 - MSE loss: 0.008581014 - KL loss: 0.16499701\n",
            "Epoch: 42 - Step: 144 - MSE loss: 0.008112156 - KL loss: 0.17595766\n",
            "Epoch:  43\n",
            "Epoch: 43 - Step: 0 - MSE loss: 0.004177855 - KL loss: 0.114008844\n",
            "Epoch: 43 - Step: 1 - MSE loss: 0.0045646504 - KL loss: 0.11946343\n",
            "Epoch: 43 - Step: 2 - MSE loss: 0.004118789 - KL loss: 0.123244956\n",
            "Epoch: 43 - Step: 3 - MSE loss: 0.0034712618 - KL loss: 0.11253024\n",
            "Epoch: 43 - Step: 4 - MSE loss: 0.003782956 - KL loss: 0.11776316\n",
            "Epoch: 43 - Step: 5 - MSE loss: 0.004027625 - KL loss: 0.12397459\n",
            "Epoch: 43 - Step: 6 - MSE loss: 0.0040100333 - KL loss: 0.12213895\n",
            "Epoch: 43 - Step: 7 - MSE loss: 0.00397519 - KL loss: 0.12177919\n",
            "Epoch: 43 - Step: 8 - MSE loss: 0.0044419942 - KL loss: 0.12806734\n",
            "Epoch: 43 - Step: 9 - MSE loss: 0.004674643 - KL loss: 0.121663585\n",
            "Epoch: 43 - Step: 10 - MSE loss: 0.004629892 - KL loss: 0.12175077\n",
            "Epoch: 43 - Step: 11 - MSE loss: 0.0046000252 - KL loss: 0.12425108\n",
            "Epoch: 43 - Step: 12 - MSE loss: 0.004676925 - KL loss: 0.11861257\n",
            "Epoch: 43 - Step: 13 - MSE loss: 0.004470229 - KL loss: 0.120072395\n",
            "Epoch: 43 - Step: 14 - MSE loss: 0.004807778 - KL loss: 0.122641094\n",
            "Epoch: 43 - Step: 15 - MSE loss: 0.0048775016 - KL loss: 0.12289472\n",
            "Epoch: 43 - Step: 16 - MSE loss: 0.0050440263 - KL loss: 0.12224685\n",
            "Epoch: 43 - Step: 17 - MSE loss: 0.0047645764 - KL loss: 0.119708315\n",
            "Epoch: 43 - Step: 18 - MSE loss: 0.0044474276 - KL loss: 0.111057445\n",
            "Epoch: 43 - Step: 19 - MSE loss: 0.004499636 - KL loss: 0.111110955\n",
            "Epoch: 43 - Step: 20 - MSE loss: 0.0047170357 - KL loss: 0.11794415\n",
            "Epoch: 43 - Step: 21 - MSE loss: 0.004994864 - KL loss: 0.10966919\n",
            "Epoch: 43 - Step: 22 - MSE loss: 0.0048593185 - KL loss: 0.11502656\n",
            "Epoch: 43 - Step: 23 - MSE loss: 0.004629861 - KL loss: 0.11408967\n",
            "Epoch: 43 - Step: 24 - MSE loss: 0.004095429 - KL loss: 0.11187397\n",
            "Epoch: 43 - Step: 25 - MSE loss: 0.0042708833 - KL loss: 0.11246981\n",
            "Epoch: 43 - Step: 26 - MSE loss: 0.0039916816 - KL loss: 0.10827084\n",
            "Epoch: 43 - Step: 27 - MSE loss: 0.0043544676 - KL loss: 0.1089309\n",
            "Epoch: 43 - Step: 28 - MSE loss: 0.0045965128 - KL loss: 0.11145294\n",
            "Epoch: 43 - Step: 29 - MSE loss: 0.0044147912 - KL loss: 0.110362865\n",
            "Epoch: 43 - Step: 30 - MSE loss: 0.0037188996 - KL loss: 0.10596391\n",
            "Epoch: 43 - Step: 31 - MSE loss: 0.004176931 - KL loss: 0.11044997\n",
            "Epoch: 43 - Step: 32 - MSE loss: 0.00470843 - KL loss: 0.12176327\n",
            "Epoch: 43 - Step: 33 - MSE loss: 0.005254386 - KL loss: 0.1255458\n",
            "Epoch: 43 - Step: 34 - MSE loss: 0.00485885 - KL loss: 0.12212045\n",
            "Epoch: 43 - Step: 35 - MSE loss: 0.0051537324 - KL loss: 0.13016841\n",
            "Epoch: 43 - Step: 36 - MSE loss: 0.0054686014 - KL loss: 0.14218304\n",
            "Epoch: 43 - Step: 37 - MSE loss: 0.005853512 - KL loss: 0.14030299\n",
            "Epoch: 43 - Step: 38 - MSE loss: 0.0060625453 - KL loss: 0.15201992\n",
            "Epoch: 43 - Step: 39 - MSE loss: 0.006614814 - KL loss: 0.15108189\n",
            "Epoch: 43 - Step: 40 - MSE loss: 0.006827639 - KL loss: 0.16251016\n",
            "Epoch: 43 - Step: 41 - MSE loss: 0.0068044695 - KL loss: 0.15336673\n",
            "Epoch: 43 - Step: 42 - MSE loss: 0.006244421 - KL loss: 0.15111053\n",
            "Epoch: 43 - Step: 43 - MSE loss: 0.006083879 - KL loss: 0.15662858\n",
            "Epoch: 43 - Step: 44 - MSE loss: 0.006061809 - KL loss: 0.15661472\n",
            "Epoch: 43 - Step: 45 - MSE loss: 0.00636409 - KL loss: 0.15207228\n",
            "Epoch: 43 - Step: 46 - MSE loss: 0.0066814483 - KL loss: 0.15611297\n",
            "Epoch: 43 - Step: 47 - MSE loss: 0.006250407 - KL loss: 0.15959717\n",
            "Epoch: 43 - Step: 48 - MSE loss: 0.0063242815 - KL loss: 0.16206586\n",
            "Epoch: 43 - Step: 49 - MSE loss: 0.0067042573 - KL loss: 0.15981278\n",
            "Epoch: 43 - Step: 50 - MSE loss: 0.006659074 - KL loss: 0.16292924\n",
            "Epoch: 43 - Step: 51 - MSE loss: 0.006561309 - KL loss: 0.16378886\n",
            "Epoch: 43 - Step: 52 - MSE loss: 0.0067845862 - KL loss: 0.1685736\n",
            "Epoch: 43 - Step: 53 - MSE loss: 0.007064061 - KL loss: 0.1701869\n",
            "Epoch: 43 - Step: 54 - MSE loss: 0.0068234815 - KL loss: 0.16090876\n",
            "Epoch: 43 - Step: 55 - MSE loss: 0.00694897 - KL loss: 0.16660838\n",
            "Epoch: 43 - Step: 56 - MSE loss: 0.007457249 - KL loss: 0.168768\n",
            "Epoch: 43 - Step: 57 - MSE loss: 0.0065567032 - KL loss: 0.15691994\n",
            "Epoch: 43 - Step: 58 - MSE loss: 0.0067511667 - KL loss: 0.157877\n",
            "Epoch: 43 - Step: 59 - MSE loss: 0.0070503647 - KL loss: 0.16481614\n",
            "Epoch: 43 - Step: 60 - MSE loss: 0.0069130673 - KL loss: 0.16565844\n",
            "Epoch: 43 - Step: 61 - MSE loss: 0.007478394 - KL loss: 0.1728923\n",
            "Epoch: 43 - Step: 62 - MSE loss: 0.007036745 - KL loss: 0.16983771\n",
            "Epoch: 43 - Step: 63 - MSE loss: 0.0076326584 - KL loss: 0.17187923\n",
            "Epoch: 43 - Step: 64 - MSE loss: 0.0075418153 - KL loss: 0.1788677\n",
            "Epoch: 43 - Step: 65 - MSE loss: 0.006853039 - KL loss: 0.16574702\n",
            "Epoch: 43 - Step: 66 - MSE loss: 0.006767059 - KL loss: 0.16213968\n",
            "Epoch: 43 - Step: 67 - MSE loss: 0.006465126 - KL loss: 0.14839432\n",
            "Epoch: 43 - Step: 68 - MSE loss: 0.0062146634 - KL loss: 0.1494481\n",
            "Epoch: 43 - Step: 69 - MSE loss: 0.0059353937 - KL loss: 0.14558211\n",
            "Epoch: 43 - Step: 70 - MSE loss: 0.0056849574 - KL loss: 0.14047231\n",
            "Epoch: 43 - Step: 71 - MSE loss: 0.005234318 - KL loss: 0.13040528\n",
            "Epoch: 43 - Step: 72 - MSE loss: 0.004988071 - KL loss: 0.12575898\n",
            "Epoch: 43 - Step: 73 - MSE loss: 0.004649758 - KL loss: 0.12566823\n",
            "Epoch: 43 - Step: 74 - MSE loss: 0.0044202968 - KL loss: 0.12073062\n",
            "Epoch: 43 - Step: 75 - MSE loss: 0.004336612 - KL loss: 0.111298904\n",
            "Epoch: 43 - Step: 76 - MSE loss: 0.0043563917 - KL loss: 0.11501592\n",
            "Epoch: 43 - Step: 77 - MSE loss: 0.0044094482 - KL loss: 0.11392018\n",
            "Epoch: 43 - Step: 78 - MSE loss: 0.004157524 - KL loss: 0.1096486\n",
            "Epoch: 43 - Step: 79 - MSE loss: 0.004825108 - KL loss: 0.11546306\n",
            "Epoch: 43 - Step: 80 - MSE loss: 0.004908914 - KL loss: 0.11778672\n",
            "Epoch: 43 - Step: 81 - MSE loss: 0.0046362383 - KL loss: 0.113647364\n",
            "Epoch: 43 - Step: 82 - MSE loss: 0.00466492 - KL loss: 0.11746365\n",
            "Epoch: 43 - Step: 83 - MSE loss: 0.004924054 - KL loss: 0.1143187\n",
            "Epoch: 43 - Step: 84 - MSE loss: 0.004670669 - KL loss: 0.120514855\n",
            "Epoch: 43 - Step: 85 - MSE loss: 0.0048305998 - KL loss: 0.12320843\n",
            "Epoch: 43 - Step: 86 - MSE loss: 0.0041367044 - KL loss: 0.118522406\n",
            "Epoch: 43 - Step: 87 - MSE loss: 0.004599231 - KL loss: 0.119766764\n",
            "Epoch: 43 - Step: 88 - MSE loss: 0.0046047824 - KL loss: 0.12070159\n",
            "Epoch: 43 - Step: 89 - MSE loss: 0.0045758127 - KL loss: 0.12315933\n",
            "Epoch: 43 - Step: 90 - MSE loss: 0.0043916027 - KL loss: 0.12369879\n",
            "Epoch: 43 - Step: 91 - MSE loss: 0.004344557 - KL loss: 0.12448286\n",
            "Epoch: 43 - Step: 92 - MSE loss: 0.004401767 - KL loss: 0.12463516\n",
            "Epoch: 43 - Step: 93 - MSE loss: 0.0041949754 - KL loss: 0.1256974\n",
            "Epoch: 43 - Step: 94 - MSE loss: 0.0042303093 - KL loss: 0.12019012\n",
            "Epoch: 43 - Step: 95 - MSE loss: 0.0046990155 - KL loss: 0.12613848\n",
            "Epoch: 43 - Step: 96 - MSE loss: 0.004423311 - KL loss: 0.12195141\n",
            "Epoch: 43 - Step: 97 - MSE loss: 0.0044382764 - KL loss: 0.12092966\n",
            "Epoch: 43 - Step: 98 - MSE loss: 0.0046126093 - KL loss: 0.12003249\n",
            "Epoch: 43 - Step: 99 - MSE loss: 0.004492022 - KL loss: 0.12455447\n",
            "Epoch: 43 - Step: 100 - MSE loss: 0.0045140004 - KL loss: 0.12103009\n",
            "Epoch: 43 - Step: 101 - MSE loss: 0.004425748 - KL loss: 0.119135424\n",
            "Epoch: 43 - Step: 102 - MSE loss: 0.004545434 - KL loss: 0.118218\n",
            "Epoch: 43 - Step: 103 - MSE loss: 0.004597287 - KL loss: 0.12297911\n",
            "Epoch: 43 - Step: 104 - MSE loss: 0.004425946 - KL loss: 0.11953911\n",
            "Epoch: 43 - Step: 105 - MSE loss: 0.0045612636 - KL loss: 0.12557687\n",
            "Epoch: 43 - Step: 106 - MSE loss: 0.0054523437 - KL loss: 0.14020348\n",
            "Epoch: 43 - Step: 107 - MSE loss: 0.0054188096 - KL loss: 0.13654438\n",
            "Epoch: 43 - Step: 108 - MSE loss: 0.004983071 - KL loss: 0.13721457\n",
            "Epoch: 43 - Step: 109 - MSE loss: 0.0055350834 - KL loss: 0.14774063\n",
            "Epoch: 43 - Step: 110 - MSE loss: 0.0060520787 - KL loss: 0.1478745\n",
            "Epoch: 43 - Step: 111 - MSE loss: 0.0055088084 - KL loss: 0.14969754\n",
            "Epoch: 43 - Step: 112 - MSE loss: 0.006521505 - KL loss: 0.15487605\n",
            "Epoch: 43 - Step: 113 - MSE loss: 0.00635426 - KL loss: 0.15996045\n",
            "Epoch: 43 - Step: 114 - MSE loss: 0.00669685 - KL loss: 0.15506993\n",
            "Epoch: 43 - Step: 115 - MSE loss: 0.0074145906 - KL loss: 0.16924512\n",
            "Epoch: 43 - Step: 116 - MSE loss: 0.0076005035 - KL loss: 0.16819982\n",
            "Epoch: 43 - Step: 117 - MSE loss: 0.006966373 - KL loss: 0.16729955\n",
            "Epoch: 43 - Step: 118 - MSE loss: 0.007457469 - KL loss: 0.15094954\n",
            "Epoch: 43 - Step: 119 - MSE loss: 0.007947403 - KL loss: 0.16717412\n",
            "Epoch: 43 - Step: 120 - MSE loss: 0.007825372 - KL loss: 0.15781087\n",
            "Epoch: 43 - Step: 121 - MSE loss: 0.006680917 - KL loss: 0.15677914\n",
            "Epoch: 43 - Step: 122 - MSE loss: 0.006123856 - KL loss: 0.15455522\n",
            "Epoch: 43 - Step: 123 - MSE loss: 0.00686235 - KL loss: 0.16583157\n",
            "Epoch: 43 - Step: 124 - MSE loss: 0.0064326287 - KL loss: 0.16280703\n",
            "Epoch: 43 - Step: 125 - MSE loss: 0.0064035724 - KL loss: 0.16666731\n",
            "Epoch: 43 - Step: 126 - MSE loss: 0.006543882 - KL loss: 0.1688284\n",
            "Epoch: 43 - Step: 127 - MSE loss: 0.0064782486 - KL loss: 0.16027065\n",
            "Epoch: 43 - Step: 128 - MSE loss: 0.0064822864 - KL loss: 0.16093059\n",
            "Epoch: 43 - Step: 129 - MSE loss: 0.006223938 - KL loss: 0.16577262\n",
            "Epoch: 43 - Step: 130 - MSE loss: 0.007385922 - KL loss: 0.17399684\n",
            "Epoch: 43 - Step: 131 - MSE loss: 0.006903367 - KL loss: 0.16811977\n",
            "Epoch: 43 - Step: 132 - MSE loss: 0.008378487 - KL loss: 0.17847887\n",
            "Epoch: 43 - Step: 133 - MSE loss: 0.010716864 - KL loss: 0.16846652\n",
            "Epoch: 43 - Step: 134 - MSE loss: 0.01045366 - KL loss: 0.1617484\n",
            "Epoch: 43 - Step: 135 - MSE loss: 0.009216684 - KL loss: 0.17308275\n",
            "Epoch: 43 - Step: 136 - MSE loss: 0.009321148 - KL loss: 0.16926575\n",
            "Epoch: 43 - Step: 137 - MSE loss: 0.008845468 - KL loss: 0.17541301\n",
            "Epoch: 43 - Step: 138 - MSE loss: 0.008747644 - KL loss: 0.16425231\n",
            "Epoch: 43 - Step: 139 - MSE loss: 0.008589089 - KL loss: 0.1775691\n",
            "Epoch: 43 - Step: 140 - MSE loss: 0.008849203 - KL loss: 0.16685304\n",
            "Epoch: 43 - Step: 141 - MSE loss: 0.009184791 - KL loss: 0.17212667\n",
            "Epoch: 43 - Step: 142 - MSE loss: 0.009297199 - KL loss: 0.15918998\n",
            "Epoch: 43 - Step: 143 - MSE loss: 0.008024569 - KL loss: 0.17291498\n",
            "Epoch: 43 - Step: 144 - MSE loss: 0.008010428 - KL loss: 0.16613822\n",
            "Epoch:  44\n",
            "Epoch: 44 - Step: 0 - MSE loss: 0.0039441846 - KL loss: 0.1100302\n",
            "Epoch: 44 - Step: 1 - MSE loss: 0.0038055035 - KL loss: 0.11822523\n",
            "Epoch: 44 - Step: 2 - MSE loss: 0.003700239 - KL loss: 0.117898196\n",
            "Epoch: 44 - Step: 3 - MSE loss: 0.0037369544 - KL loss: 0.11783801\n",
            "Epoch: 44 - Step: 4 - MSE loss: 0.003946518 - KL loss: 0.116422966\n",
            "Epoch: 44 - Step: 5 - MSE loss: 0.0038289428 - KL loss: 0.11851405\n",
            "Epoch: 44 - Step: 6 - MSE loss: 0.0042867213 - KL loss: 0.11729767\n",
            "Epoch: 44 - Step: 7 - MSE loss: 0.0042955074 - KL loss: 0.12285445\n",
            "Epoch: 44 - Step: 8 - MSE loss: 0.0044071698 - KL loss: 0.116864115\n",
            "Epoch: 44 - Step: 9 - MSE loss: 0.004715731 - KL loss: 0.12361701\n",
            "Epoch: 44 - Step: 10 - MSE loss: 0.004371541 - KL loss: 0.124188244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gqvzVsIxtz77"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}